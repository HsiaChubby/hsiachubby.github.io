{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/robots.txt","path":"robots.txt","modified":0,"renderable":0},{"_id":"source/images/1548834369938.jpg","path":"images/1548834369938.jpg","modified":0,"renderable":0},{"_id":"source/images/gradient_ill.jpg","path":"images/gradient_ill.jpg","modified":0,"renderable":0},{"_id":"source/images/mse_ill.jpg","path":"images/mse_ill.jpg","modified":0,"renderable":0},{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":0,"renderable":1},{"_id":"themes/next/source/images/algolia_logo.svg","path":"images/algolia_logo.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/avatar.gif","path":"images/avatar.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/apple-touch-icon-next.png","path":"images/apple-touch-icon-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/favicon-32x32-next.png","path":"images/favicon-32x32-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/favicon-16x16-next.png","path":"images/favicon-16x16-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/placeholder.gif","path":"images/placeholder.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/loading.gif","path":"images/loading.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/logo.svg","path":"images/logo.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/quote-l.svg","path":"images/quote-l.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/searchicon.png","path":"images/searchicon.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/quote-r.svg","path":"images/quote-r.svg","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/exturl.js","path":"js/src/exturl.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/bootstrap.js","path":"js/src/bootstrap.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/algolia-search.js","path":"js/src/algolia-search.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/affix.js","path":"js/src/affix.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/js.cookie.js","path":"js/src/js.cookie.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/motion.js","path":"js/src/motion.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/post-details.js","path":"js/src/post-details.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/hook-duoshuo.js","path":"js/src/hook-duoshuo.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/scroll-cookie.js","path":"js/src/scroll-cookie.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/scrollspy.js","path":"js/src/scrollspy.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/utils.js","path":"js/src/utils.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","path":"lib/canvas-nest/canvas-nest.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","path":"lib/algolia-instant-search/instantsearch.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/LICENSE","path":"lib/fastclick/LICENSE","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/README.md","path":"lib/fastclick/README.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/bower.json","path":"lib/fastclick/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","path":"lib/font-awesome/HELP-US-OUT.txt","modified":0,"renderable":1},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","path":"lib/canvas-ribbon/canvas-ribbon.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/bower.json","path":"lib/font-awesome/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","path":"lib/jquery_lazyload/README.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","path":"lib/jquery_lazyload/CONTRIBUTING.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","path":"lib/jquery_lazyload/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","path":"lib/jquery_lazyload/jquery.scrollstop.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","path":"lib/jquery_lazyload/jquery.lazyload.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","path":"lib/pace/pace-theme-barber-shop.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/font-embedded.css","path":"lib/needsharebutton/font-embedded.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.js","path":"lib/needsharebutton/needsharebutton.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.css","path":"lib/needsharebutton/needsharebutton.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","path":"lib/pace/pace-theme-big-counter.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","path":"lib/pace/pace-theme-center-atom.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","path":"lib/pace/pace-theme-center-circle.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","path":"lib/pace/pace-theme-bounce.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","path":"lib/pace/pace-theme-center-radar.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","path":"lib/pace/pace-theme-corner-indicator.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","path":"lib/pace/pace-theme-loading-bar.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","path":"lib/pace/pace-theme-fill-left.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","path":"lib/pace/pace-theme-center-simple.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","path":"lib/pace/pace-theme-flash.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","path":"lib/pace/pace-theme-mac-osx.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","path":"lib/pace/pace-theme-minimal.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace.min.js","path":"lib/pace/pace.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","path":"lib/three/canvas_sphere.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","path":"lib/three/canvas_lines.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/bower.json","path":"lib/velocity/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/three-waves.min.js","path":"lib/three/three-waves.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","path":"lib/velocity/velocity.ui.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.min.js","path":"lib/velocity/velocity.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","path":"lib/velocity/velocity.ui.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery/index.js","path":"lib/jquery/index.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/schemes/pisces.js","path":"js/src/schemes/pisces.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.css","path":"lib/Han/dist/han.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.js","path":"lib/Han/dist/han.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","path":"lib/fancybox/source/blank.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","path":"lib/fancybox/source/fancybox_overlay.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","path":"lib/fancybox/source/fancybox_loading@2x.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","path":"lib/fancybox/source/fancybox_loading.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","path":"lib/fancybox/source/jquery.fancybox.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","path":"lib/fancybox/source/fancybox_sprite@2x.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","path":"lib/fancybox/source/fancybox_sprite.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","path":"lib/fastclick/lib/fastclick.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","path":"lib/fancybox/source/jquery.fancybox.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","path":"lib/fastclick/lib/fastclick.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","path":"lib/font-awesome/css/font-awesome.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","path":"lib/font-awesome/css/font-awesome.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","path":"lib/font-awesome/css/font-awesome.css.map","modified":0,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","path":"lib/ua-parser-js/dist/ua-parser.pack.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","path":"lib/ua-parser-js/dist/ua-parser.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.css","path":"lib/Han/dist/han.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.js","path":"lib/Han/dist/han.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","path":"lib/fancybox/source/jquery.fancybox.pack.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","path":"lib/font-awesome/fonts/fontawesome-webfont.woff2","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","path":"lib/font-awesome/fonts/fontawesome-webfont.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.js","path":"lib/velocity/velocity.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","path":"lib/Han/dist/font/han-space.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","path":"lib/Han/dist/font/han-space.otf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","path":"lib/Han/dist/font/han.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","path":"lib/Han/dist/font/han.otf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff2","path":"lib/Han/dist/font/han.woff2","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","path":"lib/fancybox/source/helpers/jquery.fancybox-media.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","path":"lib/fancybox/source/helpers/fancybox_buttons.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","path":"lib/font-awesome/fonts/FontAwesome.otf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","path":"lib/font-awesome/fonts/fontawesome-webfont.eot","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","path":"lib/font-awesome/fonts/fontawesome-webfont.ttf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","path":"lib/algolia-instant-search/instantsearch.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","path":"lib/font-awesome/fonts/fontawesome-webfont.svg","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/three.min.js","path":"lib/three/three.min.js","modified":0,"renderable":1},{"_id":"source/images/dashboard-login.png","path":"images/dashboard-login.png","modified":1,"renderable":0}],"Cache":[{"_id":"source/.DS_Store","hash":"495dc0d217dbc3e7cb0c015a4aa9af3e7011d37f","modified":1548902810000},{"_id":"source/robots.txt","hash":"52b9410c2e5c1f83126794ad0de43c31eaaf6d82","modified":1548906321000},{"_id":"themes/next/.bowerrc","hash":"3228a58ed0ece9f85e1e3136352094080b8dece1","modified":1548830812000},{"_id":"themes/next/.gitignore","hash":"0b5c2ffd41f66eb1849d6426ba8cf9649eeed329","modified":1548830812000},{"_id":"themes/next/.editorconfig","hash":"792fd2bd8174ece1a75d5fd24ab16594886f3a7f","modified":1548830812000},{"_id":"themes/next/.gitattributes","hash":"44bd4729c74ccb88110804f41746fec07bf487d4","modified":1548830812000},{"_id":"themes/next/.javascript_ignore","hash":"8a224b381155f10e6eb132a4d815c5b52962a9d1","modified":1548830812000},{"_id":"themes/next/.hound.yml","hash":"b76daa84c9ca3ad292c78412603370a367cc2bc3","modified":1548830812000},{"_id":"themes/next/.stylintrc","hash":"b28e24704a5d8de08346c45286574c8e76cc109f","modified":1548830812000},{"_id":"themes/next/.jshintrc","hash":"9928f81bd822f6a8d67fdbc909b517178533bca9","modified":1548830812000},{"_id":"themes/next/.travis.yml","hash":"d60d4a5375fea23d53b2156b764a99b2e56fa660","modified":1548830812000},{"_id":"themes/next/LICENSE","hash":"f293bcfcdc06c0b77ba13570bb8af55eb5c059fd","modified":1548830812000},{"_id":"themes/next/README.cn.md","hash":"2c766b3369ed477bce134a5450dab45bef161504","modified":1548830812000},{"_id":"themes/next/README.md","hash":"8ce60ce578963eb4e1eb5e33e1efc2fc4779af9c","modified":1548830812000},{"_id":"themes/next/_config.yml","hash":"ae7fd712973c2d21b5657ae15cb924d80741f15f","modified":1548904823000},{"_id":"themes/next/bower.json","hash":"0674f11d3d514e087a176da0e1d85c2286aa5fba","modified":1548830812000},{"_id":"themes/next/package.json","hash":"036d3a1346203d2f1a3958024df7f74e7ac07bfe","modified":1548830812000},{"_id":"themes/next/gulpfile.coffee","hash":"031bffc483e417b20e90eceb6cf358e7596d2e69","modified":1548830812000},{"_id":"source/_posts/kubeadm1-13创建HAkubernetes集群.md","hash":"d99ae41ee720359e5ddc0737115a7cd411ee6f87","modified":1550482271000},{"_id":"source/_posts/基于docker-cookiercutter创建data-science项目.md","hash":"3d6c9fa73c63a5626d7e70c12a32fe7e8524dab8","modified":1548935652000},{"_id":"source/_posts/使用hexo+github搭建个人博客.md","hash":"a6010995242f1ed7de6177db4d6020008435ad67","modified":1548907476000},{"_id":"source/_posts/机器学习中常用优化算法总结.md","hash":"6c2d7747a9877a2ed0b7570041a2568ea8279689","modified":1548907317000},{"_id":"source/_posts/机器学习概论.md","hash":"b1de1ba57ca0a14d7bfe78237e27300bacf0bf00","modified":1548835602000},{"_id":"source/about/index.md","hash":"b18059dd90a13fda22befec58af167ed9531c0b3","modified":1548833132000},{"_id":"source/archives/index.md","hash":"fd1e3a4bfe7bbf775df2aeb798ecbb6920770b44","modified":1548833121000},{"_id":"source/images/1548834369938.jpg","hash":"3799e07d0109342b9e9b49f6183bc0f1e489261e","modified":1548834530000},{"_id":"source/categories/index.md","hash":"1e3a4cb1493e97360f58a9da048f2883e8fb9879","modified":1548831530000},{"_id":"source/images/gradient_ill.jpg","hash":"8cdb034b659a1edae672defd02239fa1ad6489ce","modified":1548902625000},{"_id":"source/images/mse_ill.jpg","hash":"0fc67787a50394c709d1bee5ecaffe471f2d998b","modified":1548902839000},{"_id":"source/tags/index.md","hash":"dc949f05aac9f80d70e943130a8082344fe7e00f","modified":1548833104000},{"_id":"themes/next/.git/HEAD","hash":"acbaef275e46a7f14c1ef456fff2c8bbe8c84724","modified":1548830812000},{"_id":"themes/next/.git/config","hash":"bf7d1df65cf34d0f25a7184a58c37a09f72e4be7","modified":1548830812000},{"_id":"themes/next/.git/description","hash":"9635f1b7e12c045212819dd934d809ef07efa2f4","modified":1548830800000},{"_id":"themes/next/.git/index","hash":"b4ab15f2f498ce9b08cfea2a866f8d709fea393d","modified":1548839052000},{"_id":"themes/next/.git/packed-refs","hash":"8e36811256ee380c2c65692f1b8f8e77c5bc33c9","modified":1548830812000},{"_id":"themes/next/.github/PULL_REQUEST_TEMPLATE.md","hash":"902f627155a65099e0a37842ff396a58d0dc306f","modified":1548830812000},{"_id":"themes/next/.github/CONTRIBUTING.md","hash":"3b5eafd32abb718e56ccf8d1cee0607ad8ce611d","modified":1548830812000},{"_id":"themes/next/.github/ISSUE_TEMPLATE.md","hash":"50d48c47162817a3810a9d9ad51104e83947419a","modified":1548830812000},{"_id":"themes/next/.github/browserstack_logo.png","hash":"a6c43887f64a7f48a2814e3714eaa1215e542037","modified":1548830812000},{"_id":"themes/next/scripts/merge-configs.js","hash":"81e86717ecfb775986b945d17f0a4ba27532ef07","modified":1548830812000},{"_id":"themes/next/scripts/merge.js","hash":"9130dabe6a674c54b535f322b17d75fe6081472f","modified":1548830812000},{"_id":"themes/next/layout/_layout.swig","hash":"da0929166674ea637e0ad454f85ad0d7bac4aff2","modified":1548830812000},{"_id":"themes/next/layout/archive.swig","hash":"f0a8225feafd971419837cdb4bcfec98a4a59b2f","modified":1548830812000},{"_id":"themes/next/layout/category.swig","hash":"4472255f4a3e3dd6d79201523a9526dcabdfbf18","modified":1548830812000},{"_id":"themes/next/layout/index.swig","hash":"783611349c941848a0e26ee2f1dc44dd14879bd1","modified":1548830812000},{"_id":"themes/next/layout/schedule.swig","hash":"d86f8de4e118f8c4d778b285c140474084a271db","modified":1548830812000},{"_id":"themes/next/layout/tag.swig","hash":"7e0a7d7d832883eddb1297483ad22c184e4368de","modified":1548830812000},{"_id":"themes/next/layout/page.swig","hash":"969caaee05bdea725e99016eb63d810893a73e99","modified":1548830812000},{"_id":"themes/next/layout/post.swig","hash":"b3589a8e46288a10d20e41c7a5985d2493725aec","modified":1548830812000},{"_id":"themes/next/languages/de.yml","hash":"057e7df11ddeb1c8c15a5d7c5ff29430d725ec6b","modified":1548830812000},{"_id":"themes/next/languages/default.yml","hash":"44ef3f26917f467459326c2c8be2f73e4d947f35","modified":1548830812000},{"_id":"themes/next/languages/id.yml","hash":"b5de1ea66dd9ef54cac9a1440eaa4e3f5fc011f5","modified":1548830812000},{"_id":"themes/next/languages/fr-FR.yml","hash":"7e4eb7011b8feee641cfb11c6e73180b0ded1c0f","modified":1548830812000},{"_id":"themes/next/languages/en.yml","hash":"7e680d9bb8f3a3a9d1ba1c9d312b3d257183dded","modified":1548830812000},{"_id":"themes/next/languages/ko.yml","hash":"ea5b46056e73ebcee121d5551627af35cbffc900","modified":1548830812000},{"_id":"themes/next/languages/ja.yml","hash":"3c76e16fd19b262864475faa6854b718bc08c4d8","modified":1548830812000},{"_id":"themes/next/languages/nl-NL.yml","hash":"edca4f3598857dbc3cbf19ed412213329b6edd47","modified":1548830812000},{"_id":"themes/next/languages/it.yml","hash":"aa595f2bda029f73ef7bfa104b4c55c3f4e9fb4c","modified":1548830812000},{"_id":"themes/next/languages/ru.yml","hash":"98ec6f0b7183282e11cffc7ff586ceb82400dd75","modified":1548830812000},{"_id":"themes/next/languages/pt.yml","hash":"44b61f2d085b827b507909a0b8f8ce31c6ef5d04","modified":1548830812000},{"_id":"themes/next/languages/zh-Hans.yml","hash":"16ef56d0dea94638de7d200984c90ae56f26b4fe","modified":1548830812000},{"_id":"themes/next/languages/pt-BR.yml","hash":"b1694ae766ed90277bcc4daca4b1cfa19cdcb72b","modified":1548830812000},{"_id":"themes/next/languages/vi.yml","hash":"fd08d3c8d2c62965a98ac420fdaf95e54c25d97c","modified":1548830812000},{"_id":"themes/next/languages/zh-hk.yml","hash":"9396f41ae76e4fef99b257c93c7354e661f6e0fa","modified":1548830812000},{"_id":"themes/next/languages/zh-tw.yml","hash":"50b71abb3ecc0686f9739e179e2f829cd074ecd9","modified":1548830812000},{"_id":"themes/next/test/intern.js","hash":"11fa8a4f5c3b4119a179ae0a2584c8187f907a73","modified":1548830813000},{"_id":"themes/next/test/helpers.js","hash":"a1f5de25154c3724ffc24a91ddc576cdbd60864f","modified":1548830813000},{"_id":"themes/next/test/.jshintrc","hash":"19f93d13d1689fe033c82eb2d5f3ce30b6543cc0","modified":1548830813000},{"_id":"themes/next/source/fonts/.gitkeep","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1548830812000},{"_id":"themes/next/.git/hooks/applypatch-msg.sample","hash":"4de88eb95a5e93fd27e78b5fb3b5231a8d8917dd","modified":1548830800000},{"_id":"themes/next/.git/hooks/post-update.sample","hash":"b614c2f63da7dca9f1db2e7ade61ef30448fc96c","modified":1548830800000},{"_id":"themes/next/.git/hooks/pre-applypatch.sample","hash":"f208287c1a92525de9f5462e905a9d31de1e2d75","modified":1548830800000},{"_id":"themes/next/.git/hooks/commit-msg.sample","hash":"ee1ed5aad98a435f2020b6de35c173b75d9affac","modified":1548830800000},{"_id":"themes/next/.git/hooks/pre-commit.sample","hash":"36aed8976dcc08b5076844f0ec645b18bc37758f","modified":1548830800000},{"_id":"themes/next/.git/hooks/prepare-commit-msg.sample","hash":"2b6275eda365cad50d167fe3a387c9bc9fedd54f","modified":1548830800000},{"_id":"themes/next/.git/hooks/pre-push.sample","hash":"5c8518bfd1d1d3d2c1a7194994c0a16d8a313a41","modified":1548830800000},{"_id":"themes/next/.git/hooks/pre-receive.sample","hash":"705a17d259e7896f0082fe2e9f2c0c3b127be5ac","modified":1548830800000},{"_id":"themes/next/.git/info/exclude","hash":"c879df015d97615050afa7b9641e3352a1e701ac","modified":1548830800000},{"_id":"themes/next/.git/hooks/update.sample","hash":"e729cd61b27c128951d139de8e7c63d1a3758dde","modified":1548830800000},{"_id":"themes/next/.git/hooks/pre-rebase.sample","hash":"5885a56ab4fca8075a05a562d005e922cde9853b","modified":1548830800000},{"_id":"themes/next/.git/logs/HEAD","hash":"8582611f24b301c7a614ce3f2172ef4c7ed45235","modified":1548830812000},{"_id":"themes/next/scripts/tags/button.js","hash":"d023f10a00077f47082b0517e2ad666e6e994f60","modified":1548830812000},{"_id":"themes/next/scripts/tags/center-quote.js","hash":"535fc542781021c4326dec24d8495cbb1387634a","modified":1548830812000},{"_id":"themes/next/scripts/tags/exturl.js","hash":"8d7e60f60779bde050d20fd76f6fdc36fc85e06d","modified":1548830812000},{"_id":"themes/next/scripts/tags/full-image.js","hash":"8eeb3fb89540299bdbb799edfdfdac3743b50596","modified":1548830812000},{"_id":"themes/next/scripts/tags/group-pictures.js","hash":"49252824cd53184dc9b97b2f2d87ff28e1b3ef27","modified":1548830812000},{"_id":"themes/next/scripts/tags/label.js","hash":"2f8f41a7316372f0d1ed6b51190dc4acd3e16fff","modified":1548830812000},{"_id":"themes/next/scripts/tags/lazy-image.js","hash":"eeeabede68cf263de9e6593ecf682f620da16f0a","modified":1548830812000},{"_id":"themes/next/scripts/tags/note.js","hash":"64de4e9d01cf3b491ffc7d53afdf148ee5ad9779","modified":1548830812000},{"_id":"themes/next/scripts/tags/tabs.js","hash":"5786545d51c38e8ca38d1bfc7dd9e946fc70a316","modified":1548830812000},{"_id":"themes/next/source/css/main.styl","hash":"20702c48d6053c92c5bcdbc68e8d0ef1369848a0","modified":1548830812000},{"_id":"themes/next/source/images/algolia_logo.svg","hash":"ec119560b382b2624e00144ae01c137186e91621","modified":1548830812000},{"_id":"themes/next/source/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1548830812000},{"_id":"themes/next/source/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1548830812000},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1548830812000},{"_id":"themes/next/source/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1548830812000},{"_id":"themes/next/source/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1548830812000},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1548830812000},{"_id":"themes/next/source/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1548830812000},{"_id":"themes/next/source/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1548830812000},{"_id":"themes/next/source/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1548830812000},{"_id":"themes/next/source/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1548830812000},{"_id":"themes/next/source/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1548830812000},{"_id":"themes/next/source/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1548830812000},{"_id":"themes/next/source/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1548830812000},{"_id":"themes/next/source/images/logo.svg","hash":"d29cacbae1bdc4bbccb542107ee0524fe55ad6de","modified":1548830812000},{"_id":"themes/next/source/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1548830812000},{"_id":"themes/next/source/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1548830813000},{"_id":"themes/next/layout/_custom/header.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1548830812000},{"_id":"themes/next/layout/_custom/sidebar.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1548830812000},{"_id":"themes/next/source/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1548830812000},{"_id":"themes/next/layout/_macro/post-collapse.swig","hash":"31322a7f57936cf2dc62e824af5490da5354cf02","modified":1548830812000},{"_id":"themes/next/layout/_macro/post-copyright.swig","hash":"665a928604f99d2ba7dc4a4a9150178229568cc6","modified":1548830812000},{"_id":"themes/next/layout/_macro/reward.swig","hash":"56e8d8556cf474c56ae1bef9cb7bbd26554adb07","modified":1548830812000},{"_id":"themes/next/layout/_macro/post.swig","hash":"446a35a2cd389f8cfc3aa38973a9b44ad0740134","modified":1548830812000},{"_id":"themes/next/layout/_macro/sidebar.swig","hash":"6a54c3c85ff6b19d275827a327abbf4bd99b2ebf","modified":1548830812000},{"_id":"themes/next/layout/_partials/footer.swig","hash":"c4d6181f5d3db5365e622f78714af8cc58d7a45e","modified":1548830812000},{"_id":"themes/next/layout/_macro/wechat-subscriber.swig","hash":"39852700e4084ecccffa6d4669168e5cc0514c9e","modified":1548830812000},{"_id":"themes/next/layout/_partials/comments.swig","hash":"4a6f5b1792b2e5262b7fdab9a716b3108e2f09c7","modified":1548830812000},{"_id":"themes/next/layout/_partials/page-header.swig","hash":"1efd925d34a5d4ba2dc0838d9c86ba911e705fc9","modified":1548830812000},{"_id":"themes/next/layout/_partials/head.swig","hash":"6b94fe8f3279daea5623c49ef4bb35917ba57510","modified":1548830812000},{"_id":"themes/next/layout/_partials/header.swig","hash":"ed042be6252848058c90109236ec988e392d91d4","modified":1548830812000},{"_id":"themes/next/layout/_partials/pagination.swig","hash":"9e8e21d194ef44d271b1cca0bc1448c14d7edf4f","modified":1548830812000},{"_id":"themes/next/layout/_partials/search.swig","hash":"9dbd378e94abfcb3f864a5b8dbbf18d212ca2ee0","modified":1548830812000},{"_id":"themes/next/layout/_scripts/boostrap.swig","hash":"03aaebe9d50f6acb007ec38cc04acd1cfceb404d","modified":1548830812000},{"_id":"themes/next/layout/_scripts/commons.swig","hash":"766b2bdda29523ed6cd8d7aa197f996022f8fd94","modified":1548830812000},{"_id":"themes/next/layout/_third-party/mathjax.swig","hash":"6d25596d6a7c57700d37b607f8d9a62d89708683","modified":1548830812000},{"_id":"themes/next/layout/_scripts/vendors.swig","hash":"a266f96ad06ee87bdeae6e105a4b53cd587bbd04","modified":1548830812000},{"_id":"themes/next/layout/_third-party/duoshuo-hot-articles.swig","hash":"5d4638c46aef65bf32a01681495b62416ccc98db","modified":1548830812000},{"_id":"themes/next/layout/_third-party/exturl.swig","hash":"7c04a42319d728be356746363aff8ea247791d24","modified":1548830812000},{"_id":"themes/next/layout/_third-party/needsharebutton.swig","hash":"5fe0447cc88a5a63b530cf0426f93c4634811876","modified":1548830812000},{"_id":"themes/next/layout/_third-party/rating.swig","hash":"fc93b1a7e6aed0dddb1f3910142b48d8ab61174e","modified":1548830812000},{"_id":"themes/next/layout/_third-party/schedule.swig","hash":"22369026c87fc23893c35a7f250b42f3bb1b60f1","modified":1548830812000},{"_id":"themes/next/layout/_third-party/scroll-cookie.swig","hash":"1ddb2336a1a19b47af3017047012c01ec5f54529","modified":1548830812000},{"_id":"themes/next/source/css/_variables/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1548830812000},{"_id":"themes/next/source/css/_variables/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1548830812000},{"_id":"themes/next/source/css/_mixins/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1548830812000},{"_id":"themes/next/source/css/_mixins/Mist.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1548830812000},{"_id":"themes/next/source/css/_mixins/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1548830812000},{"_id":"themes/next/layout/_scripts/schemes/mist.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1548830812000},{"_id":"themes/next/layout/_scripts/schemes/muse.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1548830812000},{"_id":"themes/next/.git/refs/heads/master","hash":"7999da428ebb87e5a2b27315d8d5123c1ccdfaa5","modified":1548830812000},{"_id":"themes/next/source/css/_variables/Gemini.styl","hash":"99fbb4686ea9a3e03a4726ed7cf4d8f529034452","modified":1548830812000},{"_id":"themes/next/source/css/_mixins/Gemini.styl","hash":"2aa5b7166a85a8aa34b17792ae4f58a5a96df6cc","modified":1548830812000},{"_id":"themes/next/source/css/_variables/base.styl","hash":"29c261fa6b4046322559074d75239c6b272fb8a3","modified":1548830812000},{"_id":"themes/next/source/css/_variables/Mist.styl","hash":"be087dcc060e8179f7e7f60ab4feb65817bd3d9f","modified":1548830812000},{"_id":"themes/next/source/css/_variables/Pisces.styl","hash":"f29165e36489a87ba32d17dddfd2720d84e3f3ec","modified":1548830812000},{"_id":"themes/next/source/css/_mixins/base.styl","hash":"82f9055955920ed88a2ab6a20ab02169abb2c634","modified":1548830812000},{"_id":"themes/next/source/css/_mixins/Pisces.styl","hash":"9ab65361ba0a12a986edd103e56492644c2db0b8","modified":1548830812000},{"_id":"themes/next/source/css/_custom/custom.styl","hash":"328d9a9696cc2ccf59c67d3c26000d569f46344c","modified":1548830812000},{"_id":"themes/next/source/js/src/exturl.js","hash":"e42e2aaab7bf4c19a0c8e779140e079c6aa5c0b1","modified":1548830813000},{"_id":"themes/next/source/js/src/bootstrap.js","hash":"034bc8113e0966fe2096ba5b56061bbf10ef0512","modified":1548830813000},{"_id":"themes/next/source/js/src/algolia-search.js","hash":"b172f697ed339a24b1e80261075232978d164c35","modified":1548830813000},{"_id":"themes/next/source/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1548830813000},{"_id":"themes/next/source/js/src/js.cookie.js","hash":"9b37973a90fd50e71ea91682265715e45ae82c75","modified":1548830813000},{"_id":"themes/next/source/js/src/motion.js","hash":"754b294394f102c8fd9423a1789ddb1201677898","modified":1548830813000},{"_id":"themes/next/source/js/src/post-details.js","hash":"a13f45f7aa8291cf7244ec5ba93907d119c5dbdd","modified":1548830813000},{"_id":"themes/next/source/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1548830813000},{"_id":"themes/next/source/js/src/scroll-cookie.js","hash":"09dc828cbf5f31158ff6250d2bf7c3cde6365c67","modified":1548830813000},{"_id":"themes/next/source/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1548830813000},{"_id":"themes/next/source/js/src/utils.js","hash":"9b1325801d27213083d1487a12b1a62b539ab6f8","modified":1548830813000},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1548830813000},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1548830813000},{"_id":"themes/next/source/lib/fancybox/.bower.json","hash":"cc40a9b11e52348e554c84e4a5c058056f6b7aeb","modified":1548830813000},{"_id":"themes/next/source/lib/fastclick/.bower.json","hash":"93ebd5b35e632f714dcf1753e1f6db77ec74449b","modified":1548830813000},{"_id":"themes/next/source/lib/fastclick/LICENSE","hash":"dcd5b6b43095d9e90353a28b09cb269de8d4838e","modified":1548830813000},{"_id":"themes/next/source/lib/fancybox/.gitattributes","hash":"2db21acfbd457452462f71cc4048a943ee61b8e0","modified":1548830813000},{"_id":"themes/next/source/lib/fastclick/README.md","hash":"1decd8e1adad2cd6db0ab50cf56de6035156f4ea","modified":1548830813000},{"_id":"themes/next/source/lib/fastclick/bower.json","hash":"13379463c7463b4b96d13556b46faa4cc38d81e6","modified":1548830813000},{"_id":"themes/next/source/lib/font-awesome/.npmignore","hash":"dcf470ab3a358103bb896a539cc03caeda10fa8b","modified":1548830813000},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1548830813000},{"_id":"themes/next/source/lib/font-awesome/.gitignore","hash":"69d152fa46b517141ec3b1114dd6134724494d83","modified":1548830813000},{"_id":"themes/next/source/lib/font-awesome/.bower.json","hash":"a2aaaf12378db56bd10596ba3daae30950eac051","modified":1548830813000},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","hash":"ff5915eb2596e890a2fc6697c864f861a1995ec0","modified":1548830813000},{"_id":"themes/next/source/lib/jquery/.bower.json","hash":"91745c2cc6c946c7275f952b2b0760b880cea69e","modified":1548830813000},{"_id":"themes/next/source/lib/font-awesome/bower.json","hash":"279a8a718ab6c930a67c41237f0aac166c1b9440","modified":1548830813000},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","hash":"895d50fa29759af7835256522e9dd7dac597765c","modified":1548830813000},{"_id":"themes/next/source/lib/jquery_lazyload/.bower.json","hash":"b7638afc93e9cd350d0783565ee9a7da6805ad8e","modified":1548830813000},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","hash":"4891864c24c28efecd81a6a8d3f261145190f901","modified":1548830813000},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","hash":"65bc85d12197e71c40a55c0cd7f6823995a05222","modified":1548830813000},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1548830813000},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1548830813000},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","hash":"ee0d51446cb4ffe1bb96bd7bc8c8e046dddfcf46","modified":1548830813000},{"_id":"themes/next/source/lib/needsharebutton/font-embedded.css","hash":"c39d37278c1e178838732af21bd26cd0baeddfe0","modified":1548830813000},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.js","hash":"9885fd9bea5e7ebafc5b1de9d17be5e106248d96","modified":1548830813000},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.css","hash":"3ef0020a1815ca6151ea4886cd0d37421ae3695c","modified":1548830813000},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","hash":"5b561dc328af4c4d512e20a76fe964d113a32ba8","modified":1548830813000},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","hash":"dcf79c24fe5350fb73d8038573a104e73639e9d3","modified":1548830813000},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","hash":"a4066769c78affbfbc5e30a600e2c7862cd532e0","modified":1548830813000},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","hash":"f6bdb9a785b7979dd8ec5c60e278af955ef1e585","modified":1548830813000},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","hash":"ab7cba998bf4c03b13df342bf43647fa4f419783","modified":1548830813000},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","hash":"b3c64c973f31884e3d8145989476707333406b9a","modified":1548830813000},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","hash":"7ee28875dfc1230d76c537f6605766e8d4011e9f","modified":1548830813000},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","hash":"0bec1e235a4a2cccda3f993b205424e1441a44ae","modified":1548830813000},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","hash":"67f44c947548bd4d77e7590d3f59e236cbf9e98a","modified":1548830813000},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","hash":"13ace22c40312d7bbd8d9c1e50eff897a7a497d8","modified":1548830813000},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","hash":"9f2e7b51b084da407863826b25265b31150b3821","modified":1548830813000},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","hash":"9cd783cceb8a191f3c8b5d81f7a430ecc3e489d3","modified":1548830813000},{"_id":"themes/next/source/lib/pace/pace.min.js","hash":"9944dfb7814b911090e96446cea4d36e2b487234","modified":1548830813000},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","hash":"d8ea241a53c135a650f7335d2b6982b899fd58a9","modified":1548830813000},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","hash":"dce4a3b65f8bf958f973690caa7ec4952f353b0c","modified":1548830813000},{"_id":"themes/next/source/lib/velocity/.bower.json","hash":"05f960846f1c7a93dab1d3f9a1121e86812e8c88","modified":1548830813000},{"_id":"themes/next/source/lib/velocity/bower.json","hash":"2ec99573e84c7117368beccb9e94b6bf35d2db03","modified":1548830813000},{"_id":"themes/next/source/lib/three/three-waves.min.js","hash":"d968cba6b3a50b3626a02d67b544f349d83b147c","modified":1548830813000},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1548830813000},{"_id":"themes/next/source/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1548830813000},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1548830813000},{"_id":"themes/next/layout/_partials/head/custom-head.swig","hash":"9e1b9666efa77f4cf8d8261bcfa445a9ac608e53","modified":1548830812000},{"_id":"themes/next/layout/_partials/share/add-this.swig","hash":"23e23dc0f76ef3c631f24c65277adf7ea517b383","modified":1548830812000},{"_id":"themes/next/layout/_partials/head/external-fonts.swig","hash":"7ce76358411184482bb0934e70037949dd0da8ca","modified":1548830812000},{"_id":"themes/next/layout/_partials/share/baidushare.swig","hash":"1f1107468aaf03f7d0dcd7eb2b653e2813a675b4","modified":1548830812000},{"_id":"themes/next/layout/_partials/share/duoshuo_share.swig","hash":"89c5a5240ecb223acfe1d12377df5562a943fd5d","modified":1548830812000},{"_id":"themes/next/layout/_partials/share/jiathis.swig","hash":"048fd5e98149469f8c28c21ba3561a7a67952c9b","modified":1548830812000},{"_id":"themes/next/layout/_partials/search/swiftype.swig","hash":"959b7e04a96a5596056e4009b73b6489c117597e","modified":1548830812000},{"_id":"themes/next/layout/_partials/search/localsearch.swig","hash":"957701729b85fb0c5bfcf2fb99c19d54582f91ed","modified":1548830812000},{"_id":"themes/next/layout/_partials/search/tinysou.swig","hash":"eefe2388ff3d424694045eda21346989b123977c","modified":1548830812000},{"_id":"themes/next/layout/_scripts/pages/post-details.swig","hash":"069d1357c717572256e5cdee09574ebce529cbae","modified":1548830812000},{"_id":"themes/next/layout/_scripts/schemes/gemini.swig","hash":"a44acf9b0d0f44ef3dfc767376a95c984cc127de","modified":1548830812000},{"_id":"themes/next/layout/_third-party/analytics/analytics-with-widget.swig","hash":"98df9d72e37dd071e882f2d5623c9d817815b139","modified":1548830812000},{"_id":"themes/next/layout/_scripts/schemes/pisces.swig","hash":"a44acf9b0d0f44ef3dfc767376a95c984cc127de","modified":1548830812000},{"_id":"themes/next/layout/_third-party/analytics/application-insights.swig","hash":"60426bf73f8a89ba61fb1be2df3ad5398e32c4ef","modified":1548830812000},{"_id":"themes/next/layout/_third-party/analytics/busuanzi-counter.swig","hash":"18e7bef8923d83ea42df6c97405e515a876cede4","modified":1548830812000},{"_id":"themes/next/layout/_third-party/analytics/baidu-analytics.swig","hash":"deda6a814ed48debc694c4e0c466f06c127163d0","modified":1548830812000},{"_id":"themes/next/layout/_third-party/analytics/cnzz-analytics.swig","hash":"8160b27bee0aa372c7dc7c8476c05bae57f58d0f","modified":1548830812000},{"_id":"themes/next/layout/_third-party/analytics/facebook-sdk.swig","hash":"a234c5cd1f75ca5731e814d0dbb92fdcf9240d1b","modified":1548830812000},{"_id":"themes/next/layout/_third-party/analytics/firestore.swig","hash":"1cd01c6e92ab1913d48e556a92bb4f28b6dc4996","modified":1548830812000},{"_id":"themes/next/layout/_third-party/analytics/google-analytics.swig","hash":"5d9943d74cc2e0a91badcf4f755c6de77eab193a","modified":1548830812000},{"_id":"themes/next/layout/_third-party/analytics/tencent-mta.swig","hash":"0ddc94ed4ba0c19627765fdf1abc4d8efbe53d5a","modified":1548830812000},{"_id":"themes/next/layout/_third-party/analytics/tencent-analytics.swig","hash":"3658414379e0e8a34c45c40feadc3edc8dc55f88","modified":1548830812000},{"_id":"themes/next/layout/_third-party/analytics/index.swig","hash":"5e9bb24c750b49513d9a65799e832f07410002ac","modified":1548830812000},{"_id":"themes/next/layout/_third-party/analytics/lean-analytics.swig","hash":"fc65b9c98a0a8ab43a5e7aabff6c5f03838e09c8","modified":1548830812000},{"_id":"themes/next/layout/_third-party/analytics/vkontakte-api.swig","hash":"c3971fd154d781088e1cc665035f8561a4098f4c","modified":1548830812000},{"_id":"themes/next/layout/_third-party/comments/disqus.swig","hash":"c316758546dc9ba6c60cb4d852c17ca6bb6d6724","modified":1548830812000},{"_id":"themes/next/layout/_third-party/comments/changyan.swig","hash":"0e3378f7c39b2b0f69638290873ede6b6b6825c0","modified":1548830812000},{"_id":"themes/next/layout/_third-party/comments/duoshuo.swig","hash":"a356b2185d40914447fde817eb3d358ab6b3e4c3","modified":1548830812000},{"_id":"themes/next/layout/_third-party/comments/hypercomments.swig","hash":"3e8dc5c6c912628a37e3b5f886bec7b2e5ed14ea","modified":1548830812000},{"_id":"themes/next/layout/_third-party/comments/gitment.swig","hash":"10160daceaa6f1ecf632323d422ebe2caae49ddf","modified":1548830812000},{"_id":"themes/next/layout/_third-party/comments/index.swig","hash":"aa0629277d751c55c6d973e7691bf84af9b17a60","modified":1548830812000},{"_id":"themes/next/layout/_third-party/comments/livere.swig","hash":"8a2e393d2e49f7bf560766d8a07cd461bf3fce4f","modified":1548830812000},{"_id":"themes/next/layout/_third-party/comments/valine.swig","hash":"fcabbb241f894c9a6309c44e126cf3e8fea81fd4","modified":1548830812000},{"_id":"themes/next/layout/_third-party/comments/youyan.swig","hash":"8b6650f77fe0a824c8075b2659e0403e0c78a705","modified":1548830812000},{"_id":"themes/next/layout/_third-party/search/index.swig","hash":"c747fb5c6b1f500e8f0c583e44195878b66e4e29","modified":1548830812000},{"_id":"themes/next/layout/_third-party/search/localsearch.swig","hash":"385c066af96bee30be2459dbec8aae1f15d382f5","modified":1548830812000},{"_id":"themes/next/layout/_third-party/search/tinysou.swig","hash":"cb3a5d36dbe1630bab84e03a52733a46df7c219b","modified":1548830812000},{"_id":"themes/next/layout/_third-party/seo/baidu-push.swig","hash":"c057b17f79e8261680fbae8dc4e81317a127c799","modified":1548830812000},{"_id":"themes/next/source/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1548830813000},{"_id":"themes/next/.git/logs/refs/heads/master","hash":"8582611f24b301c7a614ce3f2172ef4c7ed45235","modified":1548830812000},{"_id":"themes/next/.git/refs/remotes/origin/HEAD","hash":"d9427cda09aba1cdde5c69c2b13c905bddb0bc51","modified":1548830812000},{"_id":"themes/next/source/css/_common/scaffolding/base.styl","hash":"f7c44b0ee46cf2cf82a4c9455ba8d8b55299976f","modified":1548830812000},{"_id":"themes/next/source/css/_common/scaffolding/helpers.styl","hash":"9c25c75311e1bd4d68df031d3f2ae6d141a90766","modified":1548830812000},{"_id":"themes/next/source/css/_common/scaffolding/mobile.styl","hash":"47a46583a1f3731157a3f53f80ed1ed5e2753e8e","modified":1548830812000},{"_id":"themes/next/source/css/_common/scaffolding/normalize.styl","hash":"ece571f38180febaf02ace8187ead8318a300ea7","modified":1548830812000},{"_id":"themes/next/source/css/_common/scaffolding/scaffolding.styl","hash":"a280a583b7615e939aaddbf778f5c108ef8a2a6c","modified":1548830812000},{"_id":"themes/next/source/css/_common/scaffolding/tables.styl","hash":"64f5d56c08d74a338813df1265580ca0cbf0190b","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/back-to-top-sidebar.styl","hash":"4719ce717962663c5c33ef97b1119a0b3a4ecdc3","modified":1548830812000},{"_id":"themes/next/source/css/_common/outline/outline.styl","hash":"2186be20e317505cd31886f1291429cc21f76703","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/back-to-top.styl","hash":"31050fc7a25784805b4843550151c93bfa55c9c8","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/buttons.styl","hash":"7e509c7c28c59f905b847304dd3d14d94b6f3b8e","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/comments.styl","hash":"471f1627891aca5c0e1973e09fbcb01e1510d193","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/components.styl","hash":"a6bb5256be6195e76addbda12f4ed7c662d65e7a","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/pagination.styl","hash":"c5d48863f332ff8ce7c88dec2c893f709d7331d3","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/tag-cloud.styl","hash":"dd8a3b22fc2f222ac6e6c05bd8a773fb039169c0","modified":1548830812000},{"_id":"themes/next/source/css/_schemes/Mist/_base.styl","hash":"c2d079788d6fc2e9a191ccdae94e50d55bf849dc","modified":1548830812000},{"_id":"themes/next/source/css/_schemes/Gemini/index.styl","hash":"18c3336ee3d09bd2da6a876e1336539f03d5a973","modified":1548830812000},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","hash":"5ae7906dc7c1d9468c7f4b4a6feddddc555797a1","modified":1548830812000},{"_id":"themes/next/source/css/_schemes/Mist/_logo.styl","hash":"38e5df90c8689a71c978fd83ba74af3d4e4e5386","modified":1548830812000},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expanded.styl","hash":"3b25edfa187d1bbbd0d38b50dd013cef54758abf","modified":1548830812000},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","hash":"b0dcca862cd0cc6e732e33d975b476d744911742","modified":1548830812000},{"_id":"themes/next/source/css/_schemes/Mist/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1548830812000},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","hash":"9a5581a770af8964064fef7afd3e16963e45547f","modified":1548830812000},{"_id":"themes/next/source/css/_schemes/Muse/_layout.styl","hash":"0efa036a15c18f5abb058b7c0fad1dd9ac5eed4c","modified":1548830812000},{"_id":"themes/next/source/css/_schemes/Muse/_logo.styl","hash":"8829bc556ca38bfec4add4f15a2f028092ac6d46","modified":1548830812000},{"_id":"themes/next/source/css/_schemes/Muse/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1548830812000},{"_id":"themes/next/source/css/_schemes/Muse/_menu.styl","hash":"4aac01962520d60b03b23022ab601ad4bd19c08c","modified":1548830812000},{"_id":"themes/next/source/css/_schemes/Muse/index.styl","hash":"a0e2030a606c934fb2c5c7373aaae04a1caac4c5","modified":1548830812000},{"_id":"themes/next/source/css/_schemes/Pisces/_menu.styl","hash":"215de948be49bcf14f06d500cef9f7035e406a43","modified":1548830812000},{"_id":"themes/next/source/css/_schemes/Pisces/_layout.styl","hash":"5b93958239d3d2bf9aeaede44eced2434d784462","modified":1548830812000},{"_id":"themes/next/source/css/_schemes/Pisces/_brand.styl","hash":"c4ed249798296f60bda02351fe6404fb3ef2126f","modified":1548830812000},{"_id":"themes/next/source/css/_schemes/Pisces/index.styl","hash":"69ecd6c97e7cdfd822ac8102b45ad0ede85050db","modified":1548830812000},{"_id":"themes/next/source/css/_schemes/Pisces/_sidebar.styl","hash":"9d16fa3c14ed76b71229f022b63a02fd0f580958","modified":1548830812000},{"_id":"themes/next/source/css/_schemes/Pisces/_posts.styl","hash":"2f878213cb24c5ddc18877f6d15ec5c5f57745ac","modified":1548830812000},{"_id":"themes/next/source/js/src/schemes/pisces.js","hash":"8050a5b2683d1d77238c5762b6bd89c543daed6e","modified":1548830813000},{"_id":"themes/next/source/lib/Han/dist/han.min.css","hash":"a0c9e32549a8b8cf327ab9227b037f323cdb60ee","modified":1548830813000},{"_id":"themes/next/source/lib/Han/dist/han.min.js","hash":"f559c68a25065a14f47da954a7617d87263e409d","modified":1548830813000},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1548830813000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1548830813000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1548830813000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1548830813000},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1548830813000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1548830813000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1548830813000},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1548830813000},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1548830813000},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1548830813000},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1548830813000},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1548830813000},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1548830813000},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1548830813000},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1548830813000},{"_id":"themes/next/layout/_third-party/search/algolia-search/dom.swig","hash":"ba698f49dd3a868c95b240d802f5b1b24ff287e4","modified":1548830812000},{"_id":"themes/next/layout/_third-party/search/algolia-search/assets.swig","hash":"28ff4ed6714c59124569ffcbd10f1173d53ca923","modified":1548830812000},{"_id":"themes/next/source/lib/Han/dist/han.css","hash":"bd40da3fba8735df5850956814e312bd7b3193d7","modified":1548830813000},{"_id":"themes/next/source/lib/Han/dist/han.js","hash":"e345397e0585c9fed1449e614ec13e0224acf2ab","modified":1548830813000},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1548830813000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1548830813000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1548830813000},{"_id":"themes/next/source/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1548830813000},{"_id":"themes/next/.git/logs/refs/remotes/origin/HEAD","hash":"8582611f24b301c7a614ce3f2172ef4c7ed45235","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/header/menu.styl","hash":"8a2421cb9005352905fae9d41a847ae56957247e","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/footer/footer.styl","hash":"7905a7f625702b45645d8be1268cb8af3f698c70","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/header/headerband.styl","hash":"d27448f199fc2f9980b601bc22b87f08b5d64dd1","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/header/header.styl","hash":"ae1ca14e51de67b07dba8f61ec79ee0e2e344574","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/header/site-meta.styl","hash":"6c00f6e0978f4d8f9a846a15579963728aaa6a17","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/header/site-nav.styl","hash":"49c2b2c14a1e7fcc810c6be4b632975d0204c281","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/pages/categories.styl","hash":"4eff5b252d7b614e500fc7d52c97ce325e57d3ab","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/pages/archive.styl","hash":"f5aa2ba3bfffc15475e7e72a55b5c9d18609fdf5","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/pages/pages.styl","hash":"2039590632bba3943c39319d80ef630af7928185","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/post/post-button.styl","hash":"e72a89e0f421444453e149ba32c77a64bd8e44e8","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/pages/post-detail.styl","hash":"9bf4362a4d0ae151ada84b219d39fbe5bb8c790e","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/pages/schedule.styl","hash":"a82afbb72d83ee394aedc7b37ac0008a9823b4f4","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/post/post-collapse.styl","hash":"0f7f522cc6bfb3401d5afd62b0fcdf48bb2d604b","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/post/post-copyright.styl","hash":"f54367c0feda6986c030cc4d15a0ca6ceea14bcb","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/post/post-eof.styl","hash":"2cdc094ecf907a02fce25ad4a607cd5c40da0f2b","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/post/post-expand.styl","hash":"535b3b4f8cb1eec2558e094320e7dfb01f94c0e7","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/post/post-nav.styl","hash":"a5d8617a24d7cb6c5ad91ea621183ca2c0917331","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/post/post-gallery.styl","hash":"387ce23bba52b22a586b2dfb4ec618fe1ffd3926","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/post/post-reward.styl","hash":"36332c8a91f089f545f3c3e8ea90d08aa4d6e60c","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/post/post-meta.styl","hash":"aea21141015ca8c409d8b33e3e34ec505f464e93","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/post/post-title.styl","hash":"d5a4e4fc17f1f7e7c3a61b52d8e2e9677e139de7","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/post/post-rtl.styl","hash":"017074ef58166e2d69c53bb7590a0e7a8947a1ed","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/post/post-tags.styl","hash":"a352ae5b1f8857393bf770d2e638bf15f0c9585d","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/post/post-widgets.styl","hash":"e4055a0d2cd2b0ad9dc55928e2f3e7bd4e499da3","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/post/post-type.styl","hash":"10251257aceecb117233c9554dcf8ecfef8e2104","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/post/post.styl","hash":"262debfd4442fa03d9919ceb88b948339df03fb0","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/highlight/diff.styl","hash":"96f32ea6c3265a3889e6abe57587f6e2a2a40dfb","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/highlight/highlight.styl","hash":"25dc25f61a232f03ca72472b7852f882448ec185","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/highlight/theme.styl","hash":"b76387934fb6bb75212b23c1a194486892cc495e","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author-links.styl","hash":"0a6c0efffdf18bddbc1d1238feaed282b09cd0fe","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-blogroll.styl","hash":"89dd4f8b1f1cce3ad46cf2256038472712387d02","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author.styl","hash":"920343e41c124221a17f050bbb989494d44f7a24","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-dimmer.styl","hash":"efa5e5022e205b52786ce495d4879f5e7b8f84b2","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-feed-link.styl","hash":"9486ddd2cb255227db102d09a7df4cae0fabad72","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toggle.styl","hash":"f7784aba0c1cd20d824c918c120012d57a5eaa2a","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-nav.styl","hash":"45fa7193435a8eae9960267438750b4c9fa9587f","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toc.styl","hash":"12937cae17c96c74d5c58db6cb29de3b2dfa14a2","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/sidebar/site-state.styl","hash":"3623e7fa4324ec1307370f33d8f287a9e20a5578","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar.styl","hash":"50305b6ad7d09d2ffa4854e39f41ec1f4fe984fd","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/tags/full-image.styl","hash":"37e951e734a252fe8a81f452b963df2ba90bfe90","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/tags/exturl.styl","hash":"1b3cc9f4e5a7f6e05b4100e9990b37b20d4a2005","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/tags/blockquote-center.styl","hash":"c2abe4d87148e23e15d49ee225bc650de60baf46","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/tags/group-pictures.styl","hash":"4851b981020c5cbc354a1af9b831a2dcb3cf9d39","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/tags/note-modern.styl","hash":"ee7528900578ef4753effe05b346381c40de5499","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/tags/label.styl","hash":"4a457d265d62f287c63d48764ce45d9bcfc9ec5a","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/tags/note.styl","hash":"32c9156bea5bac9e9ad0b4c08ffbca8b3d9aac4b","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/tags/tabs.styl","hash":"4ab5deed8c3b0c338212380f678f8382672e1bcb","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/tags/tags.styl","hash":"ead0d0f2321dc71505788c7f689f92257cf14947","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/third-party/algolia-search.styl","hash":"fd42777b9125fd8969dc39d4f15473e2b91b4142","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/third-party/baidushare.styl","hash":"93b08815c4d17e2b96fef8530ec1f1064dede6ef","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/third-party/duoshuo.styl","hash":"2340dd9b3202c61d73cc708b790fac5adddbfc7f","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/third-party/busuanzi-counter.styl","hash":"d4e6d8d7b34dc69994593c208f875ae8f7e8a3ae","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/third-party/han.styl","hash":"cce6772e2cdb4db85d35486ae4c6c59367fbdd40","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/third-party/gitment.styl","hash":"34935b40237c074be5f5e8818c14ccfd802b7439","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/third-party/jiathis.styl","hash":"327b5f63d55ec26f7663185c1a778440588d9803","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/third-party/localsearch.styl","hash":"d89c4b562b528e4746696b2ad8935764d133bdae","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/third-party/third-party.styl","hash":"1ccfbd4d0f5754b2dc2719a91245c95f547a7652","modified":1548830812000},{"_id":"themes/next/source/css/_common/components/third-party/needsharebutton.styl","hash":"a5e3e6b4b4b814a9fe40b34d784fed67d6d977fa","modified":1548830812000},{"_id":"themes/next/source/css/_schemes/Mist/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1548830812000},{"_id":"themes/next/source/css/_schemes/Mist/outline/outline.styl","hash":"5dc4859c66305f871e56cba78f64bfe3bf1b5f01","modified":1548830812000},{"_id":"themes/next/source/css/_schemes/Muse/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1548830812000},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","hash":"7a635062b10bf5662ae1d218ba0980171005d060","modified":1548830813000},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","hash":"07436f011b44051f61b8329c99de4bec64e86f4b","modified":1548830813000},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","hash":"f38ff9b2eecaa17b50b66aa2dae87e9e7436d195","modified":1548830813000},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","hash":"f1f6bb8f461f5672e000380195d3d2358a28494c","modified":1548830813000},{"_id":"themes/next/source/lib/Han/dist/font/han.woff2","hash":"623af3ed5423371ac136a4fe0e8cc7bb7396037a","modified":1548830813000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1548830813000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1548830813000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1548830813000},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1548830813000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1548830813000},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1548830813000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1548830813000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1548830813000},{"_id":"themes/next/.git/objects/pack/pack-2e8bfe0bbc40ee78847e36e8d3edd701735c6f4e.idx","hash":"50fb014b44992cfb2c56176f1defd1be870f96b9","modified":1548830812000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1548830813000},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1548830813000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1548830813000},{"_id":"themes/next/source/lib/three/three.min.js","hash":"73f4cdc17e51a72b9bf5b9291f65386d615c483b","modified":1548830813000},{"_id":"themes/next/.git/objects/pack/pack-2e8bfe0bbc40ee78847e36e8d3edd701735c6f4e.pack","hash":"85a7403d5a07a998880356d55082d480ab60cff4","modified":1548830812000},{"_id":"public/baidusitemap.xml","hash":"16f0d4db602f5e9f99136d15f062c92addebb27b","modified":1550480297257},{"_id":"public/sitemap.xml","hash":"12d4ab51bc21662a77e7be5e2371328f0e1244a6","modified":1550482333134},{"_id":"public/archives/index.html","hash":"cdc18b2b912e93b05b9e92439c2d34000ef9dd02","modified":1550480297487},{"_id":"public/about/index.html","hash":"9e15abcbd97f9efa1b3a16b042fac684cb7929b9","modified":1550480297487},{"_id":"public/categories/index.html","hash":"f3913e00416404174998c754a3fe5237e6e64e54","modified":1550480297489},{"_id":"public/tags/index.html","hash":"e11c2fc622879e133a67c4bca0b0d906c26354fe","modified":1550480297489},{"_id":"public/archives/2019/index.html","hash":"b3c936164e44126795b27c27aa52cd50add3689a","modified":1550480297489},{"_id":"public/archives/2019/01/index.html","hash":"f85643a052cb64ee855c7222a0f152066264a426","modified":1550480297489},{"_id":"public/tags/Hexo/index.html","hash":"a6efc38b3dce0b74bad34aed9d68a7981984c459","modified":1550480297489},{"_id":"public/tags/机器学习/index.html","hash":"33b44d3ca1cd512374ec9ce05d7ad1fb1b986058","modified":1550480297489},{"_id":"public/tags/工程/index.html","hash":"9c0062ff5ad4cfb5e06a7b926a954b425993e820","modified":1550480297489},{"_id":"public/tags/数据科学/index.html","hash":"36c493970b4b09b5886019c8e6ebcdf57455b3a4","modified":1550480297489},{"_id":"public/categories/数据科学/index.html","hash":"946ef87cee40712c98c7bce98cce04030cc4de19","modified":1550480297489},{"_id":"public/categories/机器学习/index.html","hash":"d123763df79c078745c851c2d6d6385aedbdd9f3","modified":1550480297489},{"_id":"public/categories/前端/index.html","hash":"cc159388d0eeceb808bc2891627a039e17103cd0","modified":1550480297489},{"_id":"public/2019/01/31/机器学习中常用优化算法总结/index.html","hash":"18176d296091e97b4e5e9e1efe892139b10ea7d0","modified":1550480297490},{"_id":"public/2019/01/30/使用hexo+github搭建个人博客/index.html","hash":"3657a2488832a0c88d4b5062a30216bb386084c4","modified":1550480297490},{"_id":"public/2019/01/30/机器学习概论/index.html","hash":"c8acdb51edc520e09aef60cb28c8de71fcc7a1f0","modified":1550480297490},{"_id":"public/index.html","hash":"2f04a7714c3596c0fd9b752aa3c9be1403a72da0","modified":1550482334122},{"_id":"public/2019/01/31/基于docker-cookiercutter创建data-science项目/index.html","hash":"53873b73aa9f46dd179f4d870cce1b59d37970ac","modified":1550480297490},{"_id":"public/archives/2019/02/index.html","hash":"f0b2a68c6e68e729615f8e6ac0048706410d7c47","modified":1550480297494},{"_id":"public/tags/kubernetes/index.html","hash":"eedcc5448858f9451d8ea51ae2249f7b56bf180a","modified":1550480297494},{"_id":"public/categories/大数据/index.html","hash":"8ec0625c820ed6e7c20f38423dd27bf216c3d309","modified":1550480297495},{"_id":"public/2019/02/18/kubeadm1-13创建HAkubernetes集群/index.html","hash":"006d23ab4cee2990b8c22ac0afee48f4cd4e45c7","modified":1550482334122},{"_id":"public/images/1548834369938.jpg","hash":"3799e07d0109342b9e9b49f6183bc0f1e489261e","modified":1550480297495},{"_id":"public/robots.txt","hash":"52b9410c2e5c1f83126794ad0de43c31eaaf6d82","modified":1550480297495},{"_id":"public/images/gradient_ill.jpg","hash":"8cdb034b659a1edae672defd02239fa1ad6489ce","modified":1550480297495},{"_id":"public/images/mse_ill.jpg","hash":"0fc67787a50394c709d1bee5ecaffe471f2d998b","modified":1550480297495},{"_id":"public/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1550480297495},{"_id":"public/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1550480297495},{"_id":"public/images/algolia_logo.svg","hash":"ec119560b382b2624e00144ae01c137186e91621","modified":1550480297495},{"_id":"public/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1550480297495},{"_id":"public/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1550480297495},{"_id":"public/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1550480297495},{"_id":"public/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1550480297495},{"_id":"public/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1550480297495},{"_id":"public/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1550480297495},{"_id":"public/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1550480297495},{"_id":"public/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1550480297495},{"_id":"public/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1550480297495},{"_id":"public/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1550480297495},{"_id":"public/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1550480297495},{"_id":"public/images/logo.svg","hash":"d29cacbae1bdc4bbccb542107ee0524fe55ad6de","modified":1550480297495},{"_id":"public/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1550480297495},{"_id":"public/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1550480297495},{"_id":"public/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1550480297495},{"_id":"public/lib/fastclick/LICENSE","hash":"dcd5b6b43095d9e90353a28b09cb269de8d4838e","modified":1550480297934},{"_id":"public/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1550480297934},{"_id":"public/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1550480297934},{"_id":"public/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1550480297935},{"_id":"public/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1550480297935},{"_id":"public/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1550480297935},{"_id":"public/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1550480297935},{"_id":"public/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1550480297935},{"_id":"public/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1550480297935},{"_id":"public/lib/Han/dist/font/han-space.woff","hash":"7a635062b10bf5662ae1d218ba0980171005d060","modified":1550480297935},{"_id":"public/lib/Han/dist/font/han.woff","hash":"f38ff9b2eecaa17b50b66aa2dae87e9e7436d195","modified":1550480297935},{"_id":"public/lib/Han/dist/font/han-space.otf","hash":"07436f011b44051f61b8329c99de4bec64e86f4b","modified":1550480297935},{"_id":"public/lib/Han/dist/font/han.otf","hash":"f1f6bb8f461f5672e000380195d3d2358a28494c","modified":1550480297935},{"_id":"public/lib/Han/dist/font/han.woff2","hash":"623af3ed5423371ac136a4fe0e8cc7bb7396037a","modified":1550480297935},{"_id":"public/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1550480297935},{"_id":"public/css/main.css","hash":"59548965d516879b2421fe804fd223c69ca7e198","modified":1550480297957},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1550480297960},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1550480297961},{"_id":"public/js/src/exturl.js","hash":"e42e2aaab7bf4c19a0c8e779140e079c6aa5c0b1","modified":1550480297966},{"_id":"public/js/src/bootstrap.js","hash":"034bc8113e0966fe2096ba5b56061bbf10ef0512","modified":1550480297966},{"_id":"public/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1550480297967},{"_id":"public/js/src/algolia-search.js","hash":"b172f697ed339a24b1e80261075232978d164c35","modified":1550480297967},{"_id":"public/js/src/js.cookie.js","hash":"9b37973a90fd50e71ea91682265715e45ae82c75","modified":1550480297967},{"_id":"public/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1550480297967},{"_id":"public/js/src/post-details.js","hash":"a13f45f7aa8291cf7244ec5ba93907d119c5dbdd","modified":1550480297967},{"_id":"public/js/src/scroll-cookie.js","hash":"09dc828cbf5f31158ff6250d2bf7c3cde6365c67","modified":1550480297967},{"_id":"public/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1550480297967},{"_id":"public/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1550480297967},{"_id":"public/lib/font-awesome/bower.json","hash":"64394a2a9aa00f8e321d8daa5e51a420f0e96dad","modified":1550480297967},{"_id":"public/lib/canvas-ribbon/canvas-ribbon.js","hash":"ff5915eb2596e890a2fc6697c864f861a1995ec0","modified":1550480297967},{"_id":"public/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1550480297967},{"_id":"public/lib/fastclick/bower.json","hash":"4dcecf83afddba148464d5339c93f6d0aa9f42e9","modified":1550480297967},{"_id":"public/lib/jquery_lazyload/bower.json","hash":"ae3c3b61e6e7f9e1d7e3585ad854380ecc04cf53","modified":1550480297967},{"_id":"public/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1550480297967},{"_id":"public/lib/pace/pace-theme-barber-shop.min.css","hash":"ee0d51446cb4ffe1bb96bd7bc8c8e046dddfcf46","modified":1550480297967},{"_id":"public/lib/pace/pace-theme-big-counter.min.css","hash":"5b561dc328af4c4d512e20a76fe964d113a32ba8","modified":1550480297967},{"_id":"public/lib/needsharebutton/needsharebutton.css","hash":"3ef0020a1815ca6151ea4886cd0d37421ae3695c","modified":1550480297967},{"_id":"public/lib/pace/pace-theme-center-circle.min.css","hash":"a4066769c78affbfbc5e30a600e2c7862cd532e0","modified":1550480297967},{"_id":"public/lib/pace/pace-theme-bounce.min.css","hash":"f6bdb9a785b7979dd8ec5c60e278af955ef1e585","modified":1550480297967},{"_id":"public/lib/pace/pace-theme-center-atom.min.css","hash":"dcf79c24fe5350fb73d8038573a104e73639e9d3","modified":1550480297967},{"_id":"public/lib/pace/pace-theme-center-radar.min.css","hash":"ab7cba998bf4c03b13df342bf43647fa4f419783","modified":1550480297967},{"_id":"public/lib/pace/pace-theme-corner-indicator.min.css","hash":"b3c64c973f31884e3d8145989476707333406b9a","modified":1550480297967},{"_id":"public/lib/pace/pace-theme-fill-left.min.css","hash":"0bec1e235a4a2cccda3f993b205424e1441a44ae","modified":1550480297968},{"_id":"public/lib/pace/pace-theme-center-simple.min.css","hash":"67f44c947548bd4d77e7590d3f59e236cbf9e98a","modified":1550480297968},{"_id":"public/lib/pace/pace-theme-flash.min.css","hash":"13ace22c40312d7bbd8d9c1e50eff897a7a497d8","modified":1550480297968},{"_id":"public/lib/pace/pace-theme-minimal.min.css","hash":"9cd783cceb8a191f3c8b5d81f7a430ecc3e489d3","modified":1550480297968},{"_id":"public/lib/pace/pace-theme-mac-osx.min.css","hash":"9f2e7b51b084da407863826b25265b31150b3821","modified":1550480297968},{"_id":"public/lib/velocity/bower.json","hash":"0ef14e7ccdfba5db6eb3f8fc6aa3b47282c36409","modified":1550480297968},{"_id":"public/js/src/schemes/pisces.js","hash":"8050a5b2683d1d77238c5762b6bd89c543daed6e","modified":1550480297968},{"_id":"public/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1550480297968},{"_id":"public/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1550480297968},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1550480297968},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1550480297968},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1550480297968},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1550480297968},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1550480297968},{"_id":"public/lib/fastclick/README.html","hash":"da3c74d484c73cc7df565e8abbfa4d6a5a18d4da","modified":1550480297969},{"_id":"public/lib/jquery_lazyload/README.html","hash":"bde24335f6bc09d8801c0dcd7274f71b466552bd","modified":1550480297969},{"_id":"public/lib/jquery_lazyload/CONTRIBUTING.html","hash":"a6358170d346af13b1452ac157b60505bec7015c","modified":1550480297969},{"_id":"public/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1550480297969},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1550480297969},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1550480297969},{"_id":"public/js/src/motion.js","hash":"754b294394f102c8fd9423a1789ddb1201677898","modified":1550480297972},{"_id":"public/js/src/utils.js","hash":"9b1325801d27213083d1487a12b1a62b539ab6f8","modified":1550480297972},{"_id":"public/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1550480297972},{"_id":"public/lib/pace/pace-theme-loading-bar.min.css","hash":"7ee28875dfc1230d76c537f6605766e8d4011e9f","modified":1550480297972},{"_id":"public/lib/pace/pace.min.js","hash":"9944dfb7814b911090e96446cea4d36e2b487234","modified":1550480297972},{"_id":"public/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1550480297972},{"_id":"public/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1550480297972},{"_id":"public/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1550480297972},{"_id":"public/lib/needsharebutton/needsharebutton.js","hash":"9885fd9bea5e7ebafc5b1de9d17be5e106248d96","modified":1550480297976},{"_id":"public/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1550480297977},{"_id":"public/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1550480297979},{"_id":"public/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1550480297979},{"_id":"public/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1550480297984},{"_id":"public/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1550480297984},{"_id":"public/lib/three/canvas_lines.min.js","hash":"dce4a3b65f8bf958f973690caa7ec4952f353b0c","modified":1550480297984},{"_id":"public/lib/three/canvas_sphere.min.js","hash":"d8ea241a53c135a650f7335d2b6982b899fd58a9","modified":1550480297985},{"_id":"public/lib/three/three-waves.min.js","hash":"d968cba6b3a50b3626a02d67b544f349d83b147c","modified":1550480297985},{"_id":"public/lib/Han/dist/han.min.js","hash":"f559c68a25065a14f47da954a7617d87263e409d","modified":1550480297985},{"_id":"public/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1550480297985},{"_id":"public/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1550480297986},{"_id":"public/lib/Han/dist/han.min.css","hash":"a0c9e32549a8b8cf327ab9227b037f323cdb60ee","modified":1550480297986},{"_id":"public/lib/needsharebutton/font-embedded.css","hash":"c39d37278c1e178838732af21bd26cd0baeddfe0","modified":1550480297987},{"_id":"public/lib/Han/dist/han.css","hash":"bd40da3fba8735df5850956814e312bd7b3193d7","modified":1550480297987},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1550480297987},{"_id":"public/lib/Han/dist/han.js","hash":"e345397e0585c9fed1449e614ec13e0224acf2ab","modified":1550480297990},{"_id":"public/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1550480297990},{"_id":"public/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1550480297992},{"_id":"public/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1550480297998},{"_id":"public/lib/three/three.min.js","hash":"73f4cdc17e51a72b9bf5b9291f65386d615c483b","modified":1550480298000},{"_id":"source/images/dashboard-login.png","hash":"a4b9d86f4e01c61d1b5435f46aa3a0717d821c8f","modified":1550481179000},{"_id":"public/images/dashboard-login.png","hash":"a4b9d86f4e01c61d1b5435f46aa3a0717d821c8f","modified":1550482334124}],"Category":[{"name":"数据科学","_id":"cjsa3xoyf00023lxyz6pnos28"},{"name":"前端","_id":"cjsa3xoyi00053lxy4jzbqbmv"},{"name":"机器学习","_id":"cjsa3xoyj00083lxywsk38d4z"},{"name":"大数据","_id":"cjsa3xp5r000p3lxy4lhqztgr"}],"Data":[],"Page":[{"title":"about","date":"2019-01-30T07:02:41.000Z","type":"archives","_content":"","source":"about/index.md","raw":"---\ntitle: about\ndate: 2019-01-30 15:02:41\ntype: \"archives\"\n---\n","updated":"2019-01-30T07:25:32.000Z","path":"about/index.html","comments":1,"layout":"page","_id":"cjsa3xp2t000h3lxyzwjrrmta","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"archives","date":"2019-01-30T07:02:33.000Z","type":"archives","_content":"","source":"archives/index.md","raw":"---\ntitle: archives\ndate: 2019-01-30 15:02:33\ntype: \"archives\"\n---\n","updated":"2019-01-30T07:25:21.000Z","path":"archives/index.html","comments":1,"layout":"page","_id":"cjsa3xp2u000i3lxy7ysbfyf1","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"categories","date":"2019-01-30T06:57:39.000Z","type":"categories","_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2019-01-30 14:57:39\ntype: \"categories\"\n---\n","updated":"2019-01-30T06:58:50.000Z","path":"categories/index.html","comments":1,"layout":"page","_id":"cjsa3xp2w000j3lxyfwno9zmr","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"tags","date":"2019-01-30T07:02:24.000Z","type":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2019-01-30 15:02:24\ntype: \"tags\"\n---\n","updated":"2019-01-30T07:25:04.000Z","path":"tags/index.html","comments":1,"layout":"page","_id":"cjsa3xp2y000k3lxygj642ctx","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"基于docker-cookiercutter创建data-science项目","date":"2019-01-31T11:52:04.000Z","_content":"\n## github地址\n\n```\nhttps://github.com/manifoldai/docker-cookiecutter-data-science\n```\n\n## 使用方案\n\n```\n<!--安装cookiecutter-->\npip install cookiecutter\n\n<!--创建项目-->\ncookiecutter https://github.com/manifoldai/docker-cookiecutter-data-science.git\n<!--后续步骤根据提示一步一步来操作即可-->\n\n<!--启动-->\n./start.sh\n\n<!--启动pycharm-->\ncharm .\n```\n\n\n## 项目的目录结构解释解释如下\n\n```\n├── LICENSE\n├── Dockerfile            <- New project Dockerfile that sources from base ML dev image\n├── docker-compose.yml    <- Docker Compose configuration file\n├── docker_clean_all.sh   <- Helper script to remove all containers and images from your system\n├── start.sh              <- Script to run docker compose and any other project specific initialization steps \n├── Makefile              <- Makefile with commands like `make data` or `make train`\n├── README.md             <- The top-level README for developers using this project.\n├── data\n│   ├── external          <- Data from third party sources.\n│   ├── interim           <- Intermediate data that has been transformed.\n│   ├── processed         <- The final, canonical data sets for modeling.\n│   └── raw               <- The original, immutable data dump.\n│\n├── docs                  <- A default Sphinx project; see sphinx-doc.org for details\n│\n├── models                <- Trained and serialized models, model predictions, or model summaries\n│\n├── notebooks             <- Jupyter notebooks. Naming convention is a number (for ordering),\n│                            the creator's initials, and a short `-` delimited description, e.g.\n│                            `1.0-jqp-initial-data-exploration`.\n│\n├── references            <- Data dictionaries, manuals, and all other explanatory materials.\n│\n├── reports               <- Generated analysis as HTML, PDF, LaTeX, etc.\n│   └── figures           <- Generated graphics and figures to be used in reporting\n│\n├── requirements.txt      <- The requirements file for reproducing the analysis environment, e.g.\n│                            generated with `pip freeze > requirements.txt`\n│\n├── src                   <- Source code for use in this project.\n│   ├── __init__.py       <- Makes src a Python module\n│   │\n│   ├── data              <- Scripts to download or generate data\n│   │   └── make_dataset.py\n│   │\n│   ├── features          <- Scripts to turn raw data into features for modeling\n│   │   └── build_features.py\n│   │\n│   ├── models            <- Scripts to train models and then use trained models to make\n│   │   │                    predictions\n│   │   ├── predict_model.py\n│   │   └── train_model.py\n│   │\n│   └── visualization  <- Scripts to create exploratory and results oriented visualizations\n│       └── visualize.py\n│\n└── tox.ini            <- tox file with settings for running tox; see tox.testrun.org\n```\n\n\n\n","source":"_posts/基于docker-cookiercutter创建data-science项目.md","raw":"---\ntitle: 基于docker-cookiercutter创建data-science项目\ndate: 2019-01-31 19:52:04\ntags:\n  - 数据科学\n  - 工程\ncategories: 数据科学\n---\n\n## github地址\n\n```\nhttps://github.com/manifoldai/docker-cookiecutter-data-science\n```\n\n## 使用方案\n\n```\n<!--安装cookiecutter-->\npip install cookiecutter\n\n<!--创建项目-->\ncookiecutter https://github.com/manifoldai/docker-cookiecutter-data-science.git\n<!--后续步骤根据提示一步一步来操作即可-->\n\n<!--启动-->\n./start.sh\n\n<!--启动pycharm-->\ncharm .\n```\n\n\n## 项目的目录结构解释解释如下\n\n```\n├── LICENSE\n├── Dockerfile            <- New project Dockerfile that sources from base ML dev image\n├── docker-compose.yml    <- Docker Compose configuration file\n├── docker_clean_all.sh   <- Helper script to remove all containers and images from your system\n├── start.sh              <- Script to run docker compose and any other project specific initialization steps \n├── Makefile              <- Makefile with commands like `make data` or `make train`\n├── README.md             <- The top-level README for developers using this project.\n├── data\n│   ├── external          <- Data from third party sources.\n│   ├── interim           <- Intermediate data that has been transformed.\n│   ├── processed         <- The final, canonical data sets for modeling.\n│   └── raw               <- The original, immutable data dump.\n│\n├── docs                  <- A default Sphinx project; see sphinx-doc.org for details\n│\n├── models                <- Trained and serialized models, model predictions, or model summaries\n│\n├── notebooks             <- Jupyter notebooks. Naming convention is a number (for ordering),\n│                            the creator's initials, and a short `-` delimited description, e.g.\n│                            `1.0-jqp-initial-data-exploration`.\n│\n├── references            <- Data dictionaries, manuals, and all other explanatory materials.\n│\n├── reports               <- Generated analysis as HTML, PDF, LaTeX, etc.\n│   └── figures           <- Generated graphics and figures to be used in reporting\n│\n├── requirements.txt      <- The requirements file for reproducing the analysis environment, e.g.\n│                            generated with `pip freeze > requirements.txt`\n│\n├── src                   <- Source code for use in this project.\n│   ├── __init__.py       <- Makes src a Python module\n│   │\n│   ├── data              <- Scripts to download or generate data\n│   │   └── make_dataset.py\n│   │\n│   ├── features          <- Scripts to turn raw data into features for modeling\n│   │   └── build_features.py\n│   │\n│   ├── models            <- Scripts to train models and then use trained models to make\n│   │   │                    predictions\n│   │   ├── predict_model.py\n│   │   └── train_model.py\n│   │\n│   └── visualization  <- Scripts to create exploratory and results oriented visualizations\n│       └── visualize.py\n│\n└── tox.ini            <- tox file with settings for running tox; see tox.testrun.org\n```\n\n\n\n","slug":"基于docker-cookiercutter创建data-science项目","published":1,"updated":"2019-01-31T11:54:12.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjsa3xoy900003lxyw07gp0rj","content":"<h2 id=\"github地址\"><a href=\"#github地址\" class=\"headerlink\" title=\"github地址\"></a>github地址</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">https://github.com/manifoldai/docker-cookiecutter-data-science</span><br></pre></td></tr></table></figure>\n<h2 id=\"使用方案\"><a href=\"#使用方案\" class=\"headerlink\" title=\"使用方案\"></a>使用方案</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;!--安装cookiecutter--&gt;</span><br><span class=\"line\">pip install cookiecutter</span><br><span class=\"line\"></span><br><span class=\"line\">&lt;!--创建项目--&gt;</span><br><span class=\"line\">cookiecutter https://github.com/manifoldai/docker-cookiecutter-data-science.git</span><br><span class=\"line\">&lt;!--后续步骤根据提示一步一步来操作即可--&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">&lt;!--启动--&gt;</span><br><span class=\"line\">./start.sh</span><br><span class=\"line\"></span><br><span class=\"line\">&lt;!--启动pycharm--&gt;</span><br><span class=\"line\">charm .</span><br></pre></td></tr></table></figure>\n<h2 id=\"项目的目录结构解释解释如下\"><a href=\"#项目的目录结构解释解释如下\" class=\"headerlink\" title=\"项目的目录结构解释解释如下\"></a>项目的目录结构解释解释如下</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">├── LICENSE</span><br><span class=\"line\">├── Dockerfile            &lt;- New project Dockerfile that sources from base ML dev image</span><br><span class=\"line\">├── docker-compose.yml    &lt;- Docker Compose configuration file</span><br><span class=\"line\">├── docker_clean_all.sh   &lt;- Helper script to remove all containers and images from your system</span><br><span class=\"line\">├── start.sh              &lt;- Script to run docker compose and any other project specific initialization steps </span><br><span class=\"line\">├── Makefile              &lt;- Makefile with commands like `make data` or `make train`</span><br><span class=\"line\">├── README.md             &lt;- The top-level README for developers using this project.</span><br><span class=\"line\">├── data</span><br><span class=\"line\">│   ├── external          &lt;- Data from third party sources.</span><br><span class=\"line\">│   ├── interim           &lt;- Intermediate data that has been transformed.</span><br><span class=\"line\">│   ├── processed         &lt;- The final, canonical data sets for modeling.</span><br><span class=\"line\">│   └── raw               &lt;- The original, immutable data dump.</span><br><span class=\"line\">│</span><br><span class=\"line\">├── docs                  &lt;- A default Sphinx project; see sphinx-doc.org for details</span><br><span class=\"line\">│</span><br><span class=\"line\">├── models                &lt;- Trained and serialized models, model predictions, or model summaries</span><br><span class=\"line\">│</span><br><span class=\"line\">├── notebooks             &lt;- Jupyter notebooks. Naming convention is a number (for ordering),</span><br><span class=\"line\">│                            the creator&apos;s initials, and a short `-` delimited description, e.g.</span><br><span class=\"line\">│                            `1.0-jqp-initial-data-exploration`.</span><br><span class=\"line\">│</span><br><span class=\"line\">├── references            &lt;- Data dictionaries, manuals, and all other explanatory materials.</span><br><span class=\"line\">│</span><br><span class=\"line\">├── reports               &lt;- Generated analysis as HTML, PDF, LaTeX, etc.</span><br><span class=\"line\">│   └── figures           &lt;- Generated graphics and figures to be used in reporting</span><br><span class=\"line\">│</span><br><span class=\"line\">├── requirements.txt      &lt;- The requirements file for reproducing the analysis environment, e.g.</span><br><span class=\"line\">│                            generated with `pip freeze &gt; requirements.txt`</span><br><span class=\"line\">│</span><br><span class=\"line\">├── src                   &lt;- Source code for use in this project.</span><br><span class=\"line\">│   ├── __init__.py       &lt;- Makes src a Python module</span><br><span class=\"line\">│   │</span><br><span class=\"line\">│   ├── data              &lt;- Scripts to download or generate data</span><br><span class=\"line\">│   │   └── make_dataset.py</span><br><span class=\"line\">│   │</span><br><span class=\"line\">│   ├── features          &lt;- Scripts to turn raw data into features for modeling</span><br><span class=\"line\">│   │   └── build_features.py</span><br><span class=\"line\">│   │</span><br><span class=\"line\">│   ├── models            &lt;- Scripts to train models and then use trained models to make</span><br><span class=\"line\">│   │   │                    predictions</span><br><span class=\"line\">│   │   ├── predict_model.py</span><br><span class=\"line\">│   │   └── train_model.py</span><br><span class=\"line\">│   │</span><br><span class=\"line\">│   └── visualization  &lt;- Scripts to create exploratory and results oriented visualizations</span><br><span class=\"line\">│       └── visualize.py</span><br><span class=\"line\">│</span><br><span class=\"line\">└── tox.ini            &lt;- tox file with settings for running tox; see tox.testrun.org</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"github地址\"><a href=\"#github地址\" class=\"headerlink\" title=\"github地址\"></a>github地址</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">https://github.com/manifoldai/docker-cookiecutter-data-science</span><br></pre></td></tr></table></figure>\n<h2 id=\"使用方案\"><a href=\"#使用方案\" class=\"headerlink\" title=\"使用方案\"></a>使用方案</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;!--安装cookiecutter--&gt;</span><br><span class=\"line\">pip install cookiecutter</span><br><span class=\"line\"></span><br><span class=\"line\">&lt;!--创建项目--&gt;</span><br><span class=\"line\">cookiecutter https://github.com/manifoldai/docker-cookiecutter-data-science.git</span><br><span class=\"line\">&lt;!--后续步骤根据提示一步一步来操作即可--&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">&lt;!--启动--&gt;</span><br><span class=\"line\">./start.sh</span><br><span class=\"line\"></span><br><span class=\"line\">&lt;!--启动pycharm--&gt;</span><br><span class=\"line\">charm .</span><br></pre></td></tr></table></figure>\n<h2 id=\"项目的目录结构解释解释如下\"><a href=\"#项目的目录结构解释解释如下\" class=\"headerlink\" title=\"项目的目录结构解释解释如下\"></a>项目的目录结构解释解释如下</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">├── LICENSE</span><br><span class=\"line\">├── Dockerfile            &lt;- New project Dockerfile that sources from base ML dev image</span><br><span class=\"line\">├── docker-compose.yml    &lt;- Docker Compose configuration file</span><br><span class=\"line\">├── docker_clean_all.sh   &lt;- Helper script to remove all containers and images from your system</span><br><span class=\"line\">├── start.sh              &lt;- Script to run docker compose and any other project specific initialization steps </span><br><span class=\"line\">├── Makefile              &lt;- Makefile with commands like `make data` or `make train`</span><br><span class=\"line\">├── README.md             &lt;- The top-level README for developers using this project.</span><br><span class=\"line\">├── data</span><br><span class=\"line\">│   ├── external          &lt;- Data from third party sources.</span><br><span class=\"line\">│   ├── interim           &lt;- Intermediate data that has been transformed.</span><br><span class=\"line\">│   ├── processed         &lt;- The final, canonical data sets for modeling.</span><br><span class=\"line\">│   └── raw               &lt;- The original, immutable data dump.</span><br><span class=\"line\">│</span><br><span class=\"line\">├── docs                  &lt;- A default Sphinx project; see sphinx-doc.org for details</span><br><span class=\"line\">│</span><br><span class=\"line\">├── models                &lt;- Trained and serialized models, model predictions, or model summaries</span><br><span class=\"line\">│</span><br><span class=\"line\">├── notebooks             &lt;- Jupyter notebooks. Naming convention is a number (for ordering),</span><br><span class=\"line\">│                            the creator&apos;s initials, and a short `-` delimited description, e.g.</span><br><span class=\"line\">│                            `1.0-jqp-initial-data-exploration`.</span><br><span class=\"line\">│</span><br><span class=\"line\">├── references            &lt;- Data dictionaries, manuals, and all other explanatory materials.</span><br><span class=\"line\">│</span><br><span class=\"line\">├── reports               &lt;- Generated analysis as HTML, PDF, LaTeX, etc.</span><br><span class=\"line\">│   └── figures           &lt;- Generated graphics and figures to be used in reporting</span><br><span class=\"line\">│</span><br><span class=\"line\">├── requirements.txt      &lt;- The requirements file for reproducing the analysis environment, e.g.</span><br><span class=\"line\">│                            generated with `pip freeze &gt; requirements.txt`</span><br><span class=\"line\">│</span><br><span class=\"line\">├── src                   &lt;- Source code for use in this project.</span><br><span class=\"line\">│   ├── __init__.py       &lt;- Makes src a Python module</span><br><span class=\"line\">│   │</span><br><span class=\"line\">│   ├── data              &lt;- Scripts to download or generate data</span><br><span class=\"line\">│   │   └── make_dataset.py</span><br><span class=\"line\">│   │</span><br><span class=\"line\">│   ├── features          &lt;- Scripts to turn raw data into features for modeling</span><br><span class=\"line\">│   │   └── build_features.py</span><br><span class=\"line\">│   │</span><br><span class=\"line\">│   ├── models            &lt;- Scripts to train models and then use trained models to make</span><br><span class=\"line\">│   │   │                    predictions</span><br><span class=\"line\">│   │   ├── predict_model.py</span><br><span class=\"line\">│   │   └── train_model.py</span><br><span class=\"line\">│   │</span><br><span class=\"line\">│   └── visualization  &lt;- Scripts to create exploratory and results oriented visualizations</span><br><span class=\"line\">│       └── visualize.py</span><br><span class=\"line\">│</span><br><span class=\"line\">└── tox.ini            &lt;- tox file with settings for running tox; see tox.testrun.org</span><br></pre></td></tr></table></figure>\n"},{"title":"使用hexo+github搭建个人博客","_content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## 创建GitHub仓库\n1. 登录https://github.com/\n2. 注册账号\n3. 创建一个新Repositorie(仓库名必须要为以下格式：**xxx.github.io**，其中，xxx为用户名小写)\n## hexo部署\n### 什么是hexo?\nhexo是一个简单但强大的博客系统，Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。\n### 部署\n1. 安装node.js\n```\n<!--MacOS-->\n<!--安装了node之后，默认也会安装npm-->\nbrew install node\n```\n2. 安装hexo\n```\nnpm install hexo-cli\n```\n3.创建本地项目\n```\nhexo init xxx.github.io\ncd xxx.github.io\n<!--修改项目配置文件中的deploy配置-->\n\tdeploy:\n\t  type: git\n  repo: https://github.com/HsiaChubby/hsiachubby.github.io.git,master\n```\n<!-- more -->\n## 修改配置\n### 设置主题\n1. 下载next主题\n```\ngit clone https://github.com/iissnan/hexo-theme-next themes/next\n```\n2. 配置项目的主题\n打开项目配置文件_config.yml，设置theme如下：\n```\n# Extensions\n## Plugins: https://hexo.io/plugins/\n## Themes: https://hexo.io/themes/\ntheme: next\n```\n3. 配置主站相关信息\n打开项目配置文件_config.yml，设置基础如下:\n```\n# Site\ntitle: Chubby的博客\nsubtitle:\ndescription:\nkeywords:\nauthor: Chubby Hsia\nlanguage: zh-Hans\ntimezone:\n```\n4. 配置首页支持分类、标签、关于、归档\n分别运行一下命令\n```\n<!--创建分类页面-->\nhexo new page categories\n<!--创建标签页面-->\nhexo new page tags\n<!--创建归档页面-->\nhexo new page archives\n<!--创建关于页面-->\nhexo new page about\n```\n创建好上述页面后，会在source目录下，分别生成categories/tags/archives/about四个文件夹，然后分别进入相应的文件夹中，修改各自的index.md文件，如下：\n```\n<!--categories的index.md-->\n---\ntitle: categories\ndate: 2019-01-30 14:57:39\ntype: \"categories\"\n---\n<!--tags的index.md-->\n---\ntitle: tags\ndate: 2019-01-30 15:02:24\ntype: \"tags\"\n---\n<!--archives的index.md-->\ntitle: archives\ndate: 2019-01-30 15:02:33\ntype: \"archives\"\n---\n<!--about的index.md-->\n---\ntitle: about\ndate: 2019-01-30 15:02:41\ntype: \"archives\"\n---\n```\n然后，进入theme/next主题下，打开主题的配置文件_config.yml，修改menu配置，如下：\n```\nmenu:\n  home: / || home\n  about: /about/ || user\n  tags: /tags/ || tags\n  categories: /categories/ || th\n  archives: /archives/ || archive\n  #schedule: /schedule/ || calendar\n  #sitemap: /sitemap.xml || sitemap\n  #commonweal: /404/ || heartbeat\n```\n## 启动服务\n```\nhexo clean\nhexo g -d\n```\n然后，稍等一会，直接访问https://hsiachubby.github.io/\n\n## 提交代码\n新建hexo分支，将本地代码提交至hexo分支，该分支用来维护具体的文档信息；master分支是用来发布hexo的。\n\n## 相关问题\n* [ ] 设置”全文阅读“，在具体的md文件中，选择合适的地方，插入**<!-- more -->**\n* [ ] 文章插入图片，在source目录中，创建images目录，该目录用来维护图片信息，当Hexo项目中只用到少量图片时，可以将图片统一放在source/images文件夹中，通过markdown语法访问它们。\n\n### 参考文献\n* https://juejin.im/post/5c2dceb1518825079f78574d\n\n","source":"_posts/使用hexo+github搭建个人博客.md","raw":"---\ntitle: 使用hexo+github搭建个人博客\ntags: Hexo\ncategories: 前端\n---\nWelcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## 创建GitHub仓库\n1. 登录https://github.com/\n2. 注册账号\n3. 创建一个新Repositorie(仓库名必须要为以下格式：**xxx.github.io**，其中，xxx为用户名小写)\n## hexo部署\n### 什么是hexo?\nhexo是一个简单但强大的博客系统，Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。\n### 部署\n1. 安装node.js\n```\n<!--MacOS-->\n<!--安装了node之后，默认也会安装npm-->\nbrew install node\n```\n2. 安装hexo\n```\nnpm install hexo-cli\n```\n3.创建本地项目\n```\nhexo init xxx.github.io\ncd xxx.github.io\n<!--修改项目配置文件中的deploy配置-->\n\tdeploy:\n\t  type: git\n  repo: https://github.com/HsiaChubby/hsiachubby.github.io.git,master\n```\n<!-- more -->\n## 修改配置\n### 设置主题\n1. 下载next主题\n```\ngit clone https://github.com/iissnan/hexo-theme-next themes/next\n```\n2. 配置项目的主题\n打开项目配置文件_config.yml，设置theme如下：\n```\n# Extensions\n## Plugins: https://hexo.io/plugins/\n## Themes: https://hexo.io/themes/\ntheme: next\n```\n3. 配置主站相关信息\n打开项目配置文件_config.yml，设置基础如下:\n```\n# Site\ntitle: Chubby的博客\nsubtitle:\ndescription:\nkeywords:\nauthor: Chubby Hsia\nlanguage: zh-Hans\ntimezone:\n```\n4. 配置首页支持分类、标签、关于、归档\n分别运行一下命令\n```\n<!--创建分类页面-->\nhexo new page categories\n<!--创建标签页面-->\nhexo new page tags\n<!--创建归档页面-->\nhexo new page archives\n<!--创建关于页面-->\nhexo new page about\n```\n创建好上述页面后，会在source目录下，分别生成categories/tags/archives/about四个文件夹，然后分别进入相应的文件夹中，修改各自的index.md文件，如下：\n```\n<!--categories的index.md-->\n---\ntitle: categories\ndate: 2019-01-30 14:57:39\ntype: \"categories\"\n---\n<!--tags的index.md-->\n---\ntitle: tags\ndate: 2019-01-30 15:02:24\ntype: \"tags\"\n---\n<!--archives的index.md-->\ntitle: archives\ndate: 2019-01-30 15:02:33\ntype: \"archives\"\n---\n<!--about的index.md-->\n---\ntitle: about\ndate: 2019-01-30 15:02:41\ntype: \"archives\"\n---\n```\n然后，进入theme/next主题下，打开主题的配置文件_config.yml，修改menu配置，如下：\n```\nmenu:\n  home: / || home\n  about: /about/ || user\n  tags: /tags/ || tags\n  categories: /categories/ || th\n  archives: /archives/ || archive\n  #schedule: /schedule/ || calendar\n  #sitemap: /sitemap.xml || sitemap\n  #commonweal: /404/ || heartbeat\n```\n## 启动服务\n```\nhexo clean\nhexo g -d\n```\n然后，稍等一会，直接访问https://hsiachubby.github.io/\n\n## 提交代码\n新建hexo分支，将本地代码提交至hexo分支，该分支用来维护具体的文档信息；master分支是用来发布hexo的。\n\n## 相关问题\n* [ ] 设置”全文阅读“，在具体的md文件中，选择合适的地方，插入**<!-- more -->**\n* [ ] 文章插入图片，在source目录中，创建images目录，该目录用来维护图片信息，当Hexo项目中只用到少量图片时，可以将图片统一放在source/images文件夹中，通过markdown语法访问它们。\n\n### 参考文献\n* https://juejin.im/post/5c2dceb1518825079f78574d\n\n","slug":"使用hexo+github搭建个人博客","published":1,"date":"2019-01-30T08:58:27.000Z","updated":"2019-01-31T04:04:36.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjsa3xoyd00013lxyr9dyd3nn","content":"<p>Welcome to <a href=\"https://hexo.io/\" target=\"_blank\" rel=\"noopener\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\" target=\"_blank\" rel=\"noopener\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\" target=\"_blank\" rel=\"noopener\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\" target=\"_blank\" rel=\"noopener\">GitHub</a>.</p>\n<h2 id=\"创建GitHub仓库\"><a href=\"#创建GitHub仓库\" class=\"headerlink\" title=\"创建GitHub仓库\"></a>创建GitHub仓库</h2><ol>\n<li>登录<a href=\"https://github.com/\" target=\"_blank\" rel=\"noopener\">https://github.com/</a></li>\n<li>注册账号</li>\n<li>创建一个新Repositorie(仓库名必须要为以下格式：<strong>xxx.github.io</strong>，其中，xxx为用户名小写)<h2 id=\"hexo部署\"><a href=\"#hexo部署\" class=\"headerlink\" title=\"hexo部署\"></a>hexo部署</h2><h3 id=\"什么是hexo\"><a href=\"#什么是hexo\" class=\"headerlink\" title=\"什么是hexo?\"></a>什么是hexo?</h3>hexo是一个简单但强大的博客系统，Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。<h3 id=\"部署\"><a href=\"#部署\" class=\"headerlink\" title=\"部署\"></a>部署</h3></li>\n<li><p>安装node.js</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;!--MacOS--&gt;</span><br><span class=\"line\">&lt;!--安装了node之后，默认也会安装npm--&gt;</span><br><span class=\"line\">brew install node</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>安装hexo</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm install hexo-cli</span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n<p>3.创建本地项目<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo init xxx.github.io</span><br><span class=\"line\">cd xxx.github.io</span><br><span class=\"line\">&lt;!--修改项目配置文件中的deploy配置--&gt;</span><br><span class=\"line\">\tdeploy:</span><br><span class=\"line\">\t  type: git</span><br><span class=\"line\">  repo: https://github.com/HsiaChubby/hsiachubby.github.io.git,master</span><br></pre></td></tr></table></figure></p>\n<a id=\"more\"></a>\n<h2 id=\"修改配置\"><a href=\"#修改配置\" class=\"headerlink\" title=\"修改配置\"></a>修改配置</h2><h3 id=\"设置主题\"><a href=\"#设置主题\" class=\"headerlink\" title=\"设置主题\"></a>设置主题</h3><ol>\n<li><p>下载next主题</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git clone https://github.com/iissnan/hexo-theme-next themes/next</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>配置项目的主题<br>打开项目配置文件_config.yml，设置theme如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># Extensions</span><br><span class=\"line\">## Plugins: https://hexo.io/plugins/</span><br><span class=\"line\">## Themes: https://hexo.io/themes/</span><br><span class=\"line\">theme: next</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>配置主站相关信息<br>打开项目配置文件_config.yml，设置基础如下:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># Site</span><br><span class=\"line\">title: Chubby的博客</span><br><span class=\"line\">subtitle:</span><br><span class=\"line\">description:</span><br><span class=\"line\">keywords:</span><br><span class=\"line\">author: Chubby Hsia</span><br><span class=\"line\">language: zh-Hans</span><br><span class=\"line\">timezone:</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>配置首页支持分类、标签、关于、归档<br>分别运行一下命令</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;!--创建分类页面--&gt;</span><br><span class=\"line\">hexo new page categories</span><br><span class=\"line\">&lt;!--创建标签页面--&gt;</span><br><span class=\"line\">hexo new page tags</span><br><span class=\"line\">&lt;!--创建归档页面--&gt;</span><br><span class=\"line\">hexo new page archives</span><br><span class=\"line\">&lt;!--创建关于页面--&gt;</span><br><span class=\"line\">hexo new page about</span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n<p>创建好上述页面后，会在source目录下，分别生成categories/tags/archives/about四个文件夹，然后分别进入相应的文件夹中，修改各自的index.md文件，如下：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;!--categories的index.md--&gt;</span><br><span class=\"line\">---</span><br><span class=\"line\">title: categories</span><br><span class=\"line\">date: 2019-01-30 14:57:39</span><br><span class=\"line\">type: &quot;categories&quot;</span><br><span class=\"line\">---</span><br><span class=\"line\">&lt;!--tags的index.md--&gt;</span><br><span class=\"line\">---</span><br><span class=\"line\">title: tags</span><br><span class=\"line\">date: 2019-01-30 15:02:24</span><br><span class=\"line\">type: &quot;tags&quot;</span><br><span class=\"line\">---</span><br><span class=\"line\">&lt;!--archives的index.md--&gt;</span><br><span class=\"line\">title: archives</span><br><span class=\"line\">date: 2019-01-30 15:02:33</span><br><span class=\"line\">type: &quot;archives&quot;</span><br><span class=\"line\">---</span><br><span class=\"line\">&lt;!--about的index.md--&gt;</span><br><span class=\"line\">---</span><br><span class=\"line\">title: about</span><br><span class=\"line\">date: 2019-01-30 15:02:41</span><br><span class=\"line\">type: &quot;archives&quot;</span><br><span class=\"line\">---</span><br></pre></td></tr></table></figure></p>\n<p>然后，进入theme/next主题下，打开主题的配置文件_config.yml，修改menu配置，如下：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">menu:</span><br><span class=\"line\">  home: / || home</span><br><span class=\"line\">  about: /about/ || user</span><br><span class=\"line\">  tags: /tags/ || tags</span><br><span class=\"line\">  categories: /categories/ || th</span><br><span class=\"line\">  archives: /archives/ || archive</span><br><span class=\"line\">  #schedule: /schedule/ || calendar</span><br><span class=\"line\">  #sitemap: /sitemap.xml || sitemap</span><br><span class=\"line\">  #commonweal: /404/ || heartbeat</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"启动服务\"><a href=\"#启动服务\" class=\"headerlink\" title=\"启动服务\"></a>启动服务</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo clean</span><br><span class=\"line\">hexo g -d</span><br></pre></td></tr></table></figure>\n<p>然后，稍等一会，直接访问<a href=\"https://hsiachubby.github.io/\" target=\"_blank\" rel=\"noopener\">https://hsiachubby.github.io/</a></p>\n<h2 id=\"提交代码\"><a href=\"#提交代码\" class=\"headerlink\" title=\"提交代码\"></a>提交代码</h2><p>新建hexo分支，将本地代码提交至hexo分支，该分支用来维护具体的文档信息；master分支是用来发布hexo的。</p>\n<h2 id=\"相关问题\"><a href=\"#相关问题\" class=\"headerlink\" title=\"相关问题\"></a>相关问题</h2><ul>\n<li style=\"list-style: none\"><input type=\"checkbox\"> 设置”全文阅读“，在具体的md文件中，选择合适的地方，插入<strong><!-- more --></strong></li>\n<li style=\"list-style: none\"><input type=\"checkbox\"> 文章插入图片，在source目录中，创建images目录，该目录用来维护图片信息，当Hexo项目中只用到少量图片时，可以将图片统一放在source/images文件夹中，通过markdown语法访问它们。</li>\n</ul>\n<h3 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h3><ul>\n<li><a href=\"https://juejin.im/post/5c2dceb1518825079f78574d\" target=\"_blank\" rel=\"noopener\">https://juejin.im/post/5c2dceb1518825079f78574d</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<p>Welcome to <a href=\"https://hexo.io/\" target=\"_blank\" rel=\"noopener\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\" target=\"_blank\" rel=\"noopener\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\" target=\"_blank\" rel=\"noopener\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\" target=\"_blank\" rel=\"noopener\">GitHub</a>.</p>\n<h2 id=\"创建GitHub仓库\"><a href=\"#创建GitHub仓库\" class=\"headerlink\" title=\"创建GitHub仓库\"></a>创建GitHub仓库</h2><ol>\n<li>登录<a href=\"https://github.com/\" target=\"_blank\" rel=\"noopener\">https://github.com/</a></li>\n<li>注册账号</li>\n<li>创建一个新Repositorie(仓库名必须要为以下格式：<strong>xxx.github.io</strong>，其中，xxx为用户名小写)<h2 id=\"hexo部署\"><a href=\"#hexo部署\" class=\"headerlink\" title=\"hexo部署\"></a>hexo部署</h2><h3 id=\"什么是hexo\"><a href=\"#什么是hexo\" class=\"headerlink\" title=\"什么是hexo?\"></a>什么是hexo?</h3>hexo是一个简单但强大的博客系统，Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。<h3 id=\"部署\"><a href=\"#部署\" class=\"headerlink\" title=\"部署\"></a>部署</h3></li>\n<li><p>安装node.js</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;!--MacOS--&gt;</span><br><span class=\"line\">&lt;!--安装了node之后，默认也会安装npm--&gt;</span><br><span class=\"line\">brew install node</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>安装hexo</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm install hexo-cli</span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n<p>3.创建本地项目<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo init xxx.github.io</span><br><span class=\"line\">cd xxx.github.io</span><br><span class=\"line\">&lt;!--修改项目配置文件中的deploy配置--&gt;</span><br><span class=\"line\">\tdeploy:</span><br><span class=\"line\">\t  type: git</span><br><span class=\"line\">  repo: https://github.com/HsiaChubby/hsiachubby.github.io.git,master</span><br></pre></td></tr></table></figure></p>","more":"<h2 id=\"修改配置\"><a href=\"#修改配置\" class=\"headerlink\" title=\"修改配置\"></a>修改配置</h2><h3 id=\"设置主题\"><a href=\"#设置主题\" class=\"headerlink\" title=\"设置主题\"></a>设置主题</h3><ol>\n<li><p>下载next主题</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git clone https://github.com/iissnan/hexo-theme-next themes/next</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>配置项目的主题<br>打开项目配置文件_config.yml，设置theme如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># Extensions</span><br><span class=\"line\">## Plugins: https://hexo.io/plugins/</span><br><span class=\"line\">## Themes: https://hexo.io/themes/</span><br><span class=\"line\">theme: next</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>配置主站相关信息<br>打开项目配置文件_config.yml，设置基础如下:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># Site</span><br><span class=\"line\">title: Chubby的博客</span><br><span class=\"line\">subtitle:</span><br><span class=\"line\">description:</span><br><span class=\"line\">keywords:</span><br><span class=\"line\">author: Chubby Hsia</span><br><span class=\"line\">language: zh-Hans</span><br><span class=\"line\">timezone:</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>配置首页支持分类、标签、关于、归档<br>分别运行一下命令</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;!--创建分类页面--&gt;</span><br><span class=\"line\">hexo new page categories</span><br><span class=\"line\">&lt;!--创建标签页面--&gt;</span><br><span class=\"line\">hexo new page tags</span><br><span class=\"line\">&lt;!--创建归档页面--&gt;</span><br><span class=\"line\">hexo new page archives</span><br><span class=\"line\">&lt;!--创建关于页面--&gt;</span><br><span class=\"line\">hexo new page about</span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n<p>创建好上述页面后，会在source目录下，分别生成categories/tags/archives/about四个文件夹，然后分别进入相应的文件夹中，修改各自的index.md文件，如下：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;!--categories的index.md--&gt;</span><br><span class=\"line\">---</span><br><span class=\"line\">title: categories</span><br><span class=\"line\">date: 2019-01-30 14:57:39</span><br><span class=\"line\">type: &quot;categories&quot;</span><br><span class=\"line\">---</span><br><span class=\"line\">&lt;!--tags的index.md--&gt;</span><br><span class=\"line\">---</span><br><span class=\"line\">title: tags</span><br><span class=\"line\">date: 2019-01-30 15:02:24</span><br><span class=\"line\">type: &quot;tags&quot;</span><br><span class=\"line\">---</span><br><span class=\"line\">&lt;!--archives的index.md--&gt;</span><br><span class=\"line\">title: archives</span><br><span class=\"line\">date: 2019-01-30 15:02:33</span><br><span class=\"line\">type: &quot;archives&quot;</span><br><span class=\"line\">---</span><br><span class=\"line\">&lt;!--about的index.md--&gt;</span><br><span class=\"line\">---</span><br><span class=\"line\">title: about</span><br><span class=\"line\">date: 2019-01-30 15:02:41</span><br><span class=\"line\">type: &quot;archives&quot;</span><br><span class=\"line\">---</span><br></pre></td></tr></table></figure></p>\n<p>然后，进入theme/next主题下，打开主题的配置文件_config.yml，修改menu配置，如下：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">menu:</span><br><span class=\"line\">  home: / || home</span><br><span class=\"line\">  about: /about/ || user</span><br><span class=\"line\">  tags: /tags/ || tags</span><br><span class=\"line\">  categories: /categories/ || th</span><br><span class=\"line\">  archives: /archives/ || archive</span><br><span class=\"line\">  #schedule: /schedule/ || calendar</span><br><span class=\"line\">  #sitemap: /sitemap.xml || sitemap</span><br><span class=\"line\">  #commonweal: /404/ || heartbeat</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"启动服务\"><a href=\"#启动服务\" class=\"headerlink\" title=\"启动服务\"></a>启动服务</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo clean</span><br><span class=\"line\">hexo g -d</span><br></pre></td></tr></table></figure>\n<p>然后，稍等一会，直接访问<a href=\"https://hsiachubby.github.io/\" target=\"_blank\" rel=\"noopener\">https://hsiachubby.github.io/</a></p>\n<h2 id=\"提交代码\"><a href=\"#提交代码\" class=\"headerlink\" title=\"提交代码\"></a>提交代码</h2><p>新建hexo分支，将本地代码提交至hexo分支，该分支用来维护具体的文档信息；master分支是用来发布hexo的。</p>\n<h2 id=\"相关问题\"><a href=\"#相关问题\" class=\"headerlink\" title=\"相关问题\"></a>相关问题</h2><ul>\n<li style=\"list-style: none\"><input type=\"checkbox\"> 设置”全文阅读“，在具体的md文件中，选择合适的地方，插入<strong><!-- more --></strong></li>\n<li style=\"list-style: none\"><input type=\"checkbox\"> 文章插入图片，在source目录中，创建images目录，该目录用来维护图片信息，当Hexo项目中只用到少量图片时，可以将图片统一放在source/images文件夹中，通过markdown语法访问它们。</li>\n</ul>\n<h3 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h3><ul>\n<li><a href=\"https://juejin.im/post/5c2dceb1518825079f78574d\" target=\"_blank\" rel=\"noopener\">https://juejin.im/post/5c2dceb1518825079f78574d</a></li>\n</ul>"},{"title":"机器学习概论","date":"2019-01-30T07:26:01.000Z","_content":"\n\n## 开篇背景\n目前，工作中的事情相对少一点，富余时间比较足，因此，可以拿出一部分时间用来学习下机器学习方面的理论知识与实践知识。这样做主要出于两个方面的目的，一方面是想通过本次整理的系列来增强与梳理自己在机器学习领域中的理解，梳理出自己在机器学习领域中的方法论，另一方面，提升自己的实际工作效率。\n\n-------\n\n好了，以上说明了本次系列的背景，接下来将主要阐述本系列的主要内容：\n\n    * 希望能够以自己的理解阐述什么是机器学习，机器学习的框架，机器学习可以用来解决什么样的问题等等\n    * 阐述机器学习中常用的优化方法\n    * 从模型的角度出发，深入阐述不同模型，主要从以下几个方面来阐述模型：a. 模型是什么（这种阐述是一种通用型的表述）；b.模型产生的背景与原因（通常是为了解决另一个模型中的缺点，而产生的一种新的模型）；c.模型的应用场景限制或者说是前提条件以及常见的应用场景；d.模型涉及的梳理理论背景知识；e.阐述模型的理论推导\n    * 最后，尽可能地能够输出一份相对完整的模型间的整合对比\n\n以上就是本系列希望能够实现的一个目标，希望接下来会有系列2，系列3...，接下来将正式进入本系列的内容当中.\n<!-- more -->\n\n## 什么是机器学习？\n\"机器学习\"顾名思义，就是让机器来学习，如果将机器和人进行类比的话，可以认为机器的学习过程和人的学习过程在一定程度上是具有相似性的。通常，人在学习的过程中，都需要确定以下信息：1、学习什么领域的知识？2、学习的内容或者目标是什么？3、通过什么学习方法来进行学习，使得自己能够快速掌握这些知识点？4、同时，还有一个重要的点，就是我们应该将习得的知识应用于我们的日常生活中，通过知识来丰富与提升个人的生活品质嘛。\n\n同理，机器学习也会遇到人在学习过程中所遇到的问题，比如：1、机器学习也是学习特定领域中的知识或者规律的，这里的特定领域通常就是指我们在实际的工作中所遇到的**业务问题**，而这个”业务问题“就是机器学习中所涉及到的知识背景；2、那么机器需要学习什么呢？这个学习的内容通常需要我们人类参与设计，为什么呢，当下机器学习终究还是为了我们人类而服务的，因此，为了让机器能够更好地服务于人类，那么我们自己就要扮演者\"出题者\"的决策，即你告诉机器学习什么内容，这个过程实际上就是**建模**的过程，通常这也是在我们实际的工作生活中最重要的一部；3、当人类给了机器设定了学习目标（通常这个目标是能够用数学等相对抽象的方式进行表达）后，机器就需要能够通过自己的方法论来学习以及人类所提供的材料（**数据**）来掌握目标中的知识点，通常机器用来进行学习的方法论被称为**优化算法**，但是在这个学习过程中，我们怎么来判断它知识点掌握得牢靠呢，同时我们还需要判断它到底有没有提升的空间呢，最可靠的方式就是制定标准化考试的评分机制（**损失函数**），来计算在该评分机制下的得分，从而判断机器对知识点掌握的程度如何，如果达到令人满意的程度，那么我们就可以给机器放假啦，但是，如果没有达到令人满意的程度，我们就需要想方设法地让机器优化其习得的结果（通常有以下做法：一、给机器提供更多的材料及数据；二、让机器不断地投入精力（不断迭代优化）；三、也许这个机器偏科，那么我们可以重新制定学习目标；四、既然一个人考试的结果不好，那么我们让大家一起协同起来，各自发挥自己的长处）；4、最好，当机器很好地掌握了知识点后，我们就可以放心地让其来提升我们的业务啦。\n\n以上通过相对形象的方式阐述了机器学习的过程到底是一个什么样的情况，具体的如下图：\n![](/images/1548834369938.jpg)\n\n## 机器学习可以解决什么问题？\n机器学习的应用面非常广，但凡是所有能够通过数学模型抽象出来的问题，理论上都是能够应用机器学习的，目前，主流的应用有：推荐系统，广告TA，金融风控等。在不同的应用环境中，会有不同的业务问题，因此，通常会出现不同的模型，当然有些模型也是能够跨行业，跨问题的，在实际过程中，还是需要具体问题具体分析，设计出最佳的业务数学模型。\n\n## 机器学习有哪些常见的模型？\n目前常见的模型有：线性回归模型，logistics回归模型，EM模型，朴素贝叶斯模型，决策树，Boosting模型，Bagging模型，KNN模型，SVM模型，神经网络模型，HMM模型，时间序列模型、等等，每经典的模型都值得我们花时间去深入分析与理解，本系列的后续文章中将逐一来阐述这些模型。\n\n## 机器学习中有哪些常见的优化算法？\n在数学史上，数学大师们已经提出很多的优化算法来解决数学中的优化问题，经典有：最小二乘法、梯度下降法（随机梯度下降法、Mini-batch随机梯度下降法）、最大似然估计法、牛顿法、拟牛顿法等，除此之外，还有一些在计算机领域中常用的优化算法，例如：SMO算法（后续补充...）等。在接下来的文章中，我们也将逐一来理解这些优化算法\n\n## 思考：如何建模\n在上文也提到过，建模的过程通常是需要我们人来参与设计的，那么在遇到一个实际的业务问题的时候，我们应该如何建模呢？\n（后续补充...）\n\n好了，本文作为这个系列的第一篇，有点匆忙，后续将逐步来深入理解机器学习中的重要的知识点。\n晚安，2018.3.15~ \n\n\n","source":"_posts/机器学习概论.md","raw":"---\ntitle: 机器学习概论\ndate: 2019-01-30 15:26:01\ntags: 机器学习\ncategories: 机器学习\n---\n\n\n## 开篇背景\n目前，工作中的事情相对少一点，富余时间比较足，因此，可以拿出一部分时间用来学习下机器学习方面的理论知识与实践知识。这样做主要出于两个方面的目的，一方面是想通过本次整理的系列来增强与梳理自己在机器学习领域中的理解，梳理出自己在机器学习领域中的方法论，另一方面，提升自己的实际工作效率。\n\n-------\n\n好了，以上说明了本次系列的背景，接下来将主要阐述本系列的主要内容：\n\n    * 希望能够以自己的理解阐述什么是机器学习，机器学习的框架，机器学习可以用来解决什么样的问题等等\n    * 阐述机器学习中常用的优化方法\n    * 从模型的角度出发，深入阐述不同模型，主要从以下几个方面来阐述模型：a. 模型是什么（这种阐述是一种通用型的表述）；b.模型产生的背景与原因（通常是为了解决另一个模型中的缺点，而产生的一种新的模型）；c.模型的应用场景限制或者说是前提条件以及常见的应用场景；d.模型涉及的梳理理论背景知识；e.阐述模型的理论推导\n    * 最后，尽可能地能够输出一份相对完整的模型间的整合对比\n\n以上就是本系列希望能够实现的一个目标，希望接下来会有系列2，系列3...，接下来将正式进入本系列的内容当中.\n<!-- more -->\n\n## 什么是机器学习？\n\"机器学习\"顾名思义，就是让机器来学习，如果将机器和人进行类比的话，可以认为机器的学习过程和人的学习过程在一定程度上是具有相似性的。通常，人在学习的过程中，都需要确定以下信息：1、学习什么领域的知识？2、学习的内容或者目标是什么？3、通过什么学习方法来进行学习，使得自己能够快速掌握这些知识点？4、同时，还有一个重要的点，就是我们应该将习得的知识应用于我们的日常生活中，通过知识来丰富与提升个人的生活品质嘛。\n\n同理，机器学习也会遇到人在学习过程中所遇到的问题，比如：1、机器学习也是学习特定领域中的知识或者规律的，这里的特定领域通常就是指我们在实际的工作中所遇到的**业务问题**，而这个”业务问题“就是机器学习中所涉及到的知识背景；2、那么机器需要学习什么呢？这个学习的内容通常需要我们人类参与设计，为什么呢，当下机器学习终究还是为了我们人类而服务的，因此，为了让机器能够更好地服务于人类，那么我们自己就要扮演者\"出题者\"的决策，即你告诉机器学习什么内容，这个过程实际上就是**建模**的过程，通常这也是在我们实际的工作生活中最重要的一部；3、当人类给了机器设定了学习目标（通常这个目标是能够用数学等相对抽象的方式进行表达）后，机器就需要能够通过自己的方法论来学习以及人类所提供的材料（**数据**）来掌握目标中的知识点，通常机器用来进行学习的方法论被称为**优化算法**，但是在这个学习过程中，我们怎么来判断它知识点掌握得牢靠呢，同时我们还需要判断它到底有没有提升的空间呢，最可靠的方式就是制定标准化考试的评分机制（**损失函数**），来计算在该评分机制下的得分，从而判断机器对知识点掌握的程度如何，如果达到令人满意的程度，那么我们就可以给机器放假啦，但是，如果没有达到令人满意的程度，我们就需要想方设法地让机器优化其习得的结果（通常有以下做法：一、给机器提供更多的材料及数据；二、让机器不断地投入精力（不断迭代优化）；三、也许这个机器偏科，那么我们可以重新制定学习目标；四、既然一个人考试的结果不好，那么我们让大家一起协同起来，各自发挥自己的长处）；4、最好，当机器很好地掌握了知识点后，我们就可以放心地让其来提升我们的业务啦。\n\n以上通过相对形象的方式阐述了机器学习的过程到底是一个什么样的情况，具体的如下图：\n![](/images/1548834369938.jpg)\n\n## 机器学习可以解决什么问题？\n机器学习的应用面非常广，但凡是所有能够通过数学模型抽象出来的问题，理论上都是能够应用机器学习的，目前，主流的应用有：推荐系统，广告TA，金融风控等。在不同的应用环境中，会有不同的业务问题，因此，通常会出现不同的模型，当然有些模型也是能够跨行业，跨问题的，在实际过程中，还是需要具体问题具体分析，设计出最佳的业务数学模型。\n\n## 机器学习有哪些常见的模型？\n目前常见的模型有：线性回归模型，logistics回归模型，EM模型，朴素贝叶斯模型，决策树，Boosting模型，Bagging模型，KNN模型，SVM模型，神经网络模型，HMM模型，时间序列模型、等等，每经典的模型都值得我们花时间去深入分析与理解，本系列的后续文章中将逐一来阐述这些模型。\n\n## 机器学习中有哪些常见的优化算法？\n在数学史上，数学大师们已经提出很多的优化算法来解决数学中的优化问题，经典有：最小二乘法、梯度下降法（随机梯度下降法、Mini-batch随机梯度下降法）、最大似然估计法、牛顿法、拟牛顿法等，除此之外，还有一些在计算机领域中常用的优化算法，例如：SMO算法（后续补充...）等。在接下来的文章中，我们也将逐一来理解这些优化算法\n\n## 思考：如何建模\n在上文也提到过，建模的过程通常是需要我们人来参与设计的，那么在遇到一个实际的业务问题的时候，我们应该如何建模呢？\n（后续补充...）\n\n好了，本文作为这个系列的第一篇，有点匆忙，后续将逐步来深入理解机器学习中的重要的知识点。\n晚安，2018.3.15~ \n\n\n","slug":"机器学习概论","published":1,"updated":"2019-01-30T08:06:42.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjsa3xoyg00043lxyvobu2i4w","content":"<h2 id=\"开篇背景\"><a href=\"#开篇背景\" class=\"headerlink\" title=\"开篇背景\"></a>开篇背景</h2><p>目前，工作中的事情相对少一点，富余时间比较足，因此，可以拿出一部分时间用来学习下机器学习方面的理论知识与实践知识。这样做主要出于两个方面的目的，一方面是想通过本次整理的系列来增强与梳理自己在机器学习领域中的理解，梳理出自己在机器学习领域中的方法论，另一方面，提升自己的实际工作效率。</p>\n<hr>\n<p>好了，以上说明了本次系列的背景，接下来将主要阐述本系列的主要内容：</p>\n<pre><code>* 希望能够以自己的理解阐述什么是机器学习，机器学习的框架，机器学习可以用来解决什么样的问题等等\n* 阐述机器学习中常用的优化方法\n* 从模型的角度出发，深入阐述不同模型，主要从以下几个方面来阐述模型：a. 模型是什么（这种阐述是一种通用型的表述）；b.模型产生的背景与原因（通常是为了解决另一个模型中的缺点，而产生的一种新的模型）；c.模型的应用场景限制或者说是前提条件以及常见的应用场景；d.模型涉及的梳理理论背景知识；e.阐述模型的理论推导\n* 最后，尽可能地能够输出一份相对完整的模型间的整合对比\n</code></pre><p>以上就是本系列希望能够实现的一个目标，希望接下来会有系列2，系列3…，接下来将正式进入本系列的内容当中.<br><a id=\"more\"></a></p>\n<h2 id=\"什么是机器学习？\"><a href=\"#什么是机器学习？\" class=\"headerlink\" title=\"什么是机器学习？\"></a>什么是机器学习？</h2><p>“机器学习”顾名思义，就是让机器来学习，如果将机器和人进行类比的话，可以认为机器的学习过程和人的学习过程在一定程度上是具有相似性的。通常，人在学习的过程中，都需要确定以下信息：1、学习什么领域的知识？2、学习的内容或者目标是什么？3、通过什么学习方法来进行学习，使得自己能够快速掌握这些知识点？4、同时，还有一个重要的点，就是我们应该将习得的知识应用于我们的日常生活中，通过知识来丰富与提升个人的生活品质嘛。</p>\n<p>同理，机器学习也会遇到人在学习过程中所遇到的问题，比如：1、机器学习也是学习特定领域中的知识或者规律的，这里的特定领域通常就是指我们在实际的工作中所遇到的<strong>业务问题</strong>，而这个”业务问题“就是机器学习中所涉及到的知识背景；2、那么机器需要学习什么呢？这个学习的内容通常需要我们人类参与设计，为什么呢，当下机器学习终究还是为了我们人类而服务的，因此，为了让机器能够更好地服务于人类，那么我们自己就要扮演者”出题者”的决策，即你告诉机器学习什么内容，这个过程实际上就是<strong>建模</strong>的过程，通常这也是在我们实际的工作生活中最重要的一部；3、当人类给了机器设定了学习目标（通常这个目标是能够用数学等相对抽象的方式进行表达）后，机器就需要能够通过自己的方法论来学习以及人类所提供的材料（<strong>数据</strong>）来掌握目标中的知识点，通常机器用来进行学习的方法论被称为<strong>优化算法</strong>，但是在这个学习过程中，我们怎么来判断它知识点掌握得牢靠呢，同时我们还需要判断它到底有没有提升的空间呢，最可靠的方式就是制定标准化考试的评分机制（<strong>损失函数</strong>），来计算在该评分机制下的得分，从而判断机器对知识点掌握的程度如何，如果达到令人满意的程度，那么我们就可以给机器放假啦，但是，如果没有达到令人满意的程度，我们就需要想方设法地让机器优化其习得的结果（通常有以下做法：一、给机器提供更多的材料及数据；二、让机器不断地投入精力（不断迭代优化）；三、也许这个机器偏科，那么我们可以重新制定学习目标；四、既然一个人考试的结果不好，那么我们让大家一起协同起来，各自发挥自己的长处）；4、最好，当机器很好地掌握了知识点后，我们就可以放心地让其来提升我们的业务啦。</p>\n<p>以上通过相对形象的方式阐述了机器学习的过程到底是一个什么样的情况，具体的如下图：<br><img src=\"/images/1548834369938.jpg\" alt=\"\"></p>\n<h2 id=\"机器学习可以解决什么问题？\"><a href=\"#机器学习可以解决什么问题？\" class=\"headerlink\" title=\"机器学习可以解决什么问题？\"></a>机器学习可以解决什么问题？</h2><p>机器学习的应用面非常广，但凡是所有能够通过数学模型抽象出来的问题，理论上都是能够应用机器学习的，目前，主流的应用有：推荐系统，广告TA，金融风控等。在不同的应用环境中，会有不同的业务问题，因此，通常会出现不同的模型，当然有些模型也是能够跨行业，跨问题的，在实际过程中，还是需要具体问题具体分析，设计出最佳的业务数学模型。</p>\n<h2 id=\"机器学习有哪些常见的模型？\"><a href=\"#机器学习有哪些常见的模型？\" class=\"headerlink\" title=\"机器学习有哪些常见的模型？\"></a>机器学习有哪些常见的模型？</h2><p>目前常见的模型有：线性回归模型，logistics回归模型，EM模型，朴素贝叶斯模型，决策树，Boosting模型，Bagging模型，KNN模型，SVM模型，神经网络模型，HMM模型，时间序列模型、等等，每经典的模型都值得我们花时间去深入分析与理解，本系列的后续文章中将逐一来阐述这些模型。</p>\n<h2 id=\"机器学习中有哪些常见的优化算法？\"><a href=\"#机器学习中有哪些常见的优化算法？\" class=\"headerlink\" title=\"机器学习中有哪些常见的优化算法？\"></a>机器学习中有哪些常见的优化算法？</h2><p>在数学史上，数学大师们已经提出很多的优化算法来解决数学中的优化问题，经典有：最小二乘法、梯度下降法（随机梯度下降法、Mini-batch随机梯度下降法）、最大似然估计法、牛顿法、拟牛顿法等，除此之外，还有一些在计算机领域中常用的优化算法，例如：SMO算法（后续补充…）等。在接下来的文章中，我们也将逐一来理解这些优化算法</p>\n<h2 id=\"思考：如何建模\"><a href=\"#思考：如何建模\" class=\"headerlink\" title=\"思考：如何建模\"></a>思考：如何建模</h2><p>在上文也提到过，建模的过程通常是需要我们人来参与设计的，那么在遇到一个实际的业务问题的时候，我们应该如何建模呢？<br>（后续补充…）</p>\n<p>好了，本文作为这个系列的第一篇，有点匆忙，后续将逐步来深入理解机器学习中的重要的知识点。<br>晚安，2018.3.15~ </p>\n","site":{"data":{}},"excerpt":"<h2 id=\"开篇背景\"><a href=\"#开篇背景\" class=\"headerlink\" title=\"开篇背景\"></a>开篇背景</h2><p>目前，工作中的事情相对少一点，富余时间比较足，因此，可以拿出一部分时间用来学习下机器学习方面的理论知识与实践知识。这样做主要出于两个方面的目的，一方面是想通过本次整理的系列来增强与梳理自己在机器学习领域中的理解，梳理出自己在机器学习领域中的方法论，另一方面，提升自己的实际工作效率。</p>\n<hr>\n<p>好了，以上说明了本次系列的背景，接下来将主要阐述本系列的主要内容：</p>\n<pre><code>* 希望能够以自己的理解阐述什么是机器学习，机器学习的框架，机器学习可以用来解决什么样的问题等等\n* 阐述机器学习中常用的优化方法\n* 从模型的角度出发，深入阐述不同模型，主要从以下几个方面来阐述模型：a. 模型是什么（这种阐述是一种通用型的表述）；b.模型产生的背景与原因（通常是为了解决另一个模型中的缺点，而产生的一种新的模型）；c.模型的应用场景限制或者说是前提条件以及常见的应用场景；d.模型涉及的梳理理论背景知识；e.阐述模型的理论推导\n* 最后，尽可能地能够输出一份相对完整的模型间的整合对比\n</code></pre><p>以上就是本系列希望能够实现的一个目标，希望接下来会有系列2，系列3…，接下来将正式进入本系列的内容当中.<br></p>","more":"<p></p>\n<h2 id=\"什么是机器学习？\"><a href=\"#什么是机器学习？\" class=\"headerlink\" title=\"什么是机器学习？\"></a>什么是机器学习？</h2><p>“机器学习”顾名思义，就是让机器来学习，如果将机器和人进行类比的话，可以认为机器的学习过程和人的学习过程在一定程度上是具有相似性的。通常，人在学习的过程中，都需要确定以下信息：1、学习什么领域的知识？2、学习的内容或者目标是什么？3、通过什么学习方法来进行学习，使得自己能够快速掌握这些知识点？4、同时，还有一个重要的点，就是我们应该将习得的知识应用于我们的日常生活中，通过知识来丰富与提升个人的生活品质嘛。</p>\n<p>同理，机器学习也会遇到人在学习过程中所遇到的问题，比如：1、机器学习也是学习特定领域中的知识或者规律的，这里的特定领域通常就是指我们在实际的工作中所遇到的<strong>业务问题</strong>，而这个”业务问题“就是机器学习中所涉及到的知识背景；2、那么机器需要学习什么呢？这个学习的内容通常需要我们人类参与设计，为什么呢，当下机器学习终究还是为了我们人类而服务的，因此，为了让机器能够更好地服务于人类，那么我们自己就要扮演者”出题者”的决策，即你告诉机器学习什么内容，这个过程实际上就是<strong>建模</strong>的过程，通常这也是在我们实际的工作生活中最重要的一部；3、当人类给了机器设定了学习目标（通常这个目标是能够用数学等相对抽象的方式进行表达）后，机器就需要能够通过自己的方法论来学习以及人类所提供的材料（<strong>数据</strong>）来掌握目标中的知识点，通常机器用来进行学习的方法论被称为<strong>优化算法</strong>，但是在这个学习过程中，我们怎么来判断它知识点掌握得牢靠呢，同时我们还需要判断它到底有没有提升的空间呢，最可靠的方式就是制定标准化考试的评分机制（<strong>损失函数</strong>），来计算在该评分机制下的得分，从而判断机器对知识点掌握的程度如何，如果达到令人满意的程度，那么我们就可以给机器放假啦，但是，如果没有达到令人满意的程度，我们就需要想方设法地让机器优化其习得的结果（通常有以下做法：一、给机器提供更多的材料及数据；二、让机器不断地投入精力（不断迭代优化）；三、也许这个机器偏科，那么我们可以重新制定学习目标；四、既然一个人考试的结果不好，那么我们让大家一起协同起来，各自发挥自己的长处）；4、最好，当机器很好地掌握了知识点后，我们就可以放心地让其来提升我们的业务啦。</p>\n<p>以上通过相对形象的方式阐述了机器学习的过程到底是一个什么样的情况，具体的如下图：<br><img src=\"/images/1548834369938.jpg\" alt=\"\"></p>\n<h2 id=\"机器学习可以解决什么问题？\"><a href=\"#机器学习可以解决什么问题？\" class=\"headerlink\" title=\"机器学习可以解决什么问题？\"></a>机器学习可以解决什么问题？</h2><p>机器学习的应用面非常广，但凡是所有能够通过数学模型抽象出来的问题，理论上都是能够应用机器学习的，目前，主流的应用有：推荐系统，广告TA，金融风控等。在不同的应用环境中，会有不同的业务问题，因此，通常会出现不同的模型，当然有些模型也是能够跨行业，跨问题的，在实际过程中，还是需要具体问题具体分析，设计出最佳的业务数学模型。</p>\n<h2 id=\"机器学习有哪些常见的模型？\"><a href=\"#机器学习有哪些常见的模型？\" class=\"headerlink\" title=\"机器学习有哪些常见的模型？\"></a>机器学习有哪些常见的模型？</h2><p>目前常见的模型有：线性回归模型，logistics回归模型，EM模型，朴素贝叶斯模型，决策树，Boosting模型，Bagging模型，KNN模型，SVM模型，神经网络模型，HMM模型，时间序列模型、等等，每经典的模型都值得我们花时间去深入分析与理解，本系列的后续文章中将逐一来阐述这些模型。</p>\n<h2 id=\"机器学习中有哪些常见的优化算法？\"><a href=\"#机器学习中有哪些常见的优化算法？\" class=\"headerlink\" title=\"机器学习中有哪些常见的优化算法？\"></a>机器学习中有哪些常见的优化算法？</h2><p>在数学史上，数学大师们已经提出很多的优化算法来解决数学中的优化问题，经典有：最小二乘法、梯度下降法（随机梯度下降法、Mini-batch随机梯度下降法）、最大似然估计法、牛顿法、拟牛顿法等，除此之外，还有一些在计算机领域中常用的优化算法，例如：SMO算法（后续补充…）等。在接下来的文章中，我们也将逐一来理解这些优化算法</p>\n<h2 id=\"思考：如何建模\"><a href=\"#思考：如何建模\" class=\"headerlink\" title=\"思考：如何建模\"></a>思考：如何建模</h2><p>在上文也提到过，建模的过程通常是需要我们人来参与设计的，那么在遇到一个实际的业务问题的时候，我们应该如何建模呢？<br>（后续补充…）</p>\n<p>好了，本文作为这个系列的第一篇，有点匆忙，后续将逐步来深入理解机器学习中的重要的知识点。<br>晚安，2018.3.15~ </p>"},{"title":"机器学习中常用优化算法总结","date":"2019-01-31T02:41:59.000Z","mathjax":true,"_content":"\n优化算法是机器学习中的“方法论”，优化算法会告诉机器应该如何优化学习的进程，让自己能够更好地掌握学习到的知识，本文将针对机器学习领域中常用的几种优化算法进行总结。\n\n## 梯度下降法\n### 梯度下降法与梯度、导数的概念\n梯度下降法是用来求解无约束优化问题的一种数学方法，通过梯度下降法可以获取到函数的局部极小值。这里存在一个概念“梯度”，梯度的本意实际上是一个向量，及具有方向性和数值性，其表示的是一个函数在改点沿着该方向变化最快（这个方向是往函数值变大的方向），这个变化率实际上就是该梯度的模。因此，在使用梯度下降法的时候，实际上是要求我们选择梯度的反方向进行计算，只有这样才能保证我们能够取到极小值，这也就是为什么在使用导数（导数与梯度实际上是同一个概念，只不过梯度是一种抽象的表述概念，而导数是实际上用来求解梯度的一种数学表示方式，导数值前面的正负号实际上是决定了梯度的方向）进行参数迭代的时候是要在导数的前面加上负号。\n![](/images/gradient_ill.jpg)\n\n如上图所示，我们对函数f在A点对自变量x求解右导数$f^\\prime$，其值为正数，那是因为在A点右侧函数值是增大的，因此，如果要想f值变小，则需要让往左移$x=x_a-\\delta f^\\prime$；对B点求解右导数，其值为负数，那是因为在B点右侧函数值是变小的，因此，如果想要f值变小，则需要让x往右移$x=x_a-\\delta f^\\prime$，因此，如果是要使用梯度下降法，则在迭代过程中要在导数的前面加上负号。\n<!-- more -->\n\n### 梯度下降法详解\n#### 应用前提条件\n首先，我们得需要明确梯度下降法并不是万能的，因为在机器学习领域中，存在一个叫做NFL(No Free Launch)定理，这个定理说明了不存在一种模型或者算法能够适应于所有的应用场景。那么既然如此，梯度下降法能够应用于哪些场景中呢。其实从梯度下降法的原理来看，只要我们沿着梯度方向能够寻找到合适的最小值，那么就可以使用梯度下降法，那么如何判断什么样的函数是满足梯度下降法的应用的呢，最简单的一种方法就是判断该函数是否是**下凸函数**，如果一个函数是下凸函数，那么我们就可以针对该函数使用梯度下降法来求解最小值。当然，对于下凸函数可能会存在很多个局部极小值点，那么在这种情况下，使用梯度下降法来求解函数的最小值可能会存在一些偏差，那么此时，会通过一些技术性的措施（比如：采用随机性，分别从不同起始点多次进行梯度下降求解等）来优化我们使用梯度下降法的过程。\n\n在梯度下降法中，通常需要优先确定以下条件：\n    1. 步长,也成为学习率 $\\alpha$\n    2. 目标函数（损失函数，但是在确定损失函数过程$ L(\\theta) $，需要优先确定模型$ h\\_\\theta(x) $）\n基于上述两点先决条件，可以获得梯度下降法中最关键的表达式：\n$ \\theta_t = \\theta_{t-1}-\\alpha \\frac{\\partial L}{\\partial x} $\n\n下面将分别基于**线性回归模型**来阐述代数形式和矩阵形式下的梯度下降法。\n\n#### 梯度下降法的代数形式表达\n1. 假设有一组数据集$(x_1^1,x_2^1,...,x_n^1,y^1),(x_1^2,x_2^2,...,x_n^2,y^2),...,(x_1^m,x_2^m,...,x_n^m,y^m)$，该数据集共有m个样本，每个样本包含有n个特征量。\n如果我们想通过线性回归模型来构建$x$与$y$之间的关系，可得如下模型：$h_\\theta(x_1,x_2,...,x_n)=\\theta_0+\\theta_1 x_1 + ... + \\theta_n x_n$,\n2. 采用线性模型常用的误差平方和作为损失函数L:\n$L(\\theta_0,theta_1,...,theta_n)=\\frac{1}{2m}\\sum_{j=1}^m(y_j-h_\\theta(x_1^j,x_2^j,...,x_n^j)^2)$\n3. 使用梯度下降法求解，需要初始化相关参数，主要包含了$\\theta$、$\\alpha$、以及迭代停止距离$\\epsilon$,通常我们可以将$\\alpha$设置为0.9，$\\theta$设置为0。\n4. 算法流程如下：\n    Step1:计算当前$L(\\theta_0,\\theta_1,...,\\theta_n)$关于每个$\\theta_i$的梯度：$\\frac{\\partial L}{\\partial \\theta_i}$；\n    Step2:用步长$\\alpha$乘以Step1中求得的每个关于$\\theta_i$的梯度，得到每个$\\theta_i$下降的距离$d_i$；\n    Step3:判断每个$\\theta_i$的梯度下降距离$d_i$的值是否都小于终止条件$\\epsilon$,如果是，则停止学习，将当前的学习到的所有的$\\theta_i$作为最终习得的参数，反之，进入Step4;\n    Step3:更新所有的$\\theta_i$,更新公式如下：$\\theta_i=\\theta_i-\\alpha \\frac{\\partial L}{\\partial \\theta_i}$,然后重复Step1~Step3.\n#### 梯度下降法的矩阵形式表达\n梯度下降法的矩阵表达形式实际上上对代数形式的矩阵话，为什么需要矩阵化？因为在实际的计算过程中，矩阵运算的效率与高于循环计算的效率，能够提升学习的效率。\n\n通常我们会将样本数据集表示为$\\matrix{X_{m \\times n}}$，其中，$m$表示样本的个数，即矩阵的每一行表示一个样本信息，$n$表示样本中的特征量的个数，即矩阵中的每列表示的是一个特征量的取值。并且通常在机器学习领域中将向量表示为列向量，因此，所有的参数$\\theta_i$可以表示为向量$\\vec{\\theta}$.\n\n根据上述定义的矩阵和向量信息，可以重新表达线性模型：$\\vec{y}=\\matrix{X}\\theta$,同时，损失函数可以表示为：$L(\\theta) = \\frac{1}{2}(\\vec{y}-\\matrix{X}\\theta)^T(\\vec{y}-\\matrix{X}\\theta)$，预先设置的参数步骤和代数形式是一致的，算法过程也是一致的，唯一的区别是在计算过程中变成了矩阵话运算。\n\n#### 梯度下降法的变形\n上文所阐述的梯度下降法实际上是在每一轮迭代的过程中针对所有的样本进行梯度计算与梯度下降判断的，也可以成为**全批量梯度下降法（Batch Gradient Descent）**，这样的方法具有以下缺点：如果样本量非常大的时候，计算的效率会降低，但是也具有准确率高的优点；\n针对BGD算法效率低的问题，又提出了一种**随机梯度下降法（Stochastic Gradient Descent）**，顾名思义，这种做法是每一轮迭代都只随机选取一个样本进行计算，这种方式大大提升了计算的效率，但是，由于每一次都是随机选取一个样本进行迭代计算，那么会导致获得的参数值并不是局部最优解，同时，这样方式还会导致每次迭代时的方向会不稳定，即整体的收敛速度会下降；\n针对上述两种极端的梯度下降法，又提出了一种**小批量梯度下降法（Mini-Batch Gradient Descent）**，这种方法通常是选择部分样本参与计算，通常每轮迭代选择的样本量为16,32,64,128,256,512等这类$2^n$的值。（Notes:在机器学习中，如果样本量过大的时候，我们通常会在没一轮的学习过程中选择部分样本来参与学习，同时增加学习的轮数，这样可以通过多次学习的方式，来提升每次训练的效率，并且因增加了学习的次数，也能够从整体上降低泛化误差）。\n\n### 梯度下降法应用场景\n损失函数必须是凸函数，即存在局部极小值点\n\n-------\n\n## 基本牛顿法\n### 牛顿-拉夫森法\n基本牛顿法在优化问题中的应用实际上是来源于牛顿-拉夫森法，该方法是用来求解函数的零点的方法，那么这个方法到底是什么方法呢，实际上，该方法是建立在泰勒展开公式的基础上，通过使原方程泰勒展开的一阶近似等于零不断获得更好的结果的求解方程零点的方法。简单来说，具有以下特点：\n    1. 牛顿法是求解方程零点的方法\n    2. 牛顿法利用泰勒展开的一阶近似的零点获得更接近真实零点的点\n    3. 牛顿法通过迭代的方法不断的获得更好的解来求得最好的解\n\n首先，假设存在一个函数$f(\\vec{x})$,那么利用泰勒展开公式，将其进行一阶泰勒展开$f(\\vec{x})=f(\\vec{x_0})+\\frac{\\partial f(\\vec{x})}{\\partial \\vec{x}}|_{\\vec{x}=\\vec{x_{0}}}(\\vec{x}-\\vec{x_0}))$，我们可以求解出展开式的零点，即令\n$$\n\\begin{split}\n& f(\\vec{x_0})+\\frac{\\partial f(\\vec{x})}{\\partial \\vec{x}}|_{\\vec{x}=\\vec{x_{0}}}(\\vec{x}-\\vec{x_0}))=0 \\\\\n=> & \\vec{x}_1=\\vec{x_0}-\\frac{f(\\vec{x_0})}{\\frac{\\partial f(\\vec{x})}{\\partial \\vec{x}}|_{\\vec{x}=\\vec{x_0}}}\n\\end{split}\n$$\n然后再在$\\vec{x}_1$处进行一阶泰勒展开，如此迭代求解，可以计算得到:\n$$\n\\vec{x}_n=\\vec{x_{n-1}}-\\frac{f(\\vec{x_{n-1}})}{\\frac{\\partial f(\\vec{x})}{\\partial \\vec{x}}|_{\\vec{x}=\\vec{x_{n-1}}}}\n$$\n然后判断$f(\\vec{x_{n-1}})<\\epsilon$，如果满足，则停止迭代，说明此时的$\\vec{x}_{n-1}$就是函数$f(\\vec{x})$的零点。\n\n### 基本牛顿优化法\n当我们需要求解一个函数的极值点点的时候，最重要的判断条件就是$\\frac{\\partial f}{\\partial \\vec\\theta} = 0$，也就是函数的一阶导数为0时所对应的点。那么，如果要用牛顿法来解决最优化的问题，最根本的问题就是，使用牛顿-拉夫森方法来求解$\\frac{\\partial f}{\\partial \\vec\\theta}$的零点。\n首先，我们对函数进行二阶泰勒展开：\n$\n\\begin{split}\n& f(\\vec{x})=f(\\vec{x_0})+\\frac{\\partial f(\\vec{x})}{\\partial \\vec{x}}|_{\\vec{x}=\\vec{x_{0}}}(\\vec{x}-\\vec{x_0}))+\\frac{1}{2}\\frac{\\partial ^{2} f(\\vec{x})}{\\partial ^{2} \\vec{x}}|_{\\vec{x}=\\vec{x_{0}}}(\\vec{x}-\\vec{x_0})^{2}) \\\\\n\\end{split}\n$\n对上述公式求导：\n$$\n\\begin{split}\n& \\frac{\\partial f(\\vec{x})}{\\partial \\vec{x}}= &\\frac{\\partial f(\\vec{x})}{\\partial \\vec{x}}|_{\\vec{x}=\\vec{x_{0}}} + \\frac{\\partial ^{2} f(\\vec{x})}{\\partial ^{2} \\vec{x}}|_{\\vec{x}=\\vec{x_{0}}}(\\vec{x}-\\vec{x_0}) \\\\\n=> & \\vec{x}_n=\\vec{x_{n-1}}-\\frac{f(\\frac{\\partial f(\\vec{x})}{\\partial \\vec{x}}|_{\\vec{x}=\\vec{x_{n-1}}}}{\\frac{\\partial^{2} f(\\vec{x})}{\\partial^{2} \\vec{x}}|_{\\vec{x}=\\vec{x_{n-1}}}}\n\\end{split} \n$$\n因此，由上述公式可知，我们可以通过函数的一阶导数和二阶导数不断迭代计算出$\\vec{x}$,\n然后判断$\\frac{\\partial f(\\vec{x})}{\\partial\\vec{x}}|_{\\vec{x}=\\vec{x_{n-1}}}<\\epsilon$，如果满足，则停止迭代，说明此时的$\\vec{x}_{n-1}$就是函数$f(\\vec{x})$一阶导数的零点。\n\n在机器学习中，二阶导数就是海森矩阵。\n\n### 牛顿法的优缺点\n实际上牛顿法与梯度下降法在优化问题上的本质方法是一致的，唯一的区别是在于如何求解的问题，在牛顿法中的海森矩阵就相当于梯度下降法中的学习率（步长）。牛顿法收敛速度相比梯度下降法很快，而且由于海森矩阵的的逆在迭代中不断减小，起到逐渐缩小步长的效果。但是，如果样本量非常大，那么会导致计算海森矩阵的效率很慢，同时还需要大量的计算资源。\n\n## 拟牛顿法\n为了解决牛顿法中求解海森矩阵的问题，我们可以在满足拟牛顿条件的基础上构造一个近似的海森矩阵，用近似值来代替标准的海森矩阵参与计算。常用的近似计算算法有DFP算法，BFGS算法，L-BFGS算法以及Broyden类算法等。\n//todo\n\n-------\n\n\n## 最小二乘法\n最小二乘法也是用来估计这样一种参数，该参数能够使得观测值和理论值之差的平方和最小，通常是用来优化线性模型，从最小二乘法的概念上可知，其应用的目标函数是非常受限的，也就是说，其优化的目标函数必须是服从以下形式的：\n$L(\\theta)=\\sum_{i=1}^{m}{(y-y^h)}^2$.\n为什么要用这个平方和来表示损失函数呢？什么是最小二乘法的理论基础呢？实际上，最小二乘法是符合矩阵投影理论和高斯正态误差理论的。\n在深入理解最小二乘法之前，我们需要定义**误差**，如果从线性空间的角度来看的话，误差是什么？误差其实就是在空间中寻找两个向量之间的差值最小。如下图，我们可以假设$\\vec{b}$是一个标准的值，那么如果存在一个特定的映射模型，将确定为$\\vec{a}$，那么我们需要在$\\vec{a}$这个向量中寻找出与$\\vec{b}$误差最小的一个向量点，也就是$\\vec{p}$.\n![](/images/mse_ill.jpg)\n\n结合线性模型来理解的话，通常$\\vec{y}$指的是空间中的一个向量，而线性模型中的参数向量实际上是一种变换，这种变换会将空间中的点$\\matrix{X}$映射出$\\vec{y^g}$,但是，由于我们通常是无法准确地获得$\\matrix{X}$与$\\vec{y}$之间的映射关系，一方面是因为数据测量的误差，另一方面是模型本身存在误差；因此，$\\vec{y}$与$\\vec{y}$之间是存在误差的。实际上，寻找最优模型实际上就是寻找最优的$\\vec{a}$。\n### 最小二乘法的矩阵表示形式\n假设损失函数为$L(\\theta) = \\frac{1}{2}(\\vec{y}-\\matrix{X}\\theta)^T(\\vec{y}-\\matrix{X}\\theta)$，那么，根据最小二乘法原理，对$L$针对$\\theta$求导，并将其赋值为0，从而求解出$\\theta$的值。\n$$\n\\begin{split}\n\\frac{\\partial L}{\\partial \\theta}= &\\frac{1}{2}\\frac{\\partial(\\vec{y}^T\\vec{y}-\\vec{y}^T\\matrix{X}\\vec{\\theta}-\\vec{\\theta}^{T}\\matrix{X}^T\\vec{y}+\\vec{\\theta}^T\\matrix{X}^T\\matrix{X}\\vec{\\theta})}{\\partial \\vec\\theta} \\\\\n=&\\frac{1}{2}(-\\vec{y}^T\\matrix{X}-\\frac{\\partial{(\\vec{\\theta}^{T}\\matrix{X}^T\\vec{y}})^T}{\\vec{\\theta}}+\\vec\\theta^T\\matrix{X}^T\\matrix{X}+\\frac{\\partial\\theta^T }{\\partial\\vec{\\theta}}\\matrix{X}^T\\matrix{X}\\vec{\\theta}) \\\\\n= & \\frac{1}{2}(-\\vec{y}^T\\matrix{X}-\\vec{y}^T\\matrix{X}+\\vec\\theta^T\\matrix{X}^T\\matrix{X}+\\frac{(\\partial\\vec\\theta^{T} \\cdot \\matrix{X}^T\\matrix{X}\\vec{\\theta})^T}{\\partial\\vec\\theta}) \\\\\n= & \\frac{1}{2}(-2\\vec{y}^T\\matrix{X} + 2\\vec\\theta^T\\matrix{X}^T\\matrix{X})=0\n\\end{split} \n$$\n基于上式，可以推导出$\\vec\\theta=(\\matrix{X}^T\\matrix{X})^{-1}\\matrix{X}^T\\vec{y}$\n\n(Notes:一个函数的维度和该函数的微分的维度是保持一致的)\n\n### 最小二乘法的应用场景\n1. 模型必须是线性模型，求解的损失函数是误差的平方和，（如果不是线性的，则需要通过非线性函数映射，将其映射为线性模型，eg：$g(\\vec{y})=\\matrix{X}\\vec\\theta$,令$h=g(\\vec{y})$，则此时可以针对$\\vec{h}$与$\\matrix{X}$构建线性模型）\n2. $\\matrix{X}^T\\matrix{X}$必须要是可逆。\n\n-------\n\n## 最大似然估计\n最大似然估计法是统计学中一个用来求解参数模型中参数的方法，这种方法和前面的优化算法类似，也是要求具有明确的模型，然后根据观测的数据来求解模型中未知的参数。\n\n### 最大似然原理\n**似然函数**表示的是统计模型中关于参数的一种函数，这种函数表达的含义是参数的似然性（或者说该参数取某个值的概率性）。\n在统计学中，假定存在一个分布$D$,并且假设该分布的概率密度函数（连续型）或者概率质量函数（离散型）为$f_\\theta$，并且该函数是关于参数$\\theta$的一个函数。那么我们独立地从该分布中抽取出$n$个数据,分别为$X_1,X_2,...,X_n$，那么，通过这n个观测的数据，我们可以计算出模型中参数$\\theta$的似然函数，如下：\n$lik(\\theta|x_1,x_2,...,x_n)=f_\\theta(x_1,x_2,...,x_n)$\n由最大似然原理可知，要使用最大似然估计最重要的一点就是需要知道数据分布的概率密度函数或者概率质量函数，同时，该函数也是我们的建模函数，也就是说，我们针对一个特定的业务问题，通过构建关于该问题的概率密度函数或者概率质量函数模型，然后通过最大似然函数求解该模型中的参数，得到一个精确的函数。\n\n### 最大似然估计法原理\n基于最大似然原理可知，我们需要计算模型中的参数的时候，需要构建该参数的似然函数，那么怎么才能得到这个似然函数呢，最好的方式就是根据已知的观测数据，来计算这个似然函数，具体来说就是构建如下似然函数：\n$f(x_1,x_2,...,x_n|\\theta)$，显然，这是一个联合概率分布.\n1. 那么为了简化这个问题的计算过程，通常会假设所有的数据样本之间是独立的，因此，有如下表达式：\n$f(x_1,x_2,...,x_n|\\theta)=\\prod_{i=1}^{n} f(x_i|\\theta)$\n2. 同时，由于连乘计算不方便，因此，会对上述公式取对数，从而转变为加法计算，这样非常方便求解函数的极值点。\n最大似然估计法最根本的就是求解$f(x_1,...,x_n)$的最大值。\n\n最大似然估计法的步骤入下：\n1. 写出似然函数\n2. 对似然函数取对数，并整理；\n3. 求导数 ；\n4. 解似然方程\n\n（Notes：最大似然估计只考虑某个模型能产生某个给定观察序列的概率，而未考虑该模型本身的概率）\n\n\n## 参考文献\n1. http://www.cnblogs.com/pinard/p/5970503.html\n2. https://www.zhihu.com/question/37031188\n3. http://www.matongxue.com/madocs/205.html#/madoc\n\n\n\n\n\n\n\n","source":"_posts/机器学习中常用优化算法总结.md","raw":"---\ntitle: 机器学习中常用优化算法总结\ndate: 2019-01-31 10:41:59\ntags: 机器学习\ncategories: 机器学习\nmathjax: true\n---\n\n优化算法是机器学习中的“方法论”，优化算法会告诉机器应该如何优化学习的进程，让自己能够更好地掌握学习到的知识，本文将针对机器学习领域中常用的几种优化算法进行总结。\n\n## 梯度下降法\n### 梯度下降法与梯度、导数的概念\n梯度下降法是用来求解无约束优化问题的一种数学方法，通过梯度下降法可以获取到函数的局部极小值。这里存在一个概念“梯度”，梯度的本意实际上是一个向量，及具有方向性和数值性，其表示的是一个函数在改点沿着该方向变化最快（这个方向是往函数值变大的方向），这个变化率实际上就是该梯度的模。因此，在使用梯度下降法的时候，实际上是要求我们选择梯度的反方向进行计算，只有这样才能保证我们能够取到极小值，这也就是为什么在使用导数（导数与梯度实际上是同一个概念，只不过梯度是一种抽象的表述概念，而导数是实际上用来求解梯度的一种数学表示方式，导数值前面的正负号实际上是决定了梯度的方向）进行参数迭代的时候是要在导数的前面加上负号。\n![](/images/gradient_ill.jpg)\n\n如上图所示，我们对函数f在A点对自变量x求解右导数$f^\\prime$，其值为正数，那是因为在A点右侧函数值是增大的，因此，如果要想f值变小，则需要让往左移$x=x_a-\\delta f^\\prime$；对B点求解右导数，其值为负数，那是因为在B点右侧函数值是变小的，因此，如果想要f值变小，则需要让x往右移$x=x_a-\\delta f^\\prime$，因此，如果是要使用梯度下降法，则在迭代过程中要在导数的前面加上负号。\n<!-- more -->\n\n### 梯度下降法详解\n#### 应用前提条件\n首先，我们得需要明确梯度下降法并不是万能的，因为在机器学习领域中，存在一个叫做NFL(No Free Launch)定理，这个定理说明了不存在一种模型或者算法能够适应于所有的应用场景。那么既然如此，梯度下降法能够应用于哪些场景中呢。其实从梯度下降法的原理来看，只要我们沿着梯度方向能够寻找到合适的最小值，那么就可以使用梯度下降法，那么如何判断什么样的函数是满足梯度下降法的应用的呢，最简单的一种方法就是判断该函数是否是**下凸函数**，如果一个函数是下凸函数，那么我们就可以针对该函数使用梯度下降法来求解最小值。当然，对于下凸函数可能会存在很多个局部极小值点，那么在这种情况下，使用梯度下降法来求解函数的最小值可能会存在一些偏差，那么此时，会通过一些技术性的措施（比如：采用随机性，分别从不同起始点多次进行梯度下降求解等）来优化我们使用梯度下降法的过程。\n\n在梯度下降法中，通常需要优先确定以下条件：\n    1. 步长,也成为学习率 $\\alpha$\n    2. 目标函数（损失函数，但是在确定损失函数过程$ L(\\theta) $，需要优先确定模型$ h\\_\\theta(x) $）\n基于上述两点先决条件，可以获得梯度下降法中最关键的表达式：\n$ \\theta_t = \\theta_{t-1}-\\alpha \\frac{\\partial L}{\\partial x} $\n\n下面将分别基于**线性回归模型**来阐述代数形式和矩阵形式下的梯度下降法。\n\n#### 梯度下降法的代数形式表达\n1. 假设有一组数据集$(x_1^1,x_2^1,...,x_n^1,y^1),(x_1^2,x_2^2,...,x_n^2,y^2),...,(x_1^m,x_2^m,...,x_n^m,y^m)$，该数据集共有m个样本，每个样本包含有n个特征量。\n如果我们想通过线性回归模型来构建$x$与$y$之间的关系，可得如下模型：$h_\\theta(x_1,x_2,...,x_n)=\\theta_0+\\theta_1 x_1 + ... + \\theta_n x_n$,\n2. 采用线性模型常用的误差平方和作为损失函数L:\n$L(\\theta_0,theta_1,...,theta_n)=\\frac{1}{2m}\\sum_{j=1}^m(y_j-h_\\theta(x_1^j,x_2^j,...,x_n^j)^2)$\n3. 使用梯度下降法求解，需要初始化相关参数，主要包含了$\\theta$、$\\alpha$、以及迭代停止距离$\\epsilon$,通常我们可以将$\\alpha$设置为0.9，$\\theta$设置为0。\n4. 算法流程如下：\n    Step1:计算当前$L(\\theta_0,\\theta_1,...,\\theta_n)$关于每个$\\theta_i$的梯度：$\\frac{\\partial L}{\\partial \\theta_i}$；\n    Step2:用步长$\\alpha$乘以Step1中求得的每个关于$\\theta_i$的梯度，得到每个$\\theta_i$下降的距离$d_i$；\n    Step3:判断每个$\\theta_i$的梯度下降距离$d_i$的值是否都小于终止条件$\\epsilon$,如果是，则停止学习，将当前的学习到的所有的$\\theta_i$作为最终习得的参数，反之，进入Step4;\n    Step3:更新所有的$\\theta_i$,更新公式如下：$\\theta_i=\\theta_i-\\alpha \\frac{\\partial L}{\\partial \\theta_i}$,然后重复Step1~Step3.\n#### 梯度下降法的矩阵形式表达\n梯度下降法的矩阵表达形式实际上上对代数形式的矩阵话，为什么需要矩阵化？因为在实际的计算过程中，矩阵运算的效率与高于循环计算的效率，能够提升学习的效率。\n\n通常我们会将样本数据集表示为$\\matrix{X_{m \\times n}}$，其中，$m$表示样本的个数，即矩阵的每一行表示一个样本信息，$n$表示样本中的特征量的个数，即矩阵中的每列表示的是一个特征量的取值。并且通常在机器学习领域中将向量表示为列向量，因此，所有的参数$\\theta_i$可以表示为向量$\\vec{\\theta}$.\n\n根据上述定义的矩阵和向量信息，可以重新表达线性模型：$\\vec{y}=\\matrix{X}\\theta$,同时，损失函数可以表示为：$L(\\theta) = \\frac{1}{2}(\\vec{y}-\\matrix{X}\\theta)^T(\\vec{y}-\\matrix{X}\\theta)$，预先设置的参数步骤和代数形式是一致的，算法过程也是一致的，唯一的区别是在计算过程中变成了矩阵话运算。\n\n#### 梯度下降法的变形\n上文所阐述的梯度下降法实际上是在每一轮迭代的过程中针对所有的样本进行梯度计算与梯度下降判断的，也可以成为**全批量梯度下降法（Batch Gradient Descent）**，这样的方法具有以下缺点：如果样本量非常大的时候，计算的效率会降低，但是也具有准确率高的优点；\n针对BGD算法效率低的问题，又提出了一种**随机梯度下降法（Stochastic Gradient Descent）**，顾名思义，这种做法是每一轮迭代都只随机选取一个样本进行计算，这种方式大大提升了计算的效率，但是，由于每一次都是随机选取一个样本进行迭代计算，那么会导致获得的参数值并不是局部最优解，同时，这样方式还会导致每次迭代时的方向会不稳定，即整体的收敛速度会下降；\n针对上述两种极端的梯度下降法，又提出了一种**小批量梯度下降法（Mini-Batch Gradient Descent）**，这种方法通常是选择部分样本参与计算，通常每轮迭代选择的样本量为16,32,64,128,256,512等这类$2^n$的值。（Notes:在机器学习中，如果样本量过大的时候，我们通常会在没一轮的学习过程中选择部分样本来参与学习，同时增加学习的轮数，这样可以通过多次学习的方式，来提升每次训练的效率，并且因增加了学习的次数，也能够从整体上降低泛化误差）。\n\n### 梯度下降法应用场景\n损失函数必须是凸函数，即存在局部极小值点\n\n-------\n\n## 基本牛顿法\n### 牛顿-拉夫森法\n基本牛顿法在优化问题中的应用实际上是来源于牛顿-拉夫森法，该方法是用来求解函数的零点的方法，那么这个方法到底是什么方法呢，实际上，该方法是建立在泰勒展开公式的基础上，通过使原方程泰勒展开的一阶近似等于零不断获得更好的结果的求解方程零点的方法。简单来说，具有以下特点：\n    1. 牛顿法是求解方程零点的方法\n    2. 牛顿法利用泰勒展开的一阶近似的零点获得更接近真实零点的点\n    3. 牛顿法通过迭代的方法不断的获得更好的解来求得最好的解\n\n首先，假设存在一个函数$f(\\vec{x})$,那么利用泰勒展开公式，将其进行一阶泰勒展开$f(\\vec{x})=f(\\vec{x_0})+\\frac{\\partial f(\\vec{x})}{\\partial \\vec{x}}|_{\\vec{x}=\\vec{x_{0}}}(\\vec{x}-\\vec{x_0}))$，我们可以求解出展开式的零点，即令\n$$\n\\begin{split}\n& f(\\vec{x_0})+\\frac{\\partial f(\\vec{x})}{\\partial \\vec{x}}|_{\\vec{x}=\\vec{x_{0}}}(\\vec{x}-\\vec{x_0}))=0 \\\\\n=> & \\vec{x}_1=\\vec{x_0}-\\frac{f(\\vec{x_0})}{\\frac{\\partial f(\\vec{x})}{\\partial \\vec{x}}|_{\\vec{x}=\\vec{x_0}}}\n\\end{split}\n$$\n然后再在$\\vec{x}_1$处进行一阶泰勒展开，如此迭代求解，可以计算得到:\n$$\n\\vec{x}_n=\\vec{x_{n-1}}-\\frac{f(\\vec{x_{n-1}})}{\\frac{\\partial f(\\vec{x})}{\\partial \\vec{x}}|_{\\vec{x}=\\vec{x_{n-1}}}}\n$$\n然后判断$f(\\vec{x_{n-1}})<\\epsilon$，如果满足，则停止迭代，说明此时的$\\vec{x}_{n-1}$就是函数$f(\\vec{x})$的零点。\n\n### 基本牛顿优化法\n当我们需要求解一个函数的极值点点的时候，最重要的判断条件就是$\\frac{\\partial f}{\\partial \\vec\\theta} = 0$，也就是函数的一阶导数为0时所对应的点。那么，如果要用牛顿法来解决最优化的问题，最根本的问题就是，使用牛顿-拉夫森方法来求解$\\frac{\\partial f}{\\partial \\vec\\theta}$的零点。\n首先，我们对函数进行二阶泰勒展开：\n$\n\\begin{split}\n& f(\\vec{x})=f(\\vec{x_0})+\\frac{\\partial f(\\vec{x})}{\\partial \\vec{x}}|_{\\vec{x}=\\vec{x_{0}}}(\\vec{x}-\\vec{x_0}))+\\frac{1}{2}\\frac{\\partial ^{2} f(\\vec{x})}{\\partial ^{2} \\vec{x}}|_{\\vec{x}=\\vec{x_{0}}}(\\vec{x}-\\vec{x_0})^{2}) \\\\\n\\end{split}\n$\n对上述公式求导：\n$$\n\\begin{split}\n& \\frac{\\partial f(\\vec{x})}{\\partial \\vec{x}}= &\\frac{\\partial f(\\vec{x})}{\\partial \\vec{x}}|_{\\vec{x}=\\vec{x_{0}}} + \\frac{\\partial ^{2} f(\\vec{x})}{\\partial ^{2} \\vec{x}}|_{\\vec{x}=\\vec{x_{0}}}(\\vec{x}-\\vec{x_0}) \\\\\n=> & \\vec{x}_n=\\vec{x_{n-1}}-\\frac{f(\\frac{\\partial f(\\vec{x})}{\\partial \\vec{x}}|_{\\vec{x}=\\vec{x_{n-1}}}}{\\frac{\\partial^{2} f(\\vec{x})}{\\partial^{2} \\vec{x}}|_{\\vec{x}=\\vec{x_{n-1}}}}\n\\end{split} \n$$\n因此，由上述公式可知，我们可以通过函数的一阶导数和二阶导数不断迭代计算出$\\vec{x}$,\n然后判断$\\frac{\\partial f(\\vec{x})}{\\partial\\vec{x}}|_{\\vec{x}=\\vec{x_{n-1}}}<\\epsilon$，如果满足，则停止迭代，说明此时的$\\vec{x}_{n-1}$就是函数$f(\\vec{x})$一阶导数的零点。\n\n在机器学习中，二阶导数就是海森矩阵。\n\n### 牛顿法的优缺点\n实际上牛顿法与梯度下降法在优化问题上的本质方法是一致的，唯一的区别是在于如何求解的问题，在牛顿法中的海森矩阵就相当于梯度下降法中的学习率（步长）。牛顿法收敛速度相比梯度下降法很快，而且由于海森矩阵的的逆在迭代中不断减小，起到逐渐缩小步长的效果。但是，如果样本量非常大，那么会导致计算海森矩阵的效率很慢，同时还需要大量的计算资源。\n\n## 拟牛顿法\n为了解决牛顿法中求解海森矩阵的问题，我们可以在满足拟牛顿条件的基础上构造一个近似的海森矩阵，用近似值来代替标准的海森矩阵参与计算。常用的近似计算算法有DFP算法，BFGS算法，L-BFGS算法以及Broyden类算法等。\n//todo\n\n-------\n\n\n## 最小二乘法\n最小二乘法也是用来估计这样一种参数，该参数能够使得观测值和理论值之差的平方和最小，通常是用来优化线性模型，从最小二乘法的概念上可知，其应用的目标函数是非常受限的，也就是说，其优化的目标函数必须是服从以下形式的：\n$L(\\theta)=\\sum_{i=1}^{m}{(y-y^h)}^2$.\n为什么要用这个平方和来表示损失函数呢？什么是最小二乘法的理论基础呢？实际上，最小二乘法是符合矩阵投影理论和高斯正态误差理论的。\n在深入理解最小二乘法之前，我们需要定义**误差**，如果从线性空间的角度来看的话，误差是什么？误差其实就是在空间中寻找两个向量之间的差值最小。如下图，我们可以假设$\\vec{b}$是一个标准的值，那么如果存在一个特定的映射模型，将确定为$\\vec{a}$，那么我们需要在$\\vec{a}$这个向量中寻找出与$\\vec{b}$误差最小的一个向量点，也就是$\\vec{p}$.\n![](/images/mse_ill.jpg)\n\n结合线性模型来理解的话，通常$\\vec{y}$指的是空间中的一个向量，而线性模型中的参数向量实际上是一种变换，这种变换会将空间中的点$\\matrix{X}$映射出$\\vec{y^g}$,但是，由于我们通常是无法准确地获得$\\matrix{X}$与$\\vec{y}$之间的映射关系，一方面是因为数据测量的误差，另一方面是模型本身存在误差；因此，$\\vec{y}$与$\\vec{y}$之间是存在误差的。实际上，寻找最优模型实际上就是寻找最优的$\\vec{a}$。\n### 最小二乘法的矩阵表示形式\n假设损失函数为$L(\\theta) = \\frac{1}{2}(\\vec{y}-\\matrix{X}\\theta)^T(\\vec{y}-\\matrix{X}\\theta)$，那么，根据最小二乘法原理，对$L$针对$\\theta$求导，并将其赋值为0，从而求解出$\\theta$的值。\n$$\n\\begin{split}\n\\frac{\\partial L}{\\partial \\theta}= &\\frac{1}{2}\\frac{\\partial(\\vec{y}^T\\vec{y}-\\vec{y}^T\\matrix{X}\\vec{\\theta}-\\vec{\\theta}^{T}\\matrix{X}^T\\vec{y}+\\vec{\\theta}^T\\matrix{X}^T\\matrix{X}\\vec{\\theta})}{\\partial \\vec\\theta} \\\\\n=&\\frac{1}{2}(-\\vec{y}^T\\matrix{X}-\\frac{\\partial{(\\vec{\\theta}^{T}\\matrix{X}^T\\vec{y}})^T}{\\vec{\\theta}}+\\vec\\theta^T\\matrix{X}^T\\matrix{X}+\\frac{\\partial\\theta^T }{\\partial\\vec{\\theta}}\\matrix{X}^T\\matrix{X}\\vec{\\theta}) \\\\\n= & \\frac{1}{2}(-\\vec{y}^T\\matrix{X}-\\vec{y}^T\\matrix{X}+\\vec\\theta^T\\matrix{X}^T\\matrix{X}+\\frac{(\\partial\\vec\\theta^{T} \\cdot \\matrix{X}^T\\matrix{X}\\vec{\\theta})^T}{\\partial\\vec\\theta}) \\\\\n= & \\frac{1}{2}(-2\\vec{y}^T\\matrix{X} + 2\\vec\\theta^T\\matrix{X}^T\\matrix{X})=0\n\\end{split} \n$$\n基于上式，可以推导出$\\vec\\theta=(\\matrix{X}^T\\matrix{X})^{-1}\\matrix{X}^T\\vec{y}$\n\n(Notes:一个函数的维度和该函数的微分的维度是保持一致的)\n\n### 最小二乘法的应用场景\n1. 模型必须是线性模型，求解的损失函数是误差的平方和，（如果不是线性的，则需要通过非线性函数映射，将其映射为线性模型，eg：$g(\\vec{y})=\\matrix{X}\\vec\\theta$,令$h=g(\\vec{y})$，则此时可以针对$\\vec{h}$与$\\matrix{X}$构建线性模型）\n2. $\\matrix{X}^T\\matrix{X}$必须要是可逆。\n\n-------\n\n## 最大似然估计\n最大似然估计法是统计学中一个用来求解参数模型中参数的方法，这种方法和前面的优化算法类似，也是要求具有明确的模型，然后根据观测的数据来求解模型中未知的参数。\n\n### 最大似然原理\n**似然函数**表示的是统计模型中关于参数的一种函数，这种函数表达的含义是参数的似然性（或者说该参数取某个值的概率性）。\n在统计学中，假定存在一个分布$D$,并且假设该分布的概率密度函数（连续型）或者概率质量函数（离散型）为$f_\\theta$，并且该函数是关于参数$\\theta$的一个函数。那么我们独立地从该分布中抽取出$n$个数据,分别为$X_1,X_2,...,X_n$，那么，通过这n个观测的数据，我们可以计算出模型中参数$\\theta$的似然函数，如下：\n$lik(\\theta|x_1,x_2,...,x_n)=f_\\theta(x_1,x_2,...,x_n)$\n由最大似然原理可知，要使用最大似然估计最重要的一点就是需要知道数据分布的概率密度函数或者概率质量函数，同时，该函数也是我们的建模函数，也就是说，我们针对一个特定的业务问题，通过构建关于该问题的概率密度函数或者概率质量函数模型，然后通过最大似然函数求解该模型中的参数，得到一个精确的函数。\n\n### 最大似然估计法原理\n基于最大似然原理可知，我们需要计算模型中的参数的时候，需要构建该参数的似然函数，那么怎么才能得到这个似然函数呢，最好的方式就是根据已知的观测数据，来计算这个似然函数，具体来说就是构建如下似然函数：\n$f(x_1,x_2,...,x_n|\\theta)$，显然，这是一个联合概率分布.\n1. 那么为了简化这个问题的计算过程，通常会假设所有的数据样本之间是独立的，因此，有如下表达式：\n$f(x_1,x_2,...,x_n|\\theta)=\\prod_{i=1}^{n} f(x_i|\\theta)$\n2. 同时，由于连乘计算不方便，因此，会对上述公式取对数，从而转变为加法计算，这样非常方便求解函数的极值点。\n最大似然估计法最根本的就是求解$f(x_1,...,x_n)$的最大值。\n\n最大似然估计法的步骤入下：\n1. 写出似然函数\n2. 对似然函数取对数，并整理；\n3. 求导数 ；\n4. 解似然方程\n\n（Notes：最大似然估计只考虑某个模型能产生某个给定观察序列的概率，而未考虑该模型本身的概率）\n\n\n## 参考文献\n1. http://www.cnblogs.com/pinard/p/5970503.html\n2. https://www.zhihu.com/question/37031188\n3. http://www.matongxue.com/madocs/205.html#/madoc\n\n\n\n\n\n\n\n","slug":"机器学习中常用优化算法总结","published":1,"updated":"2019-01-31T04:01:57.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjsa3xp3v000l3lxy94h5a1zd","content":"<p>优化算法是机器学习中的“方法论”，优化算法会告诉机器应该如何优化学习的进程，让自己能够更好地掌握学习到的知识，本文将针对机器学习领域中常用的几种优化算法进行总结。</p>\n<h2 id=\"梯度下降法\"><a href=\"#梯度下降法\" class=\"headerlink\" title=\"梯度下降法\"></a>梯度下降法</h2><h3 id=\"梯度下降法与梯度、导数的概念\"><a href=\"#梯度下降法与梯度、导数的概念\" class=\"headerlink\" title=\"梯度下降法与梯度、导数的概念\"></a>梯度下降法与梯度、导数的概念</h3><p>梯度下降法是用来求解无约束优化问题的一种数学方法，通过梯度下降法可以获取到函数的局部极小值。这里存在一个概念“梯度”，梯度的本意实际上是一个向量，及具有方向性和数值性，其表示的是一个函数在改点沿着该方向变化最快（这个方向是往函数值变大的方向），这个变化率实际上就是该梯度的模。因此，在使用梯度下降法的时候，实际上是要求我们选择梯度的反方向进行计算，只有这样才能保证我们能够取到极小值，这也就是为什么在使用导数（导数与梯度实际上是同一个概念，只不过梯度是一种抽象的表述概念，而导数是实际上用来求解梯度的一种数学表示方式，导数值前面的正负号实际上是决定了梯度的方向）进行参数迭代的时候是要在导数的前面加上负号。<br><img src=\"/images/gradient_ill.jpg\" alt=\"\"></p>\n<p>如上图所示，我们对函数f在A点对自变量x求解右导数$f^\\prime$，其值为正数，那是因为在A点右侧函数值是增大的，因此，如果要想f值变小，则需要让往左移$x=x_a-\\delta f^\\prime$；对B点求解右导数，其值为负数，那是因为在B点右侧函数值是变小的，因此，如果想要f值变小，则需要让x往右移$x=x_a-\\delta f^\\prime$，因此，如果是要使用梯度下降法，则在迭代过程中要在导数的前面加上负号。<br><a id=\"more\"></a></p>\n<h3 id=\"梯度下降法详解\"><a href=\"#梯度下降法详解\" class=\"headerlink\" title=\"梯度下降法详解\"></a>梯度下降法详解</h3><h4 id=\"应用前提条件\"><a href=\"#应用前提条件\" class=\"headerlink\" title=\"应用前提条件\"></a>应用前提条件</h4><p>首先，我们得需要明确梯度下降法并不是万能的，因为在机器学习领域中，存在一个叫做NFL(No Free Launch)定理，这个定理说明了不存在一种模型或者算法能够适应于所有的应用场景。那么既然如此，梯度下降法能够应用于哪些场景中呢。其实从梯度下降法的原理来看，只要我们沿着梯度方向能够寻找到合适的最小值，那么就可以使用梯度下降法，那么如何判断什么样的函数是满足梯度下降法的应用的呢，最简单的一种方法就是判断该函数是否是<strong>下凸函数</strong>，如果一个函数是下凸函数，那么我们就可以针对该函数使用梯度下降法来求解最小值。当然，对于下凸函数可能会存在很多个局部极小值点，那么在这种情况下，使用梯度下降法来求解函数的最小值可能会存在一些偏差，那么此时，会通过一些技术性的措施（比如：采用随机性，分别从不同起始点多次进行梯度下降求解等）来优化我们使用梯度下降法的过程。</p>\n<p>在梯度下降法中，通常需要优先确定以下条件：</p>\n<pre><code>1. 步长,也成为学习率 $\\alpha$\n2. 目标函数（损失函数，但是在确定损失函数过程$ L(\\theta) $，需要优先确定模型$ h\\_\\theta(x) $）\n</code></pre><p>基于上述两点先决条件，可以获得梯度下降法中最关键的表达式：<br>$ \\theta_t = \\theta_{t-1}-\\alpha \\frac{\\partial L}{\\partial x} $</p>\n<p>下面将分别基于<strong>线性回归模型</strong>来阐述代数形式和矩阵形式下的梯度下降法。</p>\n<h4 id=\"梯度下降法的代数形式表达\"><a href=\"#梯度下降法的代数形式表达\" class=\"headerlink\" title=\"梯度下降法的代数形式表达\"></a>梯度下降法的代数形式表达</h4><ol>\n<li>假设有一组数据集$(x_1^1,x_2^1,…,x_n^1,y^1),(x_1^2,x_2^2,…,x_n^2,y^2),…,(x_1^m,x_2^m,…,x_n^m,y^m)$，该数据集共有m个样本，每个样本包含有n个特征量。<br>如果我们想通过线性回归模型来构建$x$与$y$之间的关系，可得如下模型：$h_\\theta(x_1,x_2,…,x_n)=\\theta_0+\\theta_1 x_1 + … + \\theta_n x_n$,</li>\n<li>采用线性模型常用的误差平方和作为损失函数L:<br>$L(\\theta_0,theta_1,…,theta_n)=\\frac{1}{2m}\\sum_{j=1}^m(y_j-h_\\theta(x_1^j,x_2^j,…,x_n^j)^2)$</li>\n<li>使用梯度下降法求解，需要初始化相关参数，主要包含了$\\theta$、$\\alpha$、以及迭代停止距离$\\epsilon$,通常我们可以将$\\alpha$设置为0.9，$\\theta$设置为0。</li>\n<li>算法流程如下：<br> Step1:计算当前$L(\\theta_0,\\theta_1,…,\\theta_n)$关于每个$\\theta_i$的梯度：$\\frac{\\partial L}{\\partial \\theta_i}$；<br> Step2:用步长$\\alpha$乘以Step1中求得的每个关于$\\theta_i$的梯度，得到每个$\\theta_i$下降的距离$d_i$；<br> Step3:判断每个$\\theta_i$的梯度下降距离$d_i$的值是否都小于终止条件$\\epsilon$,如果是，则停止学习，将当前的学习到的所有的$\\theta_i$作为最终习得的参数，反之，进入Step4;<br> Step3:更新所有的$\\theta_i$,更新公式如下：$\\theta_i=\\theta_i-\\alpha \\frac{\\partial L}{\\partial \\theta_i}$,然后重复Step1~Step3.<h4 id=\"梯度下降法的矩阵形式表达\"><a href=\"#梯度下降法的矩阵形式表达\" class=\"headerlink\" title=\"梯度下降法的矩阵形式表达\"></a>梯度下降法的矩阵形式表达</h4>梯度下降法的矩阵表达形式实际上上对代数形式的矩阵话，为什么需要矩阵化？因为在实际的计算过程中，矩阵运算的效率与高于循环计算的效率，能够提升学习的效率。</li>\n</ol>\n<p>通常我们会将样本数据集表示为$\\matrix{X_{m \\times n}}$，其中，$m$表示样本的个数，即矩阵的每一行表示一个样本信息，$n$表示样本中的特征量的个数，即矩阵中的每列表示的是一个特征量的取值。并且通常在机器学习领域中将向量表示为列向量，因此，所有的参数$\\theta_i$可以表示为向量$\\vec{\\theta}$.</p>\n<p>根据上述定义的矩阵和向量信息，可以重新表达线性模型：$\\vec{y}=\\matrix{X}\\theta$,同时，损失函数可以表示为：$L(\\theta) = \\frac{1}{2}(\\vec{y}-\\matrix{X}\\theta)^T(\\vec{y}-\\matrix{X}\\theta)$，预先设置的参数步骤和代数形式是一致的，算法过程也是一致的，唯一的区别是在计算过程中变成了矩阵话运算。</p>\n<h4 id=\"梯度下降法的变形\"><a href=\"#梯度下降法的变形\" class=\"headerlink\" title=\"梯度下降法的变形\"></a>梯度下降法的变形</h4><p>上文所阐述的梯度下降法实际上是在每一轮迭代的过程中针对所有的样本进行梯度计算与梯度下降判断的，也可以成为<strong>全批量梯度下降法（Batch Gradient Descent）</strong>，这样的方法具有以下缺点：如果样本量非常大的时候，计算的效率会降低，但是也具有准确率高的优点；<br>针对BGD算法效率低的问题，又提出了一种<strong>随机梯度下降法（Stochastic Gradient Descent）</strong>，顾名思义，这种做法是每一轮迭代都只随机选取一个样本进行计算，这种方式大大提升了计算的效率，但是，由于每一次都是随机选取一个样本进行迭代计算，那么会导致获得的参数值并不是局部最优解，同时，这样方式还会导致每次迭代时的方向会不稳定，即整体的收敛速度会下降；<br>针对上述两种极端的梯度下降法，又提出了一种<strong>小批量梯度下降法（Mini-Batch Gradient Descent）</strong>，这种方法通常是选择部分样本参与计算，通常每轮迭代选择的样本量为16,32,64,128,256,512等这类$2^n$的值。（Notes:在机器学习中，如果样本量过大的时候，我们通常会在没一轮的学习过程中选择部分样本来参与学习，同时增加学习的轮数，这样可以通过多次学习的方式，来提升每次训练的效率，并且因增加了学习的次数，也能够从整体上降低泛化误差）。</p>\n<h3 id=\"梯度下降法应用场景\"><a href=\"#梯度下降法应用场景\" class=\"headerlink\" title=\"梯度下降法应用场景\"></a>梯度下降法应用场景</h3><p>损失函数必须是凸函数，即存在局部极小值点</p>\n<hr>\n<h2 id=\"基本牛顿法\"><a href=\"#基本牛顿法\" class=\"headerlink\" title=\"基本牛顿法\"></a>基本牛顿法</h2><h3 id=\"牛顿-拉夫森法\"><a href=\"#牛顿-拉夫森法\" class=\"headerlink\" title=\"牛顿-拉夫森法\"></a>牛顿-拉夫森法</h3><p>基本牛顿法在优化问题中的应用实际上是来源于牛顿-拉夫森法，该方法是用来求解函数的零点的方法，那么这个方法到底是什么方法呢，实际上，该方法是建立在泰勒展开公式的基础上，通过使原方程泰勒展开的一阶近似等于零不断获得更好的结果的求解方程零点的方法。简单来说，具有以下特点：</p>\n<pre><code>1. 牛顿法是求解方程零点的方法\n2. 牛顿法利用泰勒展开的一阶近似的零点获得更接近真实零点的点\n3. 牛顿法通过迭代的方法不断的获得更好的解来求得最好的解\n</code></pre><p>首先，假设存在一个函数$f(\\vec{x})$,那么利用泰勒展开公式，将其进行一阶泰勒展开$f(\\vec{x})=f(\\vec{x_0})+\\frac{\\partial f(\\vec{x})}{\\partial \\vec{x}}|<em>{\\vec{x}=\\vec{x</em>{0}}}(\\vec{x}-\\vec{x_0}))$，我们可以求解出展开式的零点，即令<br>$$<br>\\begin{split}<br>&amp; f(\\vec{x_0})+\\frac{\\partial f(\\vec{x})}{\\partial \\vec{x}}|<em>{\\vec{x}=\\vec{x</em>{0}}}(\\vec{x}-\\vec{x_0}))=0 \\<br>=&gt; &amp; \\vec{x}_1=\\vec{x_0}-\\frac{f(\\vec{x_0})}{\\frac{\\partial f(\\vec{x})}{\\partial \\vec{x}}|_{\\vec{x}=\\vec{x_0}}}<br>\\end{split}<br>$$<br>然后再在$\\vec{x}_1$处进行一阶泰勒展开，如此迭代求解，可以计算得到:<br>$$<br>\\vec{x}<em>n=\\vec{x</em>{n-1}}-\\frac{f(\\vec{x_{n-1}})}{\\frac{\\partial f(\\vec{x})}{\\partial \\vec{x}}|<em>{\\vec{x}=\\vec{x</em>{n-1}}}}<br>$$<br>然后判断$f(\\vec{x_{n-1}})&lt;\\epsilon$，如果满足，则停止迭代，说明此时的$\\vec{x}_{n-1}$就是函数$f(\\vec{x})$的零点。</p>\n<h3 id=\"基本牛顿优化法\"><a href=\"#基本牛顿优化法\" class=\"headerlink\" title=\"基本牛顿优化法\"></a>基本牛顿优化法</h3><p>当我们需要求解一个函数的极值点点的时候，最重要的判断条件就是$\\frac{\\partial f}{\\partial \\vec\\theta} = 0$，也就是函数的一阶导数为0时所对应的点。那么，如果要用牛顿法来解决最优化的问题，最根本的问题就是，使用牛顿-拉夫森方法来求解$\\frac{\\partial f}{\\partial \\vec\\theta}$的零点。<br>首先，我们对函数进行二阶泰勒展开：<br>$<br>\\begin{split}<br>&amp; f(\\vec{x})=f(\\vec{x_0})+\\frac{\\partial f(\\vec{x})}{\\partial \\vec{x}}|<em>{\\vec{x}=\\vec{x</em>{0}}}(\\vec{x}-\\vec{x_0}))+\\frac{1}{2}\\frac{\\partial ^{2} f(\\vec{x})}{\\partial ^{2} \\vec{x}}|<em>{\\vec{x}=\\vec{x</em>{0}}}(\\vec{x}-\\vec{x_0})^{2}) \\<br>\\end{split}<br>$<br>对上述公式求导：<br>$$<br>\\begin{split}<br>&amp; \\frac{\\partial f(\\vec{x})}{\\partial \\vec{x}}= &amp;\\frac{\\partial f(\\vec{x})}{\\partial \\vec{x}}|<em>{\\vec{x}=\\vec{x</em>{0}}} + \\frac{\\partial ^{2} f(\\vec{x})}{\\partial ^{2} \\vec{x}}|<em>{\\vec{x}=\\vec{x</em>{0}}}(\\vec{x}-\\vec{x_0}) \\<br>=&gt; &amp; \\vec{x}<em>n=\\vec{x</em>{n-1}}-\\frac{f(\\frac{\\partial f(\\vec{x})}{\\partial \\vec{x}}|<em>{\\vec{x}=\\vec{x</em>{n-1}}}}{\\frac{\\partial^{2} f(\\vec{x})}{\\partial^{2} \\vec{x}}|<em>{\\vec{x}=\\vec{x</em>{n-1}}}}<br>\\end{split}<br>$$<br>因此，由上述公式可知，我们可以通过函数的一阶导数和二阶导数不断迭代计算出$\\vec{x}$,<br>然后判断$\\frac{\\partial f(\\vec{x})}{\\partial\\vec{x}}|<em>{\\vec{x}=\\vec{x</em>{n-1}}}&lt;\\epsilon$，如果满足，则停止迭代，说明此时的$\\vec{x}_{n-1}$就是函数$f(\\vec{x})$一阶导数的零点。</p>\n<p>在机器学习中，二阶导数就是海森矩阵。</p>\n<h3 id=\"牛顿法的优缺点\"><a href=\"#牛顿法的优缺点\" class=\"headerlink\" title=\"牛顿法的优缺点\"></a>牛顿法的优缺点</h3><p>实际上牛顿法与梯度下降法在优化问题上的本质方法是一致的，唯一的区别是在于如何求解的问题，在牛顿法中的海森矩阵就相当于梯度下降法中的学习率（步长）。牛顿法收敛速度相比梯度下降法很快，而且由于海森矩阵的的逆在迭代中不断减小，起到逐渐缩小步长的效果。但是，如果样本量非常大，那么会导致计算海森矩阵的效率很慢，同时还需要大量的计算资源。</p>\n<h2 id=\"拟牛顿法\"><a href=\"#拟牛顿法\" class=\"headerlink\" title=\"拟牛顿法\"></a>拟牛顿法</h2><p>为了解决牛顿法中求解海森矩阵的问题，我们可以在满足拟牛顿条件的基础上构造一个近似的海森矩阵，用近似值来代替标准的海森矩阵参与计算。常用的近似计算算法有DFP算法，BFGS算法，L-BFGS算法以及Broyden类算法等。<br>//todo</p>\n<hr>\n<h2 id=\"最小二乘法\"><a href=\"#最小二乘法\" class=\"headerlink\" title=\"最小二乘法\"></a>最小二乘法</h2><p>最小二乘法也是用来估计这样一种参数，该参数能够使得观测值和理论值之差的平方和最小，通常是用来优化线性模型，从最小二乘法的概念上可知，其应用的目标函数是非常受限的，也就是说，其优化的目标函数必须是服从以下形式的：<br>$L(\\theta)=\\sum_{i=1}^{m}{(y-y^h)}^2$.<br>为什么要用这个平方和来表示损失函数呢？什么是最小二乘法的理论基础呢？实际上，最小二乘法是符合矩阵投影理论和高斯正态误差理论的。<br>在深入理解最小二乘法之前，我们需要定义<strong>误差</strong>，如果从线性空间的角度来看的话，误差是什么？误差其实就是在空间中寻找两个向量之间的差值最小。如下图，我们可以假设$\\vec{b}$是一个标准的值，那么如果存在一个特定的映射模型，将确定为$\\vec{a}$，那么我们需要在$\\vec{a}$这个向量中寻找出与$\\vec{b}$误差最小的一个向量点，也就是$\\vec{p}$.<br><img src=\"/images/mse_ill.jpg\" alt=\"\"></p>\n<p>结合线性模型来理解的话，通常$\\vec{y}$指的是空间中的一个向量，而线性模型中的参数向量实际上是一种变换，这种变换会将空间中的点$\\matrix{X}$映射出$\\vec{y^g}$,但是，由于我们通常是无法准确地获得$\\matrix{X}$与$\\vec{y}$之间的映射关系，一方面是因为数据测量的误差，另一方面是模型本身存在误差；因此，$\\vec{y}$与$\\vec{y}$之间是存在误差的。实际上，寻找最优模型实际上就是寻找最优的$\\vec{a}$。</p>\n<h3 id=\"最小二乘法的矩阵表示形式\"><a href=\"#最小二乘法的矩阵表示形式\" class=\"headerlink\" title=\"最小二乘法的矩阵表示形式\"></a>最小二乘法的矩阵表示形式</h3><p>假设损失函数为$L(\\theta) = \\frac{1}{2}(\\vec{y}-\\matrix{X}\\theta)^T(\\vec{y}-\\matrix{X}\\theta)$，那么，根据最小二乘法原理，对$L$针对$\\theta$求导，并将其赋值为0，从而求解出$\\theta$的值。<br>$$<br>\\begin{split}<br>\\frac{\\partial L}{\\partial \\theta}= &amp;\\frac{1}{2}\\frac{\\partial(\\vec{y}^T\\vec{y}-\\vec{y}^T\\matrix{X}\\vec{\\theta}-\\vec{\\theta}^{T}\\matrix{X}^T\\vec{y}+\\vec{\\theta}^T\\matrix{X}^T\\matrix{X}\\vec{\\theta})}{\\partial \\vec\\theta} \\<br>=&amp;\\frac{1}{2}(-\\vec{y}^T\\matrix{X}-\\frac{\\partial{(\\vec{\\theta}^{T}\\matrix{X}^T\\vec{y}})^T}{\\vec{\\theta}}+\\vec\\theta^T\\matrix{X}^T\\matrix{X}+\\frac{\\partial\\theta^T }{\\partial\\vec{\\theta}}\\matrix{X}^T\\matrix{X}\\vec{\\theta}) \\<br>= &amp; \\frac{1}{2}(-\\vec{y}^T\\matrix{X}-\\vec{y}^T\\matrix{X}+\\vec\\theta^T\\matrix{X}^T\\matrix{X}+\\frac{(\\partial\\vec\\theta^{T} \\cdot \\matrix{X}^T\\matrix{X}\\vec{\\theta})^T}{\\partial\\vec\\theta}) \\<br>= &amp; \\frac{1}{2}(-2\\vec{y}^T\\matrix{X} + 2\\vec\\theta^T\\matrix{X}^T\\matrix{X})=0<br>\\end{split}<br>$$<br>基于上式，可以推导出$\\vec\\theta=(\\matrix{X}^T\\matrix{X})^{-1}\\matrix{X}^T\\vec{y}$</p>\n<p>(Notes:一个函数的维度和该函数的微分的维度是保持一致的)</p>\n<h3 id=\"最小二乘法的应用场景\"><a href=\"#最小二乘法的应用场景\" class=\"headerlink\" title=\"最小二乘法的应用场景\"></a>最小二乘法的应用场景</h3><ol>\n<li>模型必须是线性模型，求解的损失函数是误差的平方和，（如果不是线性的，则需要通过非线性函数映射，将其映射为线性模型，eg：$g(\\vec{y})=\\matrix{X}\\vec\\theta$,令$h=g(\\vec{y})$，则此时可以针对$\\vec{h}$与$\\matrix{X}$构建线性模型）</li>\n<li>$\\matrix{X}^T\\matrix{X}$必须要是可逆。</li>\n</ol>\n<hr>\n<h2 id=\"最大似然估计\"><a href=\"#最大似然估计\" class=\"headerlink\" title=\"最大似然估计\"></a>最大似然估计</h2><p>最大似然估计法是统计学中一个用来求解参数模型中参数的方法，这种方法和前面的优化算法类似，也是要求具有明确的模型，然后根据观测的数据来求解模型中未知的参数。</p>\n<h3 id=\"最大似然原理\"><a href=\"#最大似然原理\" class=\"headerlink\" title=\"最大似然原理\"></a>最大似然原理</h3><p><strong>似然函数</strong>表示的是统计模型中关于参数的一种函数，这种函数表达的含义是参数的似然性（或者说该参数取某个值的概率性）。<br>在统计学中，假定存在一个分布$D$,并且假设该分布的概率密度函数（连续型）或者概率质量函数（离散型）为$f_\\theta$，并且该函数是关于参数$\\theta$的一个函数。那么我们独立地从该分布中抽取出$n$个数据,分别为$X_1,X_2,…,X_n$，那么，通过这n个观测的数据，我们可以计算出模型中参数$\\theta$的似然函数，如下：<br>$lik(\\theta|x_1,x_2,…,x_n)=f_\\theta(x_1,x_2,…,x_n)$<br>由最大似然原理可知，要使用最大似然估计最重要的一点就是需要知道数据分布的概率密度函数或者概率质量函数，同时，该函数也是我们的建模函数，也就是说，我们针对一个特定的业务问题，通过构建关于该问题的概率密度函数或者概率质量函数模型，然后通过最大似然函数求解该模型中的参数，得到一个精确的函数。</p>\n<h3 id=\"最大似然估计法原理\"><a href=\"#最大似然估计法原理\" class=\"headerlink\" title=\"最大似然估计法原理\"></a>最大似然估计法原理</h3><p>基于最大似然原理可知，我们需要计算模型中的参数的时候，需要构建该参数的似然函数，那么怎么才能得到这个似然函数呢，最好的方式就是根据已知的观测数据，来计算这个似然函数，具体来说就是构建如下似然函数：<br>$f(x_1,x_2,…,x_n|\\theta)$，显然，这是一个联合概率分布.</p>\n<ol>\n<li>那么为了简化这个问题的计算过程，通常会假设所有的数据样本之间是独立的，因此，有如下表达式：<br>$f(x_1,x_2,…,x_n|\\theta)=\\prod_{i=1}^{n} f(x_i|\\theta)$</li>\n<li>同时，由于连乘计算不方便，因此，会对上述公式取对数，从而转变为加法计算，这样非常方便求解函数的极值点。<br>最大似然估计法最根本的就是求解$f(x_1,…,x_n)$的最大值。</li>\n</ol>\n<p>最大似然估计法的步骤入下：</p>\n<ol>\n<li>写出似然函数</li>\n<li>对似然函数取对数，并整理；</li>\n<li>求导数 ；</li>\n<li>解似然方程</li>\n</ol>\n<p>（Notes：最大似然估计只考虑某个模型能产生某个给定观察序列的概率，而未考虑该模型本身的概率）</p>\n<h2 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h2><ol>\n<li><a href=\"http://www.cnblogs.com/pinard/p/5970503.html\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/pinard/p/5970503.html</a></li>\n<li><a href=\"https://www.zhihu.com/question/37031188\" target=\"_blank\" rel=\"noopener\">https://www.zhihu.com/question/37031188</a></li>\n<li><a href=\"http://www.matongxue.com/madocs/205.html#/madoc\" target=\"_blank\" rel=\"noopener\">http://www.matongxue.com/madocs/205.html#/madoc</a></li>\n</ol>\n","site":{"data":{}},"excerpt":"<p>优化算法是机器学习中的“方法论”，优化算法会告诉机器应该如何优化学习的进程，让自己能够更好地掌握学习到的知识，本文将针对机器学习领域中常用的几种优化算法进行总结。</p>\n<h2 id=\"梯度下降法\"><a href=\"#梯度下降法\" class=\"headerlink\" title=\"梯度下降法\"></a>梯度下降法</h2><h3 id=\"梯度下降法与梯度、导数的概念\"><a href=\"#梯度下降法与梯度、导数的概念\" class=\"headerlink\" title=\"梯度下降法与梯度、导数的概念\"></a>梯度下降法与梯度、导数的概念</h3><p>梯度下降法是用来求解无约束优化问题的一种数学方法，通过梯度下降法可以获取到函数的局部极小值。这里存在一个概念“梯度”，梯度的本意实际上是一个向量，及具有方向性和数值性，其表示的是一个函数在改点沿着该方向变化最快（这个方向是往函数值变大的方向），这个变化率实际上就是该梯度的模。因此，在使用梯度下降法的时候，实际上是要求我们选择梯度的反方向进行计算，只有这样才能保证我们能够取到极小值，这也就是为什么在使用导数（导数与梯度实际上是同一个概念，只不过梯度是一种抽象的表述概念，而导数是实际上用来求解梯度的一种数学表示方式，导数值前面的正负号实际上是决定了梯度的方向）进行参数迭代的时候是要在导数的前面加上负号。<br><img src=\"/images/gradient_ill.jpg\" alt=\"\"></p>\n<p>如上图所示，我们对函数f在A点对自变量x求解右导数$f^\\prime$，其值为正数，那是因为在A点右侧函数值是增大的，因此，如果要想f值变小，则需要让往左移$x=x_a-\\delta f^\\prime$；对B点求解右导数，其值为负数，那是因为在B点右侧函数值是变小的，因此，如果想要f值变小，则需要让x往右移$x=x_a-\\delta f^\\prime$，因此，如果是要使用梯度下降法，则在迭代过程中要在导数的前面加上负号。<br></p>","more":"<p></p>\n<h3 id=\"梯度下降法详解\"><a href=\"#梯度下降法详解\" class=\"headerlink\" title=\"梯度下降法详解\"></a>梯度下降法详解</h3><h4 id=\"应用前提条件\"><a href=\"#应用前提条件\" class=\"headerlink\" title=\"应用前提条件\"></a>应用前提条件</h4><p>首先，我们得需要明确梯度下降法并不是万能的，因为在机器学习领域中，存在一个叫做NFL(No Free Launch)定理，这个定理说明了不存在一种模型或者算法能够适应于所有的应用场景。那么既然如此，梯度下降法能够应用于哪些场景中呢。其实从梯度下降法的原理来看，只要我们沿着梯度方向能够寻找到合适的最小值，那么就可以使用梯度下降法，那么如何判断什么样的函数是满足梯度下降法的应用的呢，最简单的一种方法就是判断该函数是否是<strong>下凸函数</strong>，如果一个函数是下凸函数，那么我们就可以针对该函数使用梯度下降法来求解最小值。当然，对于下凸函数可能会存在很多个局部极小值点，那么在这种情况下，使用梯度下降法来求解函数的最小值可能会存在一些偏差，那么此时，会通过一些技术性的措施（比如：采用随机性，分别从不同起始点多次进行梯度下降求解等）来优化我们使用梯度下降法的过程。</p>\n<p>在梯度下降法中，通常需要优先确定以下条件：</p>\n<pre><code>1. 步长,也成为学习率 $\\alpha$\n2. 目标函数（损失函数，但是在确定损失函数过程$ L(\\theta) $，需要优先确定模型$ h\\_\\theta(x) $）\n</code></pre><p>基于上述两点先决条件，可以获得梯度下降法中最关键的表达式：<br>$ \\theta_t = \\theta_{t-1}-\\alpha \\frac{\\partial L}{\\partial x} $</p>\n<p>下面将分别基于<strong>线性回归模型</strong>来阐述代数形式和矩阵形式下的梯度下降法。</p>\n<h4 id=\"梯度下降法的代数形式表达\"><a href=\"#梯度下降法的代数形式表达\" class=\"headerlink\" title=\"梯度下降法的代数形式表达\"></a>梯度下降法的代数形式表达</h4><ol>\n<li>假设有一组数据集$(x_1^1,x_2^1,…,x_n^1,y^1),(x_1^2,x_2^2,…,x_n^2,y^2),…,(x_1^m,x_2^m,…,x_n^m,y^m)$，该数据集共有m个样本，每个样本包含有n个特征量。<br>如果我们想通过线性回归模型来构建$x$与$y$之间的关系，可得如下模型：$h_\\theta(x_1,x_2,…,x_n)=\\theta_0+\\theta_1 x_1 + … + \\theta_n x_n$,</li>\n<li>采用线性模型常用的误差平方和作为损失函数L:<br>$L(\\theta_0,theta_1,…,theta_n)=\\frac{1}{2m}\\sum_{j=1}^m(y_j-h_\\theta(x_1^j,x_2^j,…,x_n^j)^2)$</li>\n<li>使用梯度下降法求解，需要初始化相关参数，主要包含了$\\theta$、$\\alpha$、以及迭代停止距离$\\epsilon$,通常我们可以将$\\alpha$设置为0.9，$\\theta$设置为0。</li>\n<li>算法流程如下：<br> Step1:计算当前$L(\\theta_0,\\theta_1,…,\\theta_n)$关于每个$\\theta_i$的梯度：$\\frac{\\partial L}{\\partial \\theta_i}$；<br> Step2:用步长$\\alpha$乘以Step1中求得的每个关于$\\theta_i$的梯度，得到每个$\\theta_i$下降的距离$d_i$；<br> Step3:判断每个$\\theta_i$的梯度下降距离$d_i$的值是否都小于终止条件$\\epsilon$,如果是，则停止学习，将当前的学习到的所有的$\\theta_i$作为最终习得的参数，反之，进入Step4;<br> Step3:更新所有的$\\theta_i$,更新公式如下：$\\theta_i=\\theta_i-\\alpha \\frac{\\partial L}{\\partial \\theta_i}$,然后重复Step1~Step3.<h4 id=\"梯度下降法的矩阵形式表达\"><a href=\"#梯度下降法的矩阵形式表达\" class=\"headerlink\" title=\"梯度下降法的矩阵形式表达\"></a>梯度下降法的矩阵形式表达</h4>梯度下降法的矩阵表达形式实际上上对代数形式的矩阵话，为什么需要矩阵化？因为在实际的计算过程中，矩阵运算的效率与高于循环计算的效率，能够提升学习的效率。</li>\n</ol>\n<p>通常我们会将样本数据集表示为$\\matrix{X_{m \\times n}}$，其中，$m$表示样本的个数，即矩阵的每一行表示一个样本信息，$n$表示样本中的特征量的个数，即矩阵中的每列表示的是一个特征量的取值。并且通常在机器学习领域中将向量表示为列向量，因此，所有的参数$\\theta_i$可以表示为向量$\\vec{\\theta}$.</p>\n<p>根据上述定义的矩阵和向量信息，可以重新表达线性模型：$\\vec{y}=\\matrix{X}\\theta$,同时，损失函数可以表示为：$L(\\theta) = \\frac{1}{2}(\\vec{y}-\\matrix{X}\\theta)^T(\\vec{y}-\\matrix{X}\\theta)$，预先设置的参数步骤和代数形式是一致的，算法过程也是一致的，唯一的区别是在计算过程中变成了矩阵话运算。</p>\n<h4 id=\"梯度下降法的变形\"><a href=\"#梯度下降法的变形\" class=\"headerlink\" title=\"梯度下降法的变形\"></a>梯度下降法的变形</h4><p>上文所阐述的梯度下降法实际上是在每一轮迭代的过程中针对所有的样本进行梯度计算与梯度下降判断的，也可以成为<strong>全批量梯度下降法（Batch Gradient Descent）</strong>，这样的方法具有以下缺点：如果样本量非常大的时候，计算的效率会降低，但是也具有准确率高的优点；<br>针对BGD算法效率低的问题，又提出了一种<strong>随机梯度下降法（Stochastic Gradient Descent）</strong>，顾名思义，这种做法是每一轮迭代都只随机选取一个样本进行计算，这种方式大大提升了计算的效率，但是，由于每一次都是随机选取一个样本进行迭代计算，那么会导致获得的参数值并不是局部最优解，同时，这样方式还会导致每次迭代时的方向会不稳定，即整体的收敛速度会下降；<br>针对上述两种极端的梯度下降法，又提出了一种<strong>小批量梯度下降法（Mini-Batch Gradient Descent）</strong>，这种方法通常是选择部分样本参与计算，通常每轮迭代选择的样本量为16,32,64,128,256,512等这类$2^n$的值。（Notes:在机器学习中，如果样本量过大的时候，我们通常会在没一轮的学习过程中选择部分样本来参与学习，同时增加学习的轮数，这样可以通过多次学习的方式，来提升每次训练的效率，并且因增加了学习的次数，也能够从整体上降低泛化误差）。</p>\n<h3 id=\"梯度下降法应用场景\"><a href=\"#梯度下降法应用场景\" class=\"headerlink\" title=\"梯度下降法应用场景\"></a>梯度下降法应用场景</h3><p>损失函数必须是凸函数，即存在局部极小值点</p>\n<hr>\n<h2 id=\"基本牛顿法\"><a href=\"#基本牛顿法\" class=\"headerlink\" title=\"基本牛顿法\"></a>基本牛顿法</h2><h3 id=\"牛顿-拉夫森法\"><a href=\"#牛顿-拉夫森法\" class=\"headerlink\" title=\"牛顿-拉夫森法\"></a>牛顿-拉夫森法</h3><p>基本牛顿法在优化问题中的应用实际上是来源于牛顿-拉夫森法，该方法是用来求解函数的零点的方法，那么这个方法到底是什么方法呢，实际上，该方法是建立在泰勒展开公式的基础上，通过使原方程泰勒展开的一阶近似等于零不断获得更好的结果的求解方程零点的方法。简单来说，具有以下特点：</p>\n<pre><code>1. 牛顿法是求解方程零点的方法\n2. 牛顿法利用泰勒展开的一阶近似的零点获得更接近真实零点的点\n3. 牛顿法通过迭代的方法不断的获得更好的解来求得最好的解\n</code></pre><p>首先，假设存在一个函数$f(\\vec{x})$,那么利用泰勒展开公式，将其进行一阶泰勒展开$f(\\vec{x})=f(\\vec{x_0})+\\frac{\\partial f(\\vec{x})}{\\partial \\vec{x}}|<em>{\\vec{x}=\\vec{x</em>{0}}}(\\vec{x}-\\vec{x_0}))$，我们可以求解出展开式的零点，即令<br>$$<br>\\begin{split}<br>&amp; f(\\vec{x_0})+\\frac{\\partial f(\\vec{x})}{\\partial \\vec{x}}|<em>{\\vec{x}=\\vec{x</em>{0}}}(\\vec{x}-\\vec{x_0}))=0 \\<br>=&gt; &amp; \\vec{x}_1=\\vec{x_0}-\\frac{f(\\vec{x_0})}{\\frac{\\partial f(\\vec{x})}{\\partial \\vec{x}}|_{\\vec{x}=\\vec{x_0}}}<br>\\end{split}<br>$$<br>然后再在$\\vec{x}_1$处进行一阶泰勒展开，如此迭代求解，可以计算得到:<br>$$<br>\\vec{x}<em>n=\\vec{x</em>{n-1}}-\\frac{f(\\vec{x_{n-1}})}{\\frac{\\partial f(\\vec{x})}{\\partial \\vec{x}}|<em>{\\vec{x}=\\vec{x</em>{n-1}}}}<br>$$<br>然后判断$f(\\vec{x_{n-1}})&lt;\\epsilon$，如果满足，则停止迭代，说明此时的$\\vec{x}_{n-1}$就是函数$f(\\vec{x})$的零点。</p>\n<h3 id=\"基本牛顿优化法\"><a href=\"#基本牛顿优化法\" class=\"headerlink\" title=\"基本牛顿优化法\"></a>基本牛顿优化法</h3><p>当我们需要求解一个函数的极值点点的时候，最重要的判断条件就是$\\frac{\\partial f}{\\partial \\vec\\theta} = 0$，也就是函数的一阶导数为0时所对应的点。那么，如果要用牛顿法来解决最优化的问题，最根本的问题就是，使用牛顿-拉夫森方法来求解$\\frac{\\partial f}{\\partial \\vec\\theta}$的零点。<br>首先，我们对函数进行二阶泰勒展开：<br>$<br>\\begin{split}<br>&amp; f(\\vec{x})=f(\\vec{x_0})+\\frac{\\partial f(\\vec{x})}{\\partial \\vec{x}}|<em>{\\vec{x}=\\vec{x</em>{0}}}(\\vec{x}-\\vec{x_0}))+\\frac{1}{2}\\frac{\\partial ^{2} f(\\vec{x})}{\\partial ^{2} \\vec{x}}|<em>{\\vec{x}=\\vec{x</em>{0}}}(\\vec{x}-\\vec{x_0})^{2}) \\<br>\\end{split}<br>$<br>对上述公式求导：<br>$$<br>\\begin{split}<br>&amp; \\frac{\\partial f(\\vec{x})}{\\partial \\vec{x}}= &amp;\\frac{\\partial f(\\vec{x})}{\\partial \\vec{x}}|<em>{\\vec{x}=\\vec{x</em>{0}}} + \\frac{\\partial ^{2} f(\\vec{x})}{\\partial ^{2} \\vec{x}}|<em>{\\vec{x}=\\vec{x</em>{0}}}(\\vec{x}-\\vec{x_0}) \\<br>=&gt; &amp; \\vec{x}<em>n=\\vec{x</em>{n-1}}-\\frac{f(\\frac{\\partial f(\\vec{x})}{\\partial \\vec{x}}|<em>{\\vec{x}=\\vec{x</em>{n-1}}}}{\\frac{\\partial^{2} f(\\vec{x})}{\\partial^{2} \\vec{x}}|<em>{\\vec{x}=\\vec{x</em>{n-1}}}}<br>\\end{split}<br>$$<br>因此，由上述公式可知，我们可以通过函数的一阶导数和二阶导数不断迭代计算出$\\vec{x}$,<br>然后判断$\\frac{\\partial f(\\vec{x})}{\\partial\\vec{x}}|<em>{\\vec{x}=\\vec{x</em>{n-1}}}&lt;\\epsilon$，如果满足，则停止迭代，说明此时的$\\vec{x}_{n-1}$就是函数$f(\\vec{x})$一阶导数的零点。</p>\n<p>在机器学习中，二阶导数就是海森矩阵。</p>\n<h3 id=\"牛顿法的优缺点\"><a href=\"#牛顿法的优缺点\" class=\"headerlink\" title=\"牛顿法的优缺点\"></a>牛顿法的优缺点</h3><p>实际上牛顿法与梯度下降法在优化问题上的本质方法是一致的，唯一的区别是在于如何求解的问题，在牛顿法中的海森矩阵就相当于梯度下降法中的学习率（步长）。牛顿法收敛速度相比梯度下降法很快，而且由于海森矩阵的的逆在迭代中不断减小，起到逐渐缩小步长的效果。但是，如果样本量非常大，那么会导致计算海森矩阵的效率很慢，同时还需要大量的计算资源。</p>\n<h2 id=\"拟牛顿法\"><a href=\"#拟牛顿法\" class=\"headerlink\" title=\"拟牛顿法\"></a>拟牛顿法</h2><p>为了解决牛顿法中求解海森矩阵的问题，我们可以在满足拟牛顿条件的基础上构造一个近似的海森矩阵，用近似值来代替标准的海森矩阵参与计算。常用的近似计算算法有DFP算法，BFGS算法，L-BFGS算法以及Broyden类算法等。<br>//todo</p>\n<hr>\n<h2 id=\"最小二乘法\"><a href=\"#最小二乘法\" class=\"headerlink\" title=\"最小二乘法\"></a>最小二乘法</h2><p>最小二乘法也是用来估计这样一种参数，该参数能够使得观测值和理论值之差的平方和最小，通常是用来优化线性模型，从最小二乘法的概念上可知，其应用的目标函数是非常受限的，也就是说，其优化的目标函数必须是服从以下形式的：<br>$L(\\theta)=\\sum_{i=1}^{m}{(y-y^h)}^2$.<br>为什么要用这个平方和来表示损失函数呢？什么是最小二乘法的理论基础呢？实际上，最小二乘法是符合矩阵投影理论和高斯正态误差理论的。<br>在深入理解最小二乘法之前，我们需要定义<strong>误差</strong>，如果从线性空间的角度来看的话，误差是什么？误差其实就是在空间中寻找两个向量之间的差值最小。如下图，我们可以假设$\\vec{b}$是一个标准的值，那么如果存在一个特定的映射模型，将确定为$\\vec{a}$，那么我们需要在$\\vec{a}$这个向量中寻找出与$\\vec{b}$误差最小的一个向量点，也就是$\\vec{p}$.<br><img src=\"/images/mse_ill.jpg\" alt=\"\"></p>\n<p>结合线性模型来理解的话，通常$\\vec{y}$指的是空间中的一个向量，而线性模型中的参数向量实际上是一种变换，这种变换会将空间中的点$\\matrix{X}$映射出$\\vec{y^g}$,但是，由于我们通常是无法准确地获得$\\matrix{X}$与$\\vec{y}$之间的映射关系，一方面是因为数据测量的误差，另一方面是模型本身存在误差；因此，$\\vec{y}$与$\\vec{y}$之间是存在误差的。实际上，寻找最优模型实际上就是寻找最优的$\\vec{a}$。</p>\n<h3 id=\"最小二乘法的矩阵表示形式\"><a href=\"#最小二乘法的矩阵表示形式\" class=\"headerlink\" title=\"最小二乘法的矩阵表示形式\"></a>最小二乘法的矩阵表示形式</h3><p>假设损失函数为$L(\\theta) = \\frac{1}{2}(\\vec{y}-\\matrix{X}\\theta)^T(\\vec{y}-\\matrix{X}\\theta)$，那么，根据最小二乘法原理，对$L$针对$\\theta$求导，并将其赋值为0，从而求解出$\\theta$的值。<br>$$<br>\\begin{split}<br>\\frac{\\partial L}{\\partial \\theta}= &amp;\\frac{1}{2}\\frac{\\partial(\\vec{y}^T\\vec{y}-\\vec{y}^T\\matrix{X}\\vec{\\theta}-\\vec{\\theta}^{T}\\matrix{X}^T\\vec{y}+\\vec{\\theta}^T\\matrix{X}^T\\matrix{X}\\vec{\\theta})}{\\partial \\vec\\theta} \\<br>=&amp;\\frac{1}{2}(-\\vec{y}^T\\matrix{X}-\\frac{\\partial{(\\vec{\\theta}^{T}\\matrix{X}^T\\vec{y}})^T}{\\vec{\\theta}}+\\vec\\theta^T\\matrix{X}^T\\matrix{X}+\\frac{\\partial\\theta^T }{\\partial\\vec{\\theta}}\\matrix{X}^T\\matrix{X}\\vec{\\theta}) \\<br>= &amp; \\frac{1}{2}(-\\vec{y}^T\\matrix{X}-\\vec{y}^T\\matrix{X}+\\vec\\theta^T\\matrix{X}^T\\matrix{X}+\\frac{(\\partial\\vec\\theta^{T} \\cdot \\matrix{X}^T\\matrix{X}\\vec{\\theta})^T}{\\partial\\vec\\theta}) \\<br>= &amp; \\frac{1}{2}(-2\\vec{y}^T\\matrix{X} + 2\\vec\\theta^T\\matrix{X}^T\\matrix{X})=0<br>\\end{split}<br>$$<br>基于上式，可以推导出$\\vec\\theta=(\\matrix{X}^T\\matrix{X})^{-1}\\matrix{X}^T\\vec{y}$</p>\n<p>(Notes:一个函数的维度和该函数的微分的维度是保持一致的)</p>\n<h3 id=\"最小二乘法的应用场景\"><a href=\"#最小二乘法的应用场景\" class=\"headerlink\" title=\"最小二乘法的应用场景\"></a>最小二乘法的应用场景</h3><ol>\n<li>模型必须是线性模型，求解的损失函数是误差的平方和，（如果不是线性的，则需要通过非线性函数映射，将其映射为线性模型，eg：$g(\\vec{y})=\\matrix{X}\\vec\\theta$,令$h=g(\\vec{y})$，则此时可以针对$\\vec{h}$与$\\matrix{X}$构建线性模型）</li>\n<li>$\\matrix{X}^T\\matrix{X}$必须要是可逆。</li>\n</ol>\n<hr>\n<h2 id=\"最大似然估计\"><a href=\"#最大似然估计\" class=\"headerlink\" title=\"最大似然估计\"></a>最大似然估计</h2><p>最大似然估计法是统计学中一个用来求解参数模型中参数的方法，这种方法和前面的优化算法类似，也是要求具有明确的模型，然后根据观测的数据来求解模型中未知的参数。</p>\n<h3 id=\"最大似然原理\"><a href=\"#最大似然原理\" class=\"headerlink\" title=\"最大似然原理\"></a>最大似然原理</h3><p><strong>似然函数</strong>表示的是统计模型中关于参数的一种函数，这种函数表达的含义是参数的似然性（或者说该参数取某个值的概率性）。<br>在统计学中，假定存在一个分布$D$,并且假设该分布的概率密度函数（连续型）或者概率质量函数（离散型）为$f_\\theta$，并且该函数是关于参数$\\theta$的一个函数。那么我们独立地从该分布中抽取出$n$个数据,分别为$X_1,X_2,…,X_n$，那么，通过这n个观测的数据，我们可以计算出模型中参数$\\theta$的似然函数，如下：<br>$lik(\\theta|x_1,x_2,…,x_n)=f_\\theta(x_1,x_2,…,x_n)$<br>由最大似然原理可知，要使用最大似然估计最重要的一点就是需要知道数据分布的概率密度函数或者概率质量函数，同时，该函数也是我们的建模函数，也就是说，我们针对一个特定的业务问题，通过构建关于该问题的概率密度函数或者概率质量函数模型，然后通过最大似然函数求解该模型中的参数，得到一个精确的函数。</p>\n<h3 id=\"最大似然估计法原理\"><a href=\"#最大似然估计法原理\" class=\"headerlink\" title=\"最大似然估计法原理\"></a>最大似然估计法原理</h3><p>基于最大似然原理可知，我们需要计算模型中的参数的时候，需要构建该参数的似然函数，那么怎么才能得到这个似然函数呢，最好的方式就是根据已知的观测数据，来计算这个似然函数，具体来说就是构建如下似然函数：<br>$f(x_1,x_2,…,x_n|\\theta)$，显然，这是一个联合概率分布.</p>\n<ol>\n<li>那么为了简化这个问题的计算过程，通常会假设所有的数据样本之间是独立的，因此，有如下表达式：<br>$f(x_1,x_2,…,x_n|\\theta)=\\prod_{i=1}^{n} f(x_i|\\theta)$</li>\n<li>同时，由于连乘计算不方便，因此，会对上述公式取对数，从而转变为加法计算，这样非常方便求解函数的极值点。<br>最大似然估计法最根本的就是求解$f(x_1,…,x_n)$的最大值。</li>\n</ol>\n<p>最大似然估计法的步骤入下：</p>\n<ol>\n<li>写出似然函数</li>\n<li>对似然函数取对数，并整理；</li>\n<li>求导数 ；</li>\n<li>解似然方程</li>\n</ol>\n<p>（Notes：最大似然估计只考虑某个模型能产生某个给定观察序列的概率，而未考虑该模型本身的概率）</p>\n<h2 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h2><ol>\n<li><a href=\"http://www.cnblogs.com/pinard/p/5970503.html\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/pinard/p/5970503.html</a></li>\n<li><a href=\"https://www.zhihu.com/question/37031188\" target=\"_blank\" rel=\"noopener\">https://www.zhihu.com/question/37031188</a></li>\n<li><a href=\"http://www.matongxue.com/madocs/205.html#/madoc\" target=\"_blank\" rel=\"noopener\">http://www.matongxue.com/madocs/205.html#/madoc</a></li>\n</ol>"},{"title":"kubeadm1.13创建HAkubernetes集群","date":"2019-02-18T02:13:14.000Z","_content":"[TOC]\n## 一、环境准备\n### 1.1 硬件设备环境\n采用5台腾讯云的CVM作为kubernetes的部署环境，具体信息如下：\n\n| 主机名 | IP | 配置 | 备注 |\n| --- | --- | --- | --- |\n| （Old）VM_0_1_centos；（New）tf-k8s-m1 | 10.0.0.1 | 4c 8g | k8s的master，同时也是etcd节点 |\n| （Old）VM_0_2_centos；（New）tf-k8s-m2 | 10.0.0.2 | 4c 8g | k8s的master，同时也是etcd节点 |\n| （Old）VM_0_3_centos；（New）tf-k8s-m3 | 10.0.0.3 | 4c 8g | k8s的master，同时也是etcd节点 |\n| （Old）VM_0_4_centos；（New）tf-k8s-n1 | 10.0.0.4 | 4c 8g | 工作节点 node，容器编排最终 pod 工作节点 |\n| （Old）VM_0_5_centos；（New）tf-k8s-n2 | 10.0.0.5 | 4c 8g | 工作节点 node，容器编排最终 pod 工作节点 |\n\n### 1.2 软件环境\n\n| 环境 | 简介 |\n| --- | --- |\n| 操作系统 | CentOS7 |\n| kubeadm | 1.13.3 |\n| kubernetes | 1.13.3 |\n| Docker | docker-ce 18.06.2 |\n\n### 1.3 相关系统设置\n在正式安装之前，需要在每台机器上对以下配置进行修改：\n* 关闭防火墙，selinux\n* 关闭系统的swap功能\n* 关闭Linux swap空间的swappiness\n* 配置L2网桥在转发包时会被iptables的FORWARD规则所过滤，该配置被CNI插件需要，更多信息请参考[Network Plugin Requirements](https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/#network-plugin-requirements)\n* 升级内核到最新（centos7 默认的内核是3.10.0-862.el7.x86_64 ,可以使用命令‘uname -a’进行查看），原因见[请问下为什么要用4.18版本内核](https://github.com/Lentil1016/kubeadm-ha/issues/19)\n* 开启IPVS\n* 修改主机名（如果主机名中含有一些特殊字符，则需要调整主机名，不然在后续操作中会出现错误）\n具体的配置修改执行脚本如下：\n\n```\n# ---------- 关闭防火墙和selinux -----------\nsystemctl stop firewalld\nsystemctl disable firewalld\nsetenforce 0\nsed -i \"s/SELINUX=enforcing/SELINUX=disabled/g\" /etc/selinux/config\n\n# ---------- 关闭交换分区 -----------\nswapoff -a\nyes | cp /etc/fstab /etc/fstab_bak\ncat /etc/fstab_bak |grep -v swap > /etc/fstab\n\n# ---------- 设置网桥包经IPTables，core文件生成路径 -----------\necho \"\"\"\nvm.swappiness = 0\nnet.bridge.bridge-nf-call-ip6tables = 1\nnet.bridge.bridge-nf-call-iptables = 1\n\"\"\" > /etc/sysctl.conf\nmodprobe br_netfilter\nsysctl -p\n\n# ---------- 同步时间 -----------\nyum install -y ntpdate\nntpdate -u ntp.api.bz\n\n# ---------- 升级内核 -----------\nrpm -Uvh http://www.elrepo.org/elrepo-release-7.0-2.el7.elrepo.noarch.rpm ;yum --enablerepo=elrepo-kernel install kernel-ml-devel kernel-ml -y\n# 查看启动配置里是否有最新的内核\ncat /boot/grub2/grub.cfg | grep menuentry\n# 修改默认启动项\ngrub2-set-default 0\n# 检查默认内核版本是否大于4.14，否则请调整默认启动参数\ngrub2-editenv list\n#重启以更换内核\nreboot\n#查看内核信息\nuname -a\n\n# ---------- 确认内核版本后，开启IPVS -----------\nuname -a\ncat > /etc/sysconfig/modules/ipvs.modules <<EOF\n#!/bin/bash\nipvs_modules=\"ip_vs ip_vs_lc ip_vs_wlc ip_vs_rr ip_vs_wrr ip_vs_lblc ip_vs_lblcr ip_vs_dh ip_vs_sh ip_vs_fo ip_vs_nq ip_vs_sed ip_vs_ftp nf_conntrack\"\nfor kernel_module in \\${ipvs_modules}; do\n /sbin/modinfo -F filename \\${kernel_module} > /dev/null 2>&1\n if [ $? -eq 0 ]; then\n /sbin/modprobe \\${kernel_module}\n fi\ndone\nEOF\nchmod 755 /etc/sysconfig/modules/ipvs.modules && bash /etc/sysconfig/modules/ipvs.modules && lsmod | grep ip_vs\n\n# ---------- 修改主机名 -----------\n# 这里以VM_0_17_centos主机为例，其他的主机分别修改成相应的主机名\nhostnamectl set-hostname tf-k8s-m1 \n```\n### 1.3 配置集群内各个机器之间的免密码登录\n#### 1.3.1 配置hosts \n为了便于后续的操作，我们需要给每一台设备配置下hosts域名信息，具体如下：\n\n```\n# vi /etc/hosts\n10.0.0.1 tf-k8s-m1 api.tf-k8s.xiangwushuo.com\n10.0.0.2 tf-k8s-m2\n10.0.0.3 tf-k8s-m3\n10.0.0.4 tf-k8s-n1\n10.0.0.5 tf-k8s-n2\n10.0.0.1 dashboard.tf-k8s.xiangwushuo.com\n```\n#### 1.3.2 新建用户\n```\n# useradd kube\n# visudo\n%wheel  ALL=(ALL)       ALL\nkube    ALL=(ALL)       NOPASSWD:ALL\n```\n备注：visudo命令是用来给kube用户添加sudo密码\n#### 1.3.3 设置免密登录\n1. 各个设备的root用户&kube用户（不同用户配置不同的）都生成各自的免密登录的ssh的私钥与公钥\n\n```\n## 为root用户生成ssh的私钥与公钥\nssh-keygen\n```\n在/root目录下，会生成一个.ssh目录，.ssh目录下会生成以下三个文件：\n\n```\n-rw------- 1 root root 2398 Feb 13 15:18 authorized_keys\n-rw------- 1 root root 1679 Feb 13 14:47 id_rsa\n-rw-r--r-- 1 root root  401 Feb 13 14:47 id_rsa.pub\n```\nauthorized_keys文件存储了本设备认证授权的其他设备的公钥信息；id_rsa存储了本设备的私钥信息；id_rsa.pub存储了本设备的公钥信息。\n\n```\n## 为kube用户生成ssh的私钥与公钥\nsu kube\nssh-keygen\n```\n在/home/kube目录下，会生成一个.ssh目录，并包含相关文件。\n2. 各个设备上都创建好各自的ssh免密登录公钥与私钥后，需要将各自的公钥copy至其他的设备上，并将公钥信息添加到各个设备的authorized_keys文件中。\n备注：也需要将各个节点自己的公钥copy至自己的authorized_keys文件中，这样自己才可以ssh自己。\n\n```\n## 将每一台节点上的公钥都同步到相应的目录下\n# ll\n-rw-r--r-- 1 root root  401 Feb 13 15:15 tf-k8s-m1-id_rsa.pub\n-rw-r--r-- 1 root root  401 Feb 13 15:15 tf-k8s-m2-id_rsa.pub\n-rw-r--r-- 1 root root  401 Feb 13 15:15 tf-k8s-m3-id_rsa.pub\n-rw-r--r-- 1 root root  401 Feb 13 15:15 tf-k8s-n1-id_rsa.pub\n-rw-r--r-- 1 root root  401 Feb 13 15:15 tf-k8s-n2-id_rsa.pub\n## 将每台节点的公钥追加至authorized_keys文件中\ncat tf-k8s-m1-id_rsa.pub > authorized_keys\ncat tf-k8s-m2-id_rsa.pub > authorized_keys\ncat tf-k8s-m3-id_rsa.pub > authorized_keys\ncat tf-k8s-n1-id_rsa.pub > authorized_keys\ncat tf-k8s-n2-id_rsa.pub > authorized_keys\n```\n测试是否能够正常使用ssh免密登录\n\n```\nssh root@tf-k8s-m1\nssh root@tf-k8s-m2\nssh root@tf-k8s-m3\nssh root@tf-k8s-n1\nssh root@tf-k8s-n2\n```\n**提示**：如果其他机器上的 root 下的 /root/.ssh/authorized_keys 不存在，可以手动创建。要注意的是：authorized_keys 的权限需要是 600。\n\n```\n## 如果 authorized_keys 的权限不是 600，执行修改权限的命令。\nchmod 600 authorized_keys\n```\n\n## 二、安装步骤\n以下操作，可以都切换至kube用户下进行操作。\n### 2.1 安装docker\n由于kubeadm的ha模式对docker的版本是有一定的要求的，因此，本教程中安装官方推荐的docker版本。\n\n```\n# 安装依赖包\nyum install -y yum-utils device-mapper-persistent-data lvm2\n\n# 添加Docker软件包源\nyum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo\n\n#关闭测试版本list（只显示稳定版）\nsudo yum-config-manager --enable docker-ce-edge\nsudo yum-config-manager --enable docker-ce-test\n\n# 更新yum包索引\nyum makecache fast\n\n#NO.1 指定版本安装\nyum list docker-ce --showduplicates|sort -r  \nyum install docker-ce-18.06.2.ce -y\n```\n为了方便操作，我们在tf-k8s-m1节点上，创建一个批量部署docker的脚本。\n\n```\n## 创建install.docker.sh\n\n#!/bin/sh\n\nvhosts=\"tf-k8s-m1 tf-k8s-m2 tf-k8s-m3 tf-k8s-n1 tf-k8s-n2\"\n\nfor h in $vhosts\ndo\n    echo \"Install docker for $h\"\n    ssh kube@$h \"sudo yum install docker-ce-18.06.2.ce -y && sudo systemctl enable docker && systemctl start docker\"\ndone \n```\n执行install.docker.sh脚本\n\n```\nchmod a+x install.docker.sh\nsh ./install.docker.sh\n```\n\n### 2.2 安装kubernetes yum源和kubelet、kubeadm、kubectl组件\n#### 2.2.1 所有机器上配置 kubernetes.repo yum 源\n详细的安装脚本如下：\n\n```\n## 创建脚本：install.k8s.repo.sh\n\n#!/bin/sh\n\nvhost=\"tf-k8s-m1 tf-k8s-m2 tf-k8s-m3 tf-k8s-n1 tf-k8s-n2\"\n\n## 设置为阿里云 kubernetes 仓库\ncat <<EOF > kubernetes.repo\n[kubernetes]\nname=Kubernetes\nbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/\nenabled=1\ngpgcheck=1\nrepo_gpgcheck=1\ngpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg\nEOF\n\nmvCmd=\"sudo cp ~/kubernetes.repo /etc/yum.repos.d/\"\nfor h in $vhost\ndo\n  echo \"Setup kubernetes repository for $h\"\n  scp ./kubernetes.repo kube@$h:~\n  ssh kube@$h $mvCmd\ndone\n\n```\n执行install.k8s.repo.sh脚本\n\n```\nchmod a+x install.k8s.repo.sh\nsh ./install.k8s.repo.sh\n```\n\n#### 2.2.2 所有机器上安装 kubelet、kubeadm、kubectl组件\n详细安装脚本如下：\n\n```\n## 创建脚本：install.k8s.basic.sh\n\n#!/bin/sh\n\nvhost=\"tf-k8s-m1 tf-k8s-m2 tf-k8s-m3 tf-k8s-n1 tf-k8s-n2\"\n\n## 安装 kubelet kubeadm kubectl\ninstallCmd=\"sudo yum install -y kubelet kubeadm kubectl && sudo systemctl enable kubelet\"\nfor h in $vhost\ndo\n  echo \"Install kubelet kubeadm kubectl for : $h\"\n  ssh kube@$h $installCmd\ndone\n```\n执行install.k8s.baisc.sh脚本\n\n```\nchmod a+x install.k8s.basic.sh\nsh ./install.k8s.basic.sh\n```\n### 2.3 初始化kubeadm配置文件\n创建三台master机器tf-k8s-m1,tf-k8s-m2,tf-k8s-m3的kubeadm配置文件，其中主要是配置生成证书的域配置、etcd集群配置。\n\n```\n## 创建脚本：init.kubeadm.config.sh\n\n#!/bin/sh\n\n## 1. 配置参数 \n## vhost 主机名和 vhostIP IP 一一对应\nvhost=(tf-k8s-m1 tf-k8s-m2 tf-k8s-m3)\nvhostIP=(10.0.0.1 10.0.0.2 10.0.0.3)\n\ndomain=api.tf-k8s.xiangwushuo.com\n\n## etcd 初始化 m01 m02 m03 集群配置\netcdInitCluster=(\ntf-k8s-m1=https://10.0.0.1:2380\ntf-k8s-m1=https://10.0.0.1:2380,tf-k8s-m2=https://10.0.0.2:2380\ntf-k8s-m1=https://10.0.0.1:2380,tf-k8s-m2=https://10.0.0.2:2380,tf-k8s-m3=https://10.0.0.3:2380\n)\n\n## etcd 初始化时，m01 m02 m03 分别的初始化集群状态\ninitClusterStatus=(\nnew\nexisting\nexisting\n)\n\n\n## 2.遍历 master 主机名和对应 IP\n## 生成对应的 kubeadmn 配置文件 \nfor i in `seq 0 $((${#vhost[*]}-1))`\ndo\n\nh=${vhost[${i}]} \nip=${vhostIP[${i}]}\n\necho \"--> $h - $ip\"\n  \n## 生成 kubeadm 配置模板\ncat <<EOF > kubeadm-config.$h.yaml\napiVersion: kubeadm.k8s.io/v1beta1\nkind: InitConfiguration\nlocalAPIEndpoint:\n  advertiseAddress: $ip\n  bindPort: 6443\n---\napiVersion: kubeadm.k8s.io/v1beta1\nkind: ClusterConfiguration\nkubernetesVersion: v1.13.3\n\n# 指定阿里云镜像仓库\nimageRepository: registry.aliyuncs.com/google_containers\n\n# apiServerCertSANs 填所有的 masterip、lbip、其它可能需要通过它访问 apiserver 的地址、域名或主机名等，\n# 如阿里fip，证书中会允许这些ip\n# 这里填一个自定义的域名\napiServer:\n  certSANs:\n  - \"$domain\"\ncontrolPlaneEndpoint: \"$domain:6443\"\n\n## Etcd 配置\netcd:\n  local:\n    extraArgs:\n      listen-client-urls: \"https://127.0.0.1:2379,https://$ip:2379\"\n      advertise-client-urls: \"https://$ip:2379\"\n      listen-peer-urls: \"https://$ip:2380\"\n      initial-advertise-peer-urls: \"https://$ip:2380\"\n      initial-cluster: \"${etcdInitCluster[${i}]}\"\n      initial-cluster-state: ${initClusterStatus[${i}]}\n    serverCertSANs:\n      - $h\n      - $ip\n    peerCertSANs:\n      - $h\n      - $ip\nnetworking:\n  podSubnet: \"10.244.0.0/16\"\n\nEOF\n\necho \"kubeadm-config.$h.yaml created ... ok\"\n\n## 3. 分发到其他 master 机器 \nscp kubeadm-config.$h.yaml kube@$h:~\necho \"scp kubeadm-config.$h.yaml ... ok\"\n\ndone\n```\n执行init.kubeadm.config.sh脚本\n\n```\nchmod a+x init.kubeadm.config.sh\nsh ./init.kubeadm.config.sh\n```\n执行成功之后，可以在tf-k8s-m1, tf-k8s-m2, tf-k8s-m3的 kube 用户的 home 目录（/home/kube）能看到对应的 kubeadm-config.tf-k8s-m1*.yaml 配置文件。 这个配置文件主要是用于后续初始化集群其他 master 的证书、 etcd 配置、kubelet 配置、kube-apiserver配置、kube-controller-manager 配置等。\n各个master节点上对应的kubeadm配置文件：\n\n```\ncvm tf-k8s-m1：kubeadm-config.tf-k8s-m1.yaml\ncvm tf-k8s-m2：kubeadm-config.tf-k8s-m2.yaml\ncvm tf-k8s-m3：kubeadm-config.tf-k8s-m3.yaml\n```\n\n### 2.4 安装master镜像和执行kubeadm初始化\n#### 2.4.1 拉取镜像到本地\n因为 k8s.gcr.io 国内无法访问，我们可以选择通过阿里云的镜像仓库（kubeadm-config.tf-k8s-m1*.yaml 配置文件中已经指定使用阿里云镜像仓库  registry.aliyuncs.com/google_containers），将所需的镜像 pull 到本地。\n我们可以通过以下命令，来查看是否已经成功指定了阿里云的镜像仓库,在tf-k8s-m1机器上，通过`kubeadm config images list`命令来查看，结果如下:\n\n```\n[kube@tf-k8s-m1 ~]$ kubeadm config images list --config kubeadm-config.tf-k8s-m1.yaml\nregistry.aliyuncs.com/google_containers/kube-apiserver:v1.13.3\nregistry.aliyuncs.com/google_containers/kube-controller-manager:v1.13.3\nregistry.aliyuncs.com/google_containers/kube-scheduler:v1.13.3\nregistry.aliyuncs.com/google_containers/kube-proxy:v1.13.3\nregistry.aliyuncs.com/google_containers/pause:3.1\nregistry.aliyuncs.com/google_containers/etcd:3.2.24\nregistry.aliyuncs.com/google_containers/coredns:1.2.6\n\n```\n接下来，分别在tf-k8s-m1、tf-k8s-m2、tf-k8s-m3机器上，拉取相关镜像\n\n```\n[kube@tf-k8s-m1 ~]$ sudo kubeadm config images pull --config kubeadm-config.tf-k8s-m1.yaml\n[kube@tf-k8s-m2 ~]$ sudo kubeadm config images pull --config kubeadm-config.tf-k8s-m2.yaml\n[kube@tf-k8s-m3 ~]$ sudo kubeadm config images pull --config kubeadm-config.tf-k8s-m3.yaml\n```\n执行成功后，应该能够看到本地已经拉取的镜像\n\n```\n[kube@tf-k8s-m1 ~]$ sudo docker images\nREPOSITORY                                                                     TAG                 IMAGE ID            CREATED             SIZE\nregistry.aliyuncs.com/google_containers/kube-apiserver                         v1.13.3             fe242e556a99        2 weeks ago         181MB\nregistry.aliyuncs.com/google_containers/kube-proxy                             v1.13.3             98db19758ad4        2 weeks ago         80.3MB\nregistry.aliyuncs.com/google_containers/kube-controller-manager                v1.13.3             0482f6400933        2 weeks ago         146MB\nregistry.aliyuncs.com/google_containers/kube-scheduler                         v1.13.3             3a6f709e97a0        2 weeks ago         79.6MB\nquay.io/coreos/flannel                                                         v0.11.0-amd64       ff281650a721        2 weeks ago         52.6MB\nregistry.cn-hangzhou.aliyuncs.com/google_containers/nginx-ingress-controller   0.21.0              01bd760f276c        2 months ago        568MB\nregistry.aliyuncs.com/google_containers/coredns                                1.2.6               f59dcacceff4        3 months ago        40MB\nregistry.aliyuncs.com/google_containers/etcd                                   3.2.24              3cab8e1b9802        5 months ago        220MB\nregistry.aliyuncs.com/google_containers/pause                                  3.1                 da86e6ba6ca1        14 months ago       742kB\n```\n\n#### 2.4.2 安装master tf-k8s-m1\n我们目标是要搭建一个高可用的 master 集群，所以需要在三台 master tf-k8s-m1 tf-k8s-m2 tf-k8s-m3机器上分别通过 kubeadm 进行初始化。\n由于 tf-k8s-m2 和 tf-k8s-m3 的初始化需要依赖 tf-k8s-m1 初始化成功后所生成的证书文件，所以这里需要先在 m01 初始化。\n\n```\n[kube@tf-k8s-m1 ~]$  sudo kubeadm init --config kubeadm-config.tf-k8s-m1.yaml \n```\n初始化成功后，会看到如下日志：\n**备注：如果初始化失败，则可以通过`kubeadm reset --force`命令重置之前kubeadm init命令的执行结果，恢复一个干净的环境**\n\n```\n[init] Using Kubernetes version: v1.13.3\n[preflight] Running pre-flight checks\n[preflight] Pulling images required for setting up a Kubernetes cluster\n[preflight] This might take a minute or two, depending on the speed of your internet connection\n[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'\n[kubelet-start] Writing kubelet environment file with flags to file \"/var/lib/kubelet/kubeadm-flags.env\"\n[kubelet-start] Writing kubelet configuration to file \"/var/lib/kubelet/config.yaml\"\n[kubelet-start] Activating the kubelet service\n[certs] Using certificateDir folder \"/etc/kubernetes/pki\"\n[certs] Generating \"ca\" certificate and key\n[certs] Generating \"apiserver\" certificate and key\n[certs] apiserver serving cert is signed for DNS names [m01 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local api.k8s.hiko.im api.k8s.hiko.im] and IPs [10.96.0.1 10.0.2.15]\n[certs] Generating \"apiserver-kubelet-client\" certificate and key\n[certs] Generating \"front-proxy-ca\" certificate and key\n[certs] Generating \"front-proxy-client\" certificate and key\n[certs] Generating \"etcd/ca\" certificate and key\n[certs] Generating \"etcd/server\" certificate and key\n[certs] etcd/server serving cert is signed for DNS names [m01 localhost m01] and IPs [10.0.2.15 127.0.0.1 ::1 192.168.33.10]\n[certs] Generating \"etcd/peer\" certificate and key\n[certs] etcd/peer serving cert is signed for DNS names [m01 localhost m01] and IPs [10.0.2.15 127.0.0.1 ::1 192.168.33.10]\n[certs] Generating \"etcd/healthcheck-client\" certificate and key\n[certs] Generating \"apiserver-etcd-client\" certificate and key\n[certs] Generating \"sa\" key and public key\n[kubeconfig] Using kubeconfig folder \"/etc/kubernetes\"\n[kubeconfig] Writing \"admin.conf\" kubeconfig file\n[kubeconfig] Writing \"kubelet.conf\" kubeconfig file\n[kubeconfig] Writing \"controller-manager.conf\" kubeconfig file\n[kubeconfig] Writing \"scheduler.conf\" kubeconfig file\n[control-plane] Using manifest folder \"/etc/kubernetes/manifests\"\n[control-plane] Creating static Pod manifest for \"kube-apiserver\"\n[control-plane] Creating static Pod manifest for \"kube-controller-manager\"\n[control-plane] Creating static Pod manifest for \"kube-scheduler\"\n[etcd] Creating static Pod manifest for local etcd in \"/etc/kubernetes/manifests\"\n[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory \"/etc/kubernetes/manifests\". This can take up to 4m0s\n[apiclient] All control plane components are healthy after 19.009523 seconds\n[uploadconfig] storing the configuration used in ConfigMap \"kubeadm-config\" in the \"kube-system\" Namespace\n[kubelet] Creating a ConfigMap \"kubelet-config-1.13\" in namespace kube-system with the configuration for the kubelets in the cluster\n[patchnode] Uploading the CRI Socket information \"/var/run/dockershim.sock\" to the Node API object \"m01\" as an annotation\n[mark-control-plane] Marking the node m01 as control-plane by adding the label \"node-role.kubernetes.io/master=''\"\n[mark-control-plane] Marking the node m01 as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]\n[bootstrap-token] Using token: a1t7c1.mzltpc72dc3wzj9y\n[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles\n[bootstraptoken] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials\n[bootstraptoken] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token\n[bootstraptoken] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster\n[bootstraptoken] creating the \"cluster-info\" ConfigMap in the \"kube-public\" namespace\n[addons] Applied essential addon: CoreDNS\n[addons] Applied essential addon: kube-proxy\n\nYour Kubernetes master has initialized successfully!\n\nTo start using your cluster, you need to run the following as a regular user:\n\n  mkdir -p $HOME/.kube\n  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n  sudo chown $(id -u):$(id -g) $HOME/.kube/config\n\nYou should now deploy a pod network to the cluster.\nRun \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at:\n  https://kubernetes.io/docs/concepts/cluster-administration/addons/\n\nYou can now join any number of machines by running the following on each node\nas root:\n\n  kubeadm join api.k8s.hiko.im:6443 --token a1t7c1.mzltpc72dc3wzj9y --discovery-token-ca-cert-hash sha256:05f44b111174613055975f012fc11fe09bdcd746bd7b3c8d99060c52619f8738\n\n```\n至此，就完成了第一台master的初始化工作。\n\n#### 2.4.3 kube用户配置\n为了让tf-k8s-m1的 kube 用户能通过 kubectl 管理集群，接着我们需要给tf-k8s-m1 的 kube 用户配置管理集群的配置。在tf-k8s-m1机器上创建config.using.cluster.sh脚本，具体如下：\n\n```\n## 创建脚本：config.using.cluster.sh\n\n#!/bin/sh\n\n# 为 kube 用户配置\nmkdir -p $HOME/.kube\nsudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nsudo chown $(id -u):$(id -g) $HOME/.kube/config\n```\n执行config.using.cluster.sh脚本\n\n```\nchmod a+x config.using.cluster.sh\nsh ./config.using.cluster.sh\n```\n验证结果，通过`kubectl`命令查看集群状态，结果如下：\n\n```\n[kube@tf-k8s-m1 ~]$ kubectl cluster-info\nKubernetes master is running at https://api.tf-k8s.xiangwushuo.com:6443\nKubeDNS is running at https://api.tf-k8s.xiangwushuo.com:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n```\n查看集群所有的pods信息，结果如下：\n\n```\n[kube@tf-k8s-m1 ~]$ kubectl get pods --all-namespaces\n\nNAMESPACE     NAME                          READY   STATUS    RESTARTS   AGE\nkube-system   coredns-78d4cf999f-cw79l      0/1     Pending   0          47m\nkube-system   coredns-78d4cf999f-w8j47      0/1     Pending   0          47m\nkube-system   etcd-m01                      1/1     Running   0          47m\nkube-system   kube-apiserver-m01            1/1     Running   0          46m\nkube-system   kube-controller-manager-m01   1/1     Running   0          46m\nkube-system   kube-proxy-5954k              1/1     Running   0          47m\nkube-system   kube-scheduler-m01            1/1     Running   0          47m\n```\n其中，由于未安装相关的网络组件，eg:flannel,所有coredn还是显示为pending，暂时没有影响。\n\n#### 2.4.4 安装CNI插件flannel\n**备注：所有的节点都需要安装**\n具体的安装脚本如下：\n\n```\n## 拉取镜像\nsudo docker pull quay.io/coreos/flannel:v0.11.0-amd64\n## 部署\nkubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml\n```\n安装成功之后，通过 `kubectl get pods --all-namespaces`，看到所有 Pod 都正常了.\n\n### 2.5 安装剩余的master\n#### 2.5.1 同步tf-k8s-m1的ca证书\n首先，将 tf-k8s-m1 中的 ca 证书，scp 到其他 master 机器（tf-k8s-m2 tf-k8s-m3）。\n为了方便，这里也是通过脚本来执行，具体如下：\n注意：需要确认 tf-k8s-m1 上的 root 账号可以免密登录到 tf-k8s-m2 和 tf-k8s-m3 的 root 账号。\n\n```\n## 创建脚本：sync.master.ca.sh\n\n#!/bin/sh\n\nvhost=\"tf-k8s-m2 tf-k8s-m3\"\nusr=root\n\nwho=`whoami`\nif [[ \"$who\" != \"$usr\" ]];then\n  echo \"请使用 root 用户执行或者 sudo ./sync.master.ca.sh\"\n  exit 1\nfi\n\necho $who\n\n# 需要从 m01 拷贝的 ca 文件\ncaFiles=(\n/etc/kubernetes/pki/ca.crt\n/etc/kubernetes/pki/ca.key\n/etc/kubernetes/pki/sa.key\n/etc/kubernetes/pki/sa.pub\n/etc/kubernetes/pki/front-proxy-ca.crt\n/etc/kubernetes/pki/front-proxy-ca.key\n/etc/kubernetes/pki/etcd/ca.crt\n/etc/kubernetes/pki/etcd/ca.key\n/etc/kubernetes/admin.conf\n)\n\npkiDir=/etc/kubernetes/pki/etcd\nfor h in $vhost \ndo\n\n  ssh ${usr}@$h \"mkdir -p $pkiDir\"\n  \n  echo \"Dirs for ca scp created, start to scp...\"\n\n  # scp 文件到目标机\n  for f in ${caFiles[@]}\n  do \n    echo \"scp $f ${usr}@$h:$f\"\n    scp $f ${usr}@$h:$f\n  done\n\n  echo \"Ca files transfered for $h ... ok\"\ndone\n```\n执行脚本，将 tf-k8s-m1 相关的 ca 文件传到tf-k8s-m2 和 tf-k8s-m3：\n\n```\nchmod +x sync.master.ca.sh\n\nsudo ./syncaster.ca.sh\n```\n\n#### 2.5.2 安装master tf-k8s-m2\n总共分为四个步骤，分别是:总1. 共分为四个步骤，分别是:\n* 配置证书、初始化 kubelet 配置和启动 kubelet\n\n```\n[kube@tf-k8s-m2 ~]$ sudo kubeadm init phase certs all --config kubeadm-config.tf-k8s-m2.yaml\n[kube@tf-k8s-m2 ~]$ sudo kubeadm init phase etcd local --config kubeadm-config.tf-k8s-m2.yaml\n[kube@tf-k8s-m2 ~]$ sudo kubeadm init phase kubeconfig kubelet --config kubeadm-config.tf-k8s-m2.yaml\n[kube@tf-k8s-m2 ~]$ sudo kubeadm init phase kubelet-start --config kubeadm-config.tf-k8s-m2.yaml\n```\n* 将etcd加入集群\n\n```\n[kube@tf-k8s-m2 root]$ kubectl exec -n kube-system etcd-tf-k8s-m1 -- etcdctl --ca-file /etc/kubernetes/pki/etcd/ca.crt --cert-file /etc/kubernetes/pki/etcd/peer.crt --key-file /etc/kubernetes/pki/etcd/peer.key --endpoints=https://10.0.0.1:2379 member add tf-k8s-m2 https://10.0.0.2:2380\n```\n\n启动kube-apiserver、kube-controller-manager、kube-scheduler\n\n```\n[kube@tf-k8s-m2 ~]$ sudo kubeadm init phase kubeconfig all --config kubeadm-config.m02.yaml\n[kube@tf-k8s-m2 ~]$ sudo kubeadm init phase control-plane all --config kubeadm-config.m02.yaml\n```\n将节点标记为master节点\n\n```\n[kube@tf-k8s-m2 ~]$ sudo kubeadm init phase mark-control-plane --config kubeadm-config.m02.yaml\n```\n\n#### 2.5.3 安装master tf-k8s-m3\n安装过程和安装master tf-k8s-m2是一样的，区别在于使用的kubeadm配置文件为kubeadm-config.tf-k8s-m3.yaml以及etcd加入成员时指定的实例地址不一样。\n完整的流程如下:\n\n```\n# 1.  配置证书、初始化 kubelet 配置和启动 kubelet\nsudo kubeadm init phase certs all --config kubeadm-config.tf-k8s-m3.yaml\nsudo kubeadm init phase etcd local --config kubeadm-config.tf-k8s-m3.yaml\nsudo kubeadm init phase kubeconfig kubelet --config kubeadm-config.tf-k8s-m3.yaml\nsudo kubeadm init phase kubelet-start --config kubeadm-config.tf-k8s-m3.yaml\n\n# 2. 将 etcd 加入集群\nkubectl exec -n kube-system etcd-tf-k8s-m1 -- etcdctl --ca-file /etc/kubernetes/pki/etcd/ca.crt --cert-file /etc/kubernetes/pki/etcd/peer.crt --key-file /etc/kubernetes/pki/etcd/peer.key --endpoints=https://10.0.0.1:2379 member add tf-k8s-m3 https://10.0.0.3:2380\n\n# 3. 启动 kube-apiserver、kube-controller-manager、kube-scheduler\nsudo kubeadm init phase kubeconfig all --config kubeadm-config.tf-k8s-m3.yaml\nsudo kubeadm init phase control-plane all --config kubeadm-config.tf-k8s-m3.yaml\n\n# 4. 将节点标记为 master 节点\nsudo kubeadm init phase mark-control-plane --config kubeadm-config.tf-k8s-m3.yaml\n```\n#### 2.5.4 验证三个master节点\n至此，三个 master 节点安装完成，通过 kubectl get pods --all-namespaces 查看当前集群所有 Pod。\n\n```\n[kube@tf-k8s-m2 ~]$ kubectl  get pods --all-namespaces\nNAMESPACE     NAME                          READY   STATUS    RESTARTS   AGE\nkube-system   coredns-78d4cf999f-j8zsr      1/1     Running   0          170m\nkube-system   coredns-78d4cf999f-lw5qx      1/1     Running   0          171m\nkube-system   etcd-m01                      1/1     Running   8          5h11m\nkube-system   etcd-m02                      1/1     Running   12         97m\nkube-system   etcd-m03                      1/1     Running   0          91m\nkube-system   kube-apiserver-m01            1/1     Running   9          5h11m\nkube-system   kube-apiserver-m02            1/1     Running   0          95m\nkube-system   kube-apiserver-m03            1/1     Running   0          91m\nkube-system   kube-controller-manager-m01   1/1     Running   4          5h11m\nkube-system   kube-controller-manager-m02   1/1     Running   0          95m\nkube-system   kube-controller-manager-m03   1/1     Running   0          91m\nkube-system   kube-flannel-ds-amd64-7b86z   1/1     Running   0          3h31m\nkube-system   kube-flannel-ds-amd64-98qks   1/1     Running   0          91m\nkube-system   kube-flannel-ds-amd64-ljcdp   1/1     Running   0          97m\nkube-system   kube-proxy-krnjq              1/1     Running   0          5h12m\nkube-system   kube-proxy-scb25              1/1     Running   0          91m\nkube-system   kube-proxy-xp4rj              1/1     Running   0          97m\nkube-system   kube-scheduler-m01            1/1     Running   4          5h11m\nkube-system   kube-scheduler-m02            1/1     Running   0          95m\nkube-system   kube-scheduler-m03            1/1     Running   0          91m\n```\n#### 2.5.5 加入工作节点\n这步很简单，只需要在工作节点 tf-k8s-n1 和 tf-k8s-n2 上执行加入集群的命令即可。\n\n可以使用上面安装 master tf-k8s-m1 成功后打印的命令 kubeadm join api.tf-k8s.xiangwushuo.com:6443 --token a1t7c1.mzltpc72dc3wzj9y --discovery-token-ca-cert-hash sha256:05f44b111174613055975f012fc11fe09bdcd746bd7b3c8d99060c52619f8738，也可以重新生成 Token。\n这里演示如何重新生成 Token 和 证书 hash，在 tf-k8s-m1 上执行以下操作：\n\n```\n# 1. 创建 token\n[kube@tf-k8s-m1 ~]$ kubeadm token create \n\n# 控制台打印如：\ngz1v4w.sulpuxkqtnyci92f\n\n# 2.  查看我们创建的 k8s 集群的证书 hash\n[kube@tf-k8s-m1 ~]$ openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2>/dev/null | openssl dgst -sha256 -hex | sed 's/^.* //'\n\n# 控制台打印如：\nb125cd0c80462353d8fa3e4f5034f1e1a1e3cc9bade32acfb235daa867c60f61\n```\n然后使用`kubeadm join`,分别在工作节点tf-k8s-n1与tf-k8s-n2上执行，将节点加入\n集群，如下：\n\n```\nsudo kubeadm join api.tf-k8s.xiangwushuo.com:6443 --token gz1v4w.sulpuxkqtnyci92f --discovery-token-ca-cert-hash sha256:b125cd0c80462353d8fa3e4f5034f1e1a1e3cc9bade32acfb235daa867c60f61\n```\n\n在 tf-k8s-m1 上通过 kubectl get nodes 查看，将看到节点已被加进来（节点刚加进来时，状态可能会是 NotReady，稍等一会就回变成 Ready）。\n\n### 2.6 部署高可用CoreDNS\n默认安装的 CoreDNS 存在单点问题。在 m01 上通过 kubectl get pods -n kube-system -owide 查看当前集群 CoreDNS Pod 分布（如下）。\n\n从列表中，可以看到 CoreDNS 的两个 Pod 都在 m01 上，存在单点问题。\n\n```\n[kube@tf-k8s-m1 ~]$ kubectl get pods -n kube-system -owide\nNAME                                    READY   STATUS    RESTARTS   AGE     IP            NODE        NOMINATED NODE   READINESS GATES\ncoredns-6c67f849c7-h7lcr                1/1     Running   0          4d3h    10.244.3.2    tf-k8s-m1   <none>           <none>\ncoredns-6c67f849c7-mx9k9                1/1     Running   0          4d3h    10.244.4.2    tf-k8s-m1   <none>           <none>\netcd-tf-k8s-m1                          1/1     Running   1          4d5h    10.0.0.1   tf-k8s-m1   <none>           <none>\netcd-tf-k8s-m2                          1/1     Running   7          4d3h    10.0.0.2   tf-k8s-m2   <none>           <none>\netcd-tf-k8s-m3                          1/1     Running   7          4d3h    10.0.0.3   tf-k8s-m3   <none>           <none>\nkube-apiserver-tf-k8s-m1                1/1     Running   0          4d5h    10.0.0.1   tf-k8s-m1   <none>           <none>\nkube-apiserver-tf-k8s-m2                1/1     Running   0          4d3h    10.0.0.2   tf-k8s-m2   <none>           <none>\nkube-apiserver-tf-k8s-m3                1/1     Running   0          4d3h    10.0.0.3   tf-k8s-m3   <none>           <none>\nkube-controller-manager-tf-k8s-m1       1/1     Running   1          4d5h    10.0.0.1   tf-k8s-m1   <none>           <none>\nkube-controller-manager-tf-k8s-m2       1/1     Running   0          4d3h    10.0.0.2   tf-k8s-m2   <none>           <none>\nkube-controller-manager-tf-k8s-m3       1/1     Running   0          4d3h    10.0.0.3   tf-k8s-m3   <none>           <none>\nkube-flannel-ds-amd64-4v6dd             1/1     Running   1          4d3h    10.0.0.5   tf-k8s-n2   <none>           <none>\nkube-flannel-ds-amd64-g6sg5             1/1     Running   0          4d3h    10.0.0.3   tf-k8s-m3   <none>           <none>\nkube-flannel-ds-amd64-ml4w7             1/1     Running   1          4d3h    10.0.0.4   tf-k8s-n1   <none>           <none>\nkube-flannel-ds-amd64-tb27x             1/1     Running   0          4d3h    10.0.0.2   tf-k8s-m2   <none>           <none>\nkube-flannel-ds-amd64-x5dqj             1/1     Running   0          4d4h    10.0.0.1   tf-k8s-m1   <none>           <none>\nkube-proxy-4wbn7                        1/1     Running   0          4d3h    10.0.0.4   tf-k8s-n1   <none>           <none>\nkube-proxy-8dhtz                        1/1     Running   0          4d3h    10.0.0.2   tf-k8s-m2   <none>           <none>\nkube-proxy-l8727                        1/1     Running   0          4d5h    10.0.0.1   tf-k8s-m1   <none>           <none>\nkube-proxy-tz924                        1/1     Running   0          4d3h    10.0.0.5   tf-k8s-n2   <none>           <none>\nkube-proxy-w7tmn                        1/1     Running   0          4d3h    10.0.0.3   tf-k8s-m3   <none>           <none>\nkube-scheduler-tf-k8s-m1                1/1     Running   1          4d5h    10.0.0.1   tf-k8s-m1   <none>           <none>\nkube-scheduler-tf-k8s-m2                1/1     Running   0          4d3h    10.0.0.2   tf-k8s-m2   <none>           <none>\nkube-scheduler-tf-k8s-m3                1/1     Running   0          4d3h    10.0.0.3   tf-k8s-m3   <none>           <none>\nkubernetes-dashboard-847f8cb7b8-hmf9m   1/1     Running   0          3d23h   10.244.4.4    tf-k8s-n2   <none>           <none>\nmetrics-server-8658466f94-pzl6z         1/1     Running   0          4d2h    10.244.3.3    tf-k8s-n1   <none>           <none>\n```\n首先删除CoreDNS的deploy，然后创建新的CoreDNS-HA.yaml配置文件，如下\n\n```\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    k8s-app: kube-dns\n  name: coredns\n  namespace: kube-system\nspec:\n  #集群规模可自行配置\n  replicas: 2\n  selector:\n    matchLabels:\n      k8s-app: kube-dns\n  strategy:\n    rollingUpdate:\n      maxSurge: 25%\n      maxUnavailable: 1\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        k8s-app: kube-dns\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchExpressions:\n                - key: k8s-app\n                  operator: In\n                  values:\n                  - kube-dns\n              topologyKey: kubernetes.io/hostname\n      containers:\n      - args:\n        - -conf\n        - /etc/coredns/Corefile\n        image: registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:1.2.6\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /health\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 60\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 5\n        name: coredns\n        ports:\n        - containerPort: 53\n          name: dns\n          protocol: UDP\n        - containerPort: 53\n          name: dns-tcp\n          protocol: TCP\n        - containerPort: 9153\n          name: metrics\n          protocol: TCP\n        resources:\n          limits:\n            memory: 170Mi\n          requests:\n            cpu: 100m\n            memory: 70Mi\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            add:\n            - NET_BIND_SERVICE\n            drop:\n            - all\n          readOnlyRootFilesystem: true\n        terminationMessagePath: /dev/termination-log\n        terminationMessagePolicy: File\n        volumeMounts:\n        - mountPath: /etc/coredns\n          name: config-volume\n          readOnly: true\n      dnsPolicy: Default\n      restartPolicy: Always\n      schedulerName: default-scheduler\n      securityContext: {}\n      serviceAccount: coredns\n      serviceAccountName: coredns\n      terminationGracePeriodSeconds: 30\n      tolerations:\n      - key: CriticalAddonsOnly\n        operator: Exists\n      - effect: NoSchedule\n        key: node-role.kubernetes.io/master\n      volumes:\n      - configMap:\n          defaultMode: 420\n          items:\n          - key: Corefile\n            path: Corefile\n          name: coredns\n        name: config-volume\n```\n部署新的CoreDNS \n\n```\nkubectl apply -f CoreDNS-HA.yaml\n```\n\n### 2.7 部署监控组件metrics-server\n\nkubernetesv1.11 以后不再支持通过 heaspter 采集监控数据。使用新的监控数据采集组件metrics-server。 metrics-server 比 heaspter 轻量很多，也不做数据的持久化存储，提供实时的监控数据查询。\n\n先将所有文件下载，保存在一个文件夹 metrics-server 里。\n\n修改 metrics-server-deployment.yaml 两处地方，分别是：apiVersion 和 image，最终修改后的 metrics-server-deployment.yaml 如下：\n\n```\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: metrics-server\n  namespace: kube-system\n---\n# 将extensions/v1beta1修改为apps/v1\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: metrics-server\n  namespace: kube-system\n  labels:\n    k8s-app: metrics-server\nspec:\n  selector:\n    matchLabels:\n      k8s-app: metrics-server\n  template:\n    metadata:\n      name: metrics-server\n      labels:\n        k8s-app: metrics-server\n    spec:\n      serviceAccountName: metrics-server\n      volumes:\n      # mount in tmp so we can safely use from-scratch images and/or read-only containers\n      - name: tmp-dir\n        emptyDir: {}\n      containers:\n      - name: metrics-server\n        image: cloudnil/metrics-server-amd64:v0.3.1\n        command:\n          - /metrics-server\n          - --kubelet-insecure-tls\n          - --kubelet-preferred-address-types=InternalIP\n        imagePullPolicy: Always\n        volumeMounts:\n        - name: tmp-dir\n          mountPath: /tmp\n```\n进入刚创建的 metrics-server，执行 kubectl apply -f .  进行部署（注意 -f 后面有个点）,如下：\n\n```\n[kube@tf-k8s-m1 metrics-server]$ kubectl apply -f .\n\nclusterrole.rbac.authorization.k8s.io/system:aggregated-metrics-reader created\nclusterrolebinding.rbac.authorization.k8s.io/metrics-server:system:auth-delegator created\nrolebinding.rbac.authorization.k8s.io/metrics-server-auth-reader created\napiservice.apiregistration.k8s.io/v1beta1.metrics.k8s.io created\nserviceaccount/metrics-server created\ndeployment.apps/metrics-server created\nservice/metrics-server created\nclusterrole.rbac.authorization.k8s.io/system:metrics-server created\nclusterrolebinding.rbac.authorization.k8s.io/system:metrics-server created\n```\n运行`kubectl get pods -n kube-system`，确定metrics-server的pods是否正常running。\n\n### 2.8 部署Nginx-ingress-controller\nNginx-ingress-controller 是 kubernetes 官方提供的集成了 Ingress-controller 和 Nginx 的一个 docker 镜像。\n\n本次部署中，将 Nginx-ingress 部署到 tf-k8s-m1、tf-k8s-m2、tf-k8s-m3上，监听宿主机的 80 端口。\n\n创建 nginx-ingress.yaml 文件，内容如下：\n\n```\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: ingress-nginx\n---\nkind: ConfigMap\napiVersion: v1\nmetadata:\n  name: nginx-configuration\n  namespace: ingress-nginx\n  labels:\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/part-of: ingress-nginx\n---\nkind: ConfigMap\napiVersion: v1\nmetadata:\n  name: tcp-services\n  namespace: ingress-nginx\n  labels:\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/part-of: ingress-nginx\n---\nkind: ConfigMap\napiVersion: v1\nmetadata:\n  name: udp-services\n  namespace: ingress-nginx\n  labels:\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/part-of: ingress-nginx\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: nginx-ingress-serviceaccount\n  namespace: ingress-nginx\n  labels:\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/part-of: ingress-nginx\n---\napiVersion: rbac.authorization.k8s.io/v1beta1\nkind: ClusterRole\nmetadata:\n  name: nginx-ingress-clusterrole\n  labels:\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/part-of: ingress-nginx\nrules:\n  - apiGroups:\n      - \"\"\n    resources:\n      - configmaps\n      - endpoints\n      - nodes\n      - pods\n      - secrets\n    verbs:\n      - list\n      - watch\n  - apiGroups:\n      - \"\"\n    resources:\n      - nodes\n    verbs:\n      - get\n  - apiGroups:\n      - \"\"\n    resources:\n      - services\n    verbs:\n      - get\n      - list\n      - watch\n  - apiGroups:\n      - \"extensions\"\n    resources:\n      - ingresses\n    verbs:\n      - get\n      - list\n      - watch\n  - apiGroups:\n      - \"\"\n    resources:\n      - events\n    verbs:\n      - create\n      - patch\n  - apiGroups:\n      - \"extensions\"\n    resources:\n      - ingresses/status\n    verbs:\n      - update\n---\napiVersion: rbac.authorization.k8s.io/v1beta1\nkind: Role\nmetadata:\n  name: nginx-ingress-role\n  namespace: ingress-nginx\n  labels:\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/part-of: ingress-nginx\nrules:\n  - apiGroups:\n      - \"\"\n    resources:\n      - configmaps\n      - pods\n      - secrets\n      - namespaces\n    verbs:\n      - get\n  - apiGroups:\n      - \"\"\n    resources:\n      - configmaps\n    resourceNames:\n      - \"ingress-controller-leader-nginx\"\n    verbs:\n      - get\n      - update\n  - apiGroups:\n      - \"\"\n    resources:\n      - configmaps\n    verbs:\n      - create\n  - apiGroups:\n      - \"\"\n    resources:\n      - endpoints\n    verbs:\n      - get\n---\napiVersion: rbac.authorization.k8s.io/v1beta1\nkind: RoleBinding\nmetadata:\n  name: nginx-ingress-role-nisa-binding\n  namespace: ingress-nginx\n  labels:\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/part-of: ingress-nginx\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: Role\n  name: nginx-ingress-role\nsubjects:\n  - kind: ServiceAccount\n    name: nginx-ingress-serviceaccount\n    namespace: ingress-nginx\n---\napiVersion: rbac.authorization.k8s.io/v1beta1\nkind: ClusterRoleBinding\nmetadata:\n  name: nginx-ingress-clusterrole-nisa-binding\n  labels:\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/part-of: ingress-nginx\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: nginx-ingress-clusterrole\nsubjects:\n  - kind: ServiceAccount\n    name: nginx-ingress-serviceaccount\n    namespace: ingress-nginx\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-ingress-controller\n  namespace: ingress-nginx\n  labels:\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/part-of: ingress-nginx\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: ingress-nginx\n      app.kubernetes.io/part-of: ingress-nginx\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: ingress-nginx\n        app.kubernetes.io/part-of: ingress-nginx\n      annotations:\n        prometheus.io/port: \"10254\"\n        prometheus.io/scrape: \"true\"\n    spec:\n      hostNetwork: true\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: kubernetes.io/hostname\n                operator: In\n                # 指定部署到三台 master 上\n                values:\n                - tf-k8s-m1\n                - tf-k8s-m2\n                - tf-k8s-m3\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            - labelSelector:\n                matchExpressions:\n                  - key: app.kubernetes.io/name\n                    operator: In\n                    values: \n                    - ingress-nginx\n              topologyKey: \"kubernetes.io/hostname\"\n      tolerations:\n      - key: node-role.kubernetes.io/master\n        effect: NoSchedule\n      serviceAccountName: nginx-ingress-serviceaccount\n      containers:\n        - name: nginx-ingress-controller\n          image: registry.cn-hangzhou.aliyuncs.com/google_containers/nginx-ingress-controller:0.21.0\n          args:\n            - /nginx-ingress-controller\n            - --configmap=/nginx-configuration\n            - --tcp-services-configmap=/tcp-services\n            - --udp-services-configmap=/udp-services\n            # - --publish-service=/ingress-nginx\n            - --annotations-prefix=nginx.ingress.kubernetes.io\n          securityContext:\n            capabilities:\n              drop:\n                - ALL\n              add:\n                - NET_BIND_SERVICE\n            # www-data -> 33\n            runAsUser: 33\n          env:\n            - name: POD_NAME\n              valueFrom:\n                fieldRef:\n                  fieldPath: metadata.name\n            - name: POD_NAMESPACE\n              valueFrom:\n                fieldRef:\n                  fieldPath: metadata.namespace\n          ports:\n            - name: http\n              containerPort: 80\n            - name: https\n              containerPort: 443\n          livenessProbe:\n            failureThreshold: 3\n            httpGet:\n              path: /healthz\n              port: 10254\n              scheme: HTTP\n            initialDelaySeconds: 10\n            periodSeconds: 10\n            successThreshold: 1\n            timeoutSeconds: 1\n          readinessProbe:\n            failureThreshold: 3\n            httpGet:\n              path: /healthz\n              port: 10254\n              scheme: HTTP\n            periodSeconds: 10\n            successThreshold: 1\n            timeoutSeconds: 1\n          resources:\n            limits:\n              cpu: 1\n              memory: 1024Mi\n            requests:\n              cpu: 0.25\n              memory: 512Mi\n```\n部署 nginx ingress，执行命令 kubectl apply -f nginx-ingress.yaml\n\n### 2.9 部署kubernetes-dashboard\n#### 2.9.1 Dashboard 配置\n新建部署 dashboard 的资源配置文件：kubernetes-dashboard.yaml，内容如下：\n\n```\napiVersion: v1\nkind: Secret\nmetadata:\n  labels:\n    k8s-app: kubernetes-dashboard\n  name: kubernetes-dashboard-certs\n  namespace: kube-system\ntype: Opaque\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  labels:\n    k8s-app: kubernetes-dashboard\n  name: kubernetes-dashboard\n  namespace: kube-system\n---\nkind: Role\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  name: kubernetes-dashboard-minimal\n  namespace: kube-system\nrules:\n  # Allow Dashboard to create 'kubernetes-dashboard-key-holder' secret.\n- apiGroups: [\"\"]\n  resources: [\"secrets\"]\n  verbs: [\"create\"]\n  # Allow Dashboard to create 'kubernetes-dashboard-settings' config map.\n- apiGroups: [\"\"]\n  resources: [\"configmaps\"]\n  verbs: [\"create\"]\n  # Allow Dashboard to get, update and delete Dashboard exclusive secrets.\n- apiGroups: [\"\"]\n  resources: [\"secrets\"]\n  resourceNames: [\"kubernetes-dashboard-key-holder\", \"kubernetes-dashboard-certs\"]\n  verbs: [\"get\", \"update\", \"delete\"]\n  # Allow Dashboard to get and update 'kubernetes-dashboard-settings' config map.\n- apiGroups: [\"\"]\n  resources: [\"configmaps\"]\n  resourceNames: [\"kubernetes-dashboard-settings\"]\n  verbs: [\"get\", \"update\"]\n  # Allow Dashboard to get metrics from heapster.\n- apiGroups: [\"\"]\n  resources: [\"services\"]\n  resourceNames: [\"heapster\"]\n  verbs: [\"proxy\"]\n- apiGroups: [\"\"]\n  resources: [\"services/proxy\"]\n  resourceNames: [\"heapster\", \"http:heapster:\", \"https:heapster:\"]\n  verbs: [\"get\"]\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: kubernetes-dashboard-minimal\n  namespace: kube-system\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: Role\n  name: kubernetes-dashboard-minimal\nsubjects:\n- kind: ServiceAccount\n  name: kubernetes-dashboard\n  namespace: kube-system\n---\nkind: Deployment\napiVersion: apps/v1\nmetadata:\n  labels:\n    k8s-app: kubernetes-dashboard\n  name: kubernetes-dashboard\n  namespace: kube-system\nspec:\n  replicas: 1\n  revisionHistoryLimit: 10\n  selector:\n    matchLabels:\n      k8s-app: kubernetes-dashboard\n  template:\n    metadata:\n      labels:\n        k8s-app: kubernetes-dashboard\n    spec:\n      containers:\n      - name: kubernetes-dashboard\n        # 使用阿里云的镜像\n        image: registry.cn-hangzhou.aliyuncs.com/google_containers/kubernetes-dashboard-amd64:v1.10.0\n        ports:\n        - containerPort: 8443\n          protocol: TCP\n        args:\n          - --auto-generate-certificates\n        volumeMounts:\n        - name: kubernetes-dashboard-certs\n          mountPath: /certs\n          # Create on-disk volume to store exec logs\n        - mountPath: /tmp\n          name: tmp-volume\n        livenessProbe:\n          httpGet:\n            scheme: HTTPS\n            path: /\n            port: 8443\n          initialDelaySeconds: 30\n          timeoutSeconds: 30\n      volumes:\n      - name: kubernetes-dashboard-certs\n        secret:\n          secretName: kubernetes-dashboard-certs\n      - name: tmp-volume\n        emptyDir: {}\n      serviceAccountName: kubernetes-dashboard\n      tolerations:\n      - key: node-role.kubernetes.io/master\n        effect: NoSchedule\n---\nkind: Service\napiVersion: v1\nmetadata:\n  labels:\n    k8s-app: kubernetes-dashboard\n  name: kubernetes-dashboard\n  namespace: kube-system\nspec:\n  ports:\n    - port: 443\n      targetPort: 8443\n  selector:\n    k8s-app: kubernetes-dashboard\n---\n# 配置 ingress 配置，待会部署完 ingress 之后，就可以通过以下配置的域名访问\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: dashboard-ingress\n  namespace: kube-system\n  annotations:\n    # 如果通过 HTTP 访问，跳转到 HTTPS\n    nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\n    nginx.ingress.kubernetes.io/rewrite-target: /\n    # 指定转发协议为 HTTPS，因为 ingress 默认转发协议是 HTTP，而 kubernetes-dashboard 默认是 HTTPS\n    nginx.ingress.kubernetes.io/backend-protocol: \"HTTPS\"\nspec:\n  # 指定使用的 secret (刚刚创建的 secret)\n  tls:\n   - secretName: secret-ca-tf-k8s-xiangwushuo-com\n  rules:\n  # 指定访问 dashboard 的域名\n  - host: dashboard.tf-k8s.xiangwushuo.com\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: kubernetes-dashboard\n          servicePort: 443\n```\n执行部署 kubernetes-dashboard，命令 kubectl apply -f kubernetes-dashboard.yaml.\n\n在本地笔记本电脑上访问dashboard的时候，需要将dashboard.tf-k8s.xiangwushuo.com域名解析到三台master的IP（配置代理），简单地，可以直接在本地/etc/hosts添加\n\n```\n## 172.66.23.13 为tf-k8s-m1的外网IP\n172.66.23.13 dashboard.tf-k8s.xiangwushuo.com\n```\n从浏览器访问: http://dashboard.tf-k8s.xiangwushuo.com\n![](/images/dashboard-login.png)\n\n\n#### 2.9.2 HTTPS 访问 Dashboard\n由于通过 HTTP 访问 dashboard 会无法登录进去 dashboard 的问题，所以这里我们将 dashboard 的服务配置成 HTTPS 进行访问。\n总共三步:\n签证书（或者使用权威的证书机构颁发的证书）\n\n```\nopenssl req -x509 -nodes -days 3650 -newkey rsa:2048 -keyout ./tf-k8s.xiangwushuo.com.key -out ./tf-k8s.xiangwushuo.com.crt -subj \"/CN=*.xiangwushuo.com\"\n```\n\n创建 k8s Secret 资源\n\n```\nkubectl -n kube-system create secret tls secret-ca-tf-k8s-xiangwushuo-com --key ./tf-k8s.xiangwushuo.com.key --cert tf-k8s.xiangwushuo.com.crt \n```\n\n配置 dashboard 的 ingress 为 HTTPS 访问服务,修改 kubernetes-dashboard.yaml，将其中的 Ingress 配置改为支持 HTTPS，具体配置如下：\n\n```\n...省略...\n\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: dashboard-ingress\n  namespace: kube-system\n  annotations:\n    # 如果通过 HTTP 访问，跳转到 HTTPS\n    nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\n    nginx.ingress.kubernetes.io/rewrite-target: /\n    # 指定转发协议为 HTTPS，因为 ingress 默认转发协议是 HTTP，而 kubernetes-dashboard 默认是 HTTPS\n    nginx.ingress.kubernetes.io/backend-protocol: \"HTTPS\"\nspec:\n  # 指定使用的 secret (刚刚创建的 secret)\n  tls:\n   - secretName: secret-ca-k8s-hiko-im\n  rules:\n  # 指定访问 dashboard 的域名\n  - host: dashboard.k8s.hiko.im\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: kubernetes-dashboard\n          servicePort: 443\n\n```\n使用 kubectl apply -f kubernetes-dashboard.yaml 让配置生效。\n\n#### 2.9.3 .3 登录 Dashboard\n登录 dashboard 需要做几个事情（不用担心，一个脚本搞定）:\n\n新建 sa 的账号（也叫 serviceaccount）\n集群角色绑定（将第 1 步新建的账号，绑定到 cluster-admin 这个角色上）\n查看 Token 以及 Token 中的 secrect （secrect 中的 token 字段就是来登录的）\n执行以下脚本，获得登录的 Token:\n\n```\n\n## 创建脚本：create.dashboard.token.sh\n\n#!/bin/sh\n\nkubectl create sa dashboard-admin -n kube-system\nkubectl create clusterrolebinding dashboard-admin --clusterrole=cluster-admin --serviceaccount=kube-system:dashboard-admin\nADMIN_SECRET=$(kubectl get secrets -n kube-system | grep dashboard-admin | awk '{print $1}')\nDASHBOARD_LOGIN_TOKEN=$(kubectl describe secret -n kube-system ${ADMIN_SECRET} | grep -E '^token' | awk '{print $2}')\necho ${DASHBOARD_LOGIN_TOKEN}\n```\n\n复制 Token 去登录就行，Token 样例：\n\n```\n\neyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJkYXNoYm9hcmQtYWRtaW4tdG9rZW4tNWtnZHoiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoiZGFzaGJvYXJkLWFkbWluIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiYWQxNDAyMjQtMDYxNC0xMWU5LTkxMDgtNTI1NDAwODQ4MWQ1Iiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmUtc3lzdGVtOmRhc2hib2FyZC1hZG1pbiJ9.ry4xYI6TFF6J8xXsilu0qhuBeRjSNqVPq3OUzl62Ad3e2wM-biC5pPlKNmJLfJzurxnQrqp59VjmVeTA8BZiF7S6hqlrk8XE9_LFlItUvq3rp5wFuhJuVol8Yoi4UJFzUYQF6baH0O3R10aK33g2WmWLIg79OFAkeMMHrLthbL2pc_p_kG13_qDXlEuVgnIAFsKzxnrCCUfZ2GwGsHEFEqTGBCb0u6x3AZqfQgbN3DALkjjNTyTLP5Ok-LJ3Ug8SZZQBksvTeXCGXZDfk2LDDIvp_DyM7nTL3CTT5cQ3g4aBTFAae47NAkQkmjZg0mxvJH0xVnxrvXLND8FLLkzMxg\n```\n\n## 3. 参考文献\n[1. kubeadm 1.13 安装高可用 kubernetes v1.13.1 集群](https://www.ctolib.com/HikoQiu-kubeadm-install-k8s.html)\n[2. 如何在CentOS 7上修改主机名](https://www.jianshu.com/p/39d7000dfa47)\n[3. Linux之ssh免密登录](https://blog.csdn.net/mmd0308/article/details/73825953)\n[4. sudo与visudo的超细用法说明](http://blog.51cto.com/chenfage/1830424)\n[5. kubeadm HA master(v1.13.0)离线包 + 自动化脚本 + 常用插件 For Centos/Fedora](https://www.kubernetes.org.cn/4948.html)\n[6. github.coreos.flannel](https://github.com/coreos/flannel)\n[7. Kubernetes Handbook——Kubernetes中文指南/云原生应用架构实践手册](https://jimmysong.io/kubernetes-handbook/)\n\n","source":"_posts/kubeadm1-13创建HAkubernetes集群.md","raw":"---\ntitle: kubeadm1.13创建HAkubernetes集群\ndate: 2019-02-18 10:13:14\ntags: kubernetes\ncategories: 大数据\n---\n[TOC]\n## 一、环境准备\n### 1.1 硬件设备环境\n采用5台腾讯云的CVM作为kubernetes的部署环境，具体信息如下：\n\n| 主机名 | IP | 配置 | 备注 |\n| --- | --- | --- | --- |\n| （Old）VM_0_1_centos；（New）tf-k8s-m1 | 10.0.0.1 | 4c 8g | k8s的master，同时也是etcd节点 |\n| （Old）VM_0_2_centos；（New）tf-k8s-m2 | 10.0.0.2 | 4c 8g | k8s的master，同时也是etcd节点 |\n| （Old）VM_0_3_centos；（New）tf-k8s-m3 | 10.0.0.3 | 4c 8g | k8s的master，同时也是etcd节点 |\n| （Old）VM_0_4_centos；（New）tf-k8s-n1 | 10.0.0.4 | 4c 8g | 工作节点 node，容器编排最终 pod 工作节点 |\n| （Old）VM_0_5_centos；（New）tf-k8s-n2 | 10.0.0.5 | 4c 8g | 工作节点 node，容器编排最终 pod 工作节点 |\n\n### 1.2 软件环境\n\n| 环境 | 简介 |\n| --- | --- |\n| 操作系统 | CentOS7 |\n| kubeadm | 1.13.3 |\n| kubernetes | 1.13.3 |\n| Docker | docker-ce 18.06.2 |\n\n### 1.3 相关系统设置\n在正式安装之前，需要在每台机器上对以下配置进行修改：\n* 关闭防火墙，selinux\n* 关闭系统的swap功能\n* 关闭Linux swap空间的swappiness\n* 配置L2网桥在转发包时会被iptables的FORWARD规则所过滤，该配置被CNI插件需要，更多信息请参考[Network Plugin Requirements](https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/#network-plugin-requirements)\n* 升级内核到最新（centos7 默认的内核是3.10.0-862.el7.x86_64 ,可以使用命令‘uname -a’进行查看），原因见[请问下为什么要用4.18版本内核](https://github.com/Lentil1016/kubeadm-ha/issues/19)\n* 开启IPVS\n* 修改主机名（如果主机名中含有一些特殊字符，则需要调整主机名，不然在后续操作中会出现错误）\n具体的配置修改执行脚本如下：\n\n```\n# ---------- 关闭防火墙和selinux -----------\nsystemctl stop firewalld\nsystemctl disable firewalld\nsetenforce 0\nsed -i \"s/SELINUX=enforcing/SELINUX=disabled/g\" /etc/selinux/config\n\n# ---------- 关闭交换分区 -----------\nswapoff -a\nyes | cp /etc/fstab /etc/fstab_bak\ncat /etc/fstab_bak |grep -v swap > /etc/fstab\n\n# ---------- 设置网桥包经IPTables，core文件生成路径 -----------\necho \"\"\"\nvm.swappiness = 0\nnet.bridge.bridge-nf-call-ip6tables = 1\nnet.bridge.bridge-nf-call-iptables = 1\n\"\"\" > /etc/sysctl.conf\nmodprobe br_netfilter\nsysctl -p\n\n# ---------- 同步时间 -----------\nyum install -y ntpdate\nntpdate -u ntp.api.bz\n\n# ---------- 升级内核 -----------\nrpm -Uvh http://www.elrepo.org/elrepo-release-7.0-2.el7.elrepo.noarch.rpm ;yum --enablerepo=elrepo-kernel install kernel-ml-devel kernel-ml -y\n# 查看启动配置里是否有最新的内核\ncat /boot/grub2/grub.cfg | grep menuentry\n# 修改默认启动项\ngrub2-set-default 0\n# 检查默认内核版本是否大于4.14，否则请调整默认启动参数\ngrub2-editenv list\n#重启以更换内核\nreboot\n#查看内核信息\nuname -a\n\n# ---------- 确认内核版本后，开启IPVS -----------\nuname -a\ncat > /etc/sysconfig/modules/ipvs.modules <<EOF\n#!/bin/bash\nipvs_modules=\"ip_vs ip_vs_lc ip_vs_wlc ip_vs_rr ip_vs_wrr ip_vs_lblc ip_vs_lblcr ip_vs_dh ip_vs_sh ip_vs_fo ip_vs_nq ip_vs_sed ip_vs_ftp nf_conntrack\"\nfor kernel_module in \\${ipvs_modules}; do\n /sbin/modinfo -F filename \\${kernel_module} > /dev/null 2>&1\n if [ $? -eq 0 ]; then\n /sbin/modprobe \\${kernel_module}\n fi\ndone\nEOF\nchmod 755 /etc/sysconfig/modules/ipvs.modules && bash /etc/sysconfig/modules/ipvs.modules && lsmod | grep ip_vs\n\n# ---------- 修改主机名 -----------\n# 这里以VM_0_17_centos主机为例，其他的主机分别修改成相应的主机名\nhostnamectl set-hostname tf-k8s-m1 \n```\n### 1.3 配置集群内各个机器之间的免密码登录\n#### 1.3.1 配置hosts \n为了便于后续的操作，我们需要给每一台设备配置下hosts域名信息，具体如下：\n\n```\n# vi /etc/hosts\n10.0.0.1 tf-k8s-m1 api.tf-k8s.xiangwushuo.com\n10.0.0.2 tf-k8s-m2\n10.0.0.3 tf-k8s-m3\n10.0.0.4 tf-k8s-n1\n10.0.0.5 tf-k8s-n2\n10.0.0.1 dashboard.tf-k8s.xiangwushuo.com\n```\n#### 1.3.2 新建用户\n```\n# useradd kube\n# visudo\n%wheel  ALL=(ALL)       ALL\nkube    ALL=(ALL)       NOPASSWD:ALL\n```\n备注：visudo命令是用来给kube用户添加sudo密码\n#### 1.3.3 设置免密登录\n1. 各个设备的root用户&kube用户（不同用户配置不同的）都生成各自的免密登录的ssh的私钥与公钥\n\n```\n## 为root用户生成ssh的私钥与公钥\nssh-keygen\n```\n在/root目录下，会生成一个.ssh目录，.ssh目录下会生成以下三个文件：\n\n```\n-rw------- 1 root root 2398 Feb 13 15:18 authorized_keys\n-rw------- 1 root root 1679 Feb 13 14:47 id_rsa\n-rw-r--r-- 1 root root  401 Feb 13 14:47 id_rsa.pub\n```\nauthorized_keys文件存储了本设备认证授权的其他设备的公钥信息；id_rsa存储了本设备的私钥信息；id_rsa.pub存储了本设备的公钥信息。\n\n```\n## 为kube用户生成ssh的私钥与公钥\nsu kube\nssh-keygen\n```\n在/home/kube目录下，会生成一个.ssh目录，并包含相关文件。\n2. 各个设备上都创建好各自的ssh免密登录公钥与私钥后，需要将各自的公钥copy至其他的设备上，并将公钥信息添加到各个设备的authorized_keys文件中。\n备注：也需要将各个节点自己的公钥copy至自己的authorized_keys文件中，这样自己才可以ssh自己。\n\n```\n## 将每一台节点上的公钥都同步到相应的目录下\n# ll\n-rw-r--r-- 1 root root  401 Feb 13 15:15 tf-k8s-m1-id_rsa.pub\n-rw-r--r-- 1 root root  401 Feb 13 15:15 tf-k8s-m2-id_rsa.pub\n-rw-r--r-- 1 root root  401 Feb 13 15:15 tf-k8s-m3-id_rsa.pub\n-rw-r--r-- 1 root root  401 Feb 13 15:15 tf-k8s-n1-id_rsa.pub\n-rw-r--r-- 1 root root  401 Feb 13 15:15 tf-k8s-n2-id_rsa.pub\n## 将每台节点的公钥追加至authorized_keys文件中\ncat tf-k8s-m1-id_rsa.pub > authorized_keys\ncat tf-k8s-m2-id_rsa.pub > authorized_keys\ncat tf-k8s-m3-id_rsa.pub > authorized_keys\ncat tf-k8s-n1-id_rsa.pub > authorized_keys\ncat tf-k8s-n2-id_rsa.pub > authorized_keys\n```\n测试是否能够正常使用ssh免密登录\n\n```\nssh root@tf-k8s-m1\nssh root@tf-k8s-m2\nssh root@tf-k8s-m3\nssh root@tf-k8s-n1\nssh root@tf-k8s-n2\n```\n**提示**：如果其他机器上的 root 下的 /root/.ssh/authorized_keys 不存在，可以手动创建。要注意的是：authorized_keys 的权限需要是 600。\n\n```\n## 如果 authorized_keys 的权限不是 600，执行修改权限的命令。\nchmod 600 authorized_keys\n```\n\n## 二、安装步骤\n以下操作，可以都切换至kube用户下进行操作。\n### 2.1 安装docker\n由于kubeadm的ha模式对docker的版本是有一定的要求的，因此，本教程中安装官方推荐的docker版本。\n\n```\n# 安装依赖包\nyum install -y yum-utils device-mapper-persistent-data lvm2\n\n# 添加Docker软件包源\nyum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo\n\n#关闭测试版本list（只显示稳定版）\nsudo yum-config-manager --enable docker-ce-edge\nsudo yum-config-manager --enable docker-ce-test\n\n# 更新yum包索引\nyum makecache fast\n\n#NO.1 指定版本安装\nyum list docker-ce --showduplicates|sort -r  \nyum install docker-ce-18.06.2.ce -y\n```\n为了方便操作，我们在tf-k8s-m1节点上，创建一个批量部署docker的脚本。\n\n```\n## 创建install.docker.sh\n\n#!/bin/sh\n\nvhosts=\"tf-k8s-m1 tf-k8s-m2 tf-k8s-m3 tf-k8s-n1 tf-k8s-n2\"\n\nfor h in $vhosts\ndo\n    echo \"Install docker for $h\"\n    ssh kube@$h \"sudo yum install docker-ce-18.06.2.ce -y && sudo systemctl enable docker && systemctl start docker\"\ndone \n```\n执行install.docker.sh脚本\n\n```\nchmod a+x install.docker.sh\nsh ./install.docker.sh\n```\n\n### 2.2 安装kubernetes yum源和kubelet、kubeadm、kubectl组件\n#### 2.2.1 所有机器上配置 kubernetes.repo yum 源\n详细的安装脚本如下：\n\n```\n## 创建脚本：install.k8s.repo.sh\n\n#!/bin/sh\n\nvhost=\"tf-k8s-m1 tf-k8s-m2 tf-k8s-m3 tf-k8s-n1 tf-k8s-n2\"\n\n## 设置为阿里云 kubernetes 仓库\ncat <<EOF > kubernetes.repo\n[kubernetes]\nname=Kubernetes\nbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/\nenabled=1\ngpgcheck=1\nrepo_gpgcheck=1\ngpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg\nEOF\n\nmvCmd=\"sudo cp ~/kubernetes.repo /etc/yum.repos.d/\"\nfor h in $vhost\ndo\n  echo \"Setup kubernetes repository for $h\"\n  scp ./kubernetes.repo kube@$h:~\n  ssh kube@$h $mvCmd\ndone\n\n```\n执行install.k8s.repo.sh脚本\n\n```\nchmod a+x install.k8s.repo.sh\nsh ./install.k8s.repo.sh\n```\n\n#### 2.2.2 所有机器上安装 kubelet、kubeadm、kubectl组件\n详细安装脚本如下：\n\n```\n## 创建脚本：install.k8s.basic.sh\n\n#!/bin/sh\n\nvhost=\"tf-k8s-m1 tf-k8s-m2 tf-k8s-m3 tf-k8s-n1 tf-k8s-n2\"\n\n## 安装 kubelet kubeadm kubectl\ninstallCmd=\"sudo yum install -y kubelet kubeadm kubectl && sudo systemctl enable kubelet\"\nfor h in $vhost\ndo\n  echo \"Install kubelet kubeadm kubectl for : $h\"\n  ssh kube@$h $installCmd\ndone\n```\n执行install.k8s.baisc.sh脚本\n\n```\nchmod a+x install.k8s.basic.sh\nsh ./install.k8s.basic.sh\n```\n### 2.3 初始化kubeadm配置文件\n创建三台master机器tf-k8s-m1,tf-k8s-m2,tf-k8s-m3的kubeadm配置文件，其中主要是配置生成证书的域配置、etcd集群配置。\n\n```\n## 创建脚本：init.kubeadm.config.sh\n\n#!/bin/sh\n\n## 1. 配置参数 \n## vhost 主机名和 vhostIP IP 一一对应\nvhost=(tf-k8s-m1 tf-k8s-m2 tf-k8s-m3)\nvhostIP=(10.0.0.1 10.0.0.2 10.0.0.3)\n\ndomain=api.tf-k8s.xiangwushuo.com\n\n## etcd 初始化 m01 m02 m03 集群配置\netcdInitCluster=(\ntf-k8s-m1=https://10.0.0.1:2380\ntf-k8s-m1=https://10.0.0.1:2380,tf-k8s-m2=https://10.0.0.2:2380\ntf-k8s-m1=https://10.0.0.1:2380,tf-k8s-m2=https://10.0.0.2:2380,tf-k8s-m3=https://10.0.0.3:2380\n)\n\n## etcd 初始化时，m01 m02 m03 分别的初始化集群状态\ninitClusterStatus=(\nnew\nexisting\nexisting\n)\n\n\n## 2.遍历 master 主机名和对应 IP\n## 生成对应的 kubeadmn 配置文件 \nfor i in `seq 0 $((${#vhost[*]}-1))`\ndo\n\nh=${vhost[${i}]} \nip=${vhostIP[${i}]}\n\necho \"--> $h - $ip\"\n  \n## 生成 kubeadm 配置模板\ncat <<EOF > kubeadm-config.$h.yaml\napiVersion: kubeadm.k8s.io/v1beta1\nkind: InitConfiguration\nlocalAPIEndpoint:\n  advertiseAddress: $ip\n  bindPort: 6443\n---\napiVersion: kubeadm.k8s.io/v1beta1\nkind: ClusterConfiguration\nkubernetesVersion: v1.13.3\n\n# 指定阿里云镜像仓库\nimageRepository: registry.aliyuncs.com/google_containers\n\n# apiServerCertSANs 填所有的 masterip、lbip、其它可能需要通过它访问 apiserver 的地址、域名或主机名等，\n# 如阿里fip，证书中会允许这些ip\n# 这里填一个自定义的域名\napiServer:\n  certSANs:\n  - \"$domain\"\ncontrolPlaneEndpoint: \"$domain:6443\"\n\n## Etcd 配置\netcd:\n  local:\n    extraArgs:\n      listen-client-urls: \"https://127.0.0.1:2379,https://$ip:2379\"\n      advertise-client-urls: \"https://$ip:2379\"\n      listen-peer-urls: \"https://$ip:2380\"\n      initial-advertise-peer-urls: \"https://$ip:2380\"\n      initial-cluster: \"${etcdInitCluster[${i}]}\"\n      initial-cluster-state: ${initClusterStatus[${i}]}\n    serverCertSANs:\n      - $h\n      - $ip\n    peerCertSANs:\n      - $h\n      - $ip\nnetworking:\n  podSubnet: \"10.244.0.0/16\"\n\nEOF\n\necho \"kubeadm-config.$h.yaml created ... ok\"\n\n## 3. 分发到其他 master 机器 \nscp kubeadm-config.$h.yaml kube@$h:~\necho \"scp kubeadm-config.$h.yaml ... ok\"\n\ndone\n```\n执行init.kubeadm.config.sh脚本\n\n```\nchmod a+x init.kubeadm.config.sh\nsh ./init.kubeadm.config.sh\n```\n执行成功之后，可以在tf-k8s-m1, tf-k8s-m2, tf-k8s-m3的 kube 用户的 home 目录（/home/kube）能看到对应的 kubeadm-config.tf-k8s-m1*.yaml 配置文件。 这个配置文件主要是用于后续初始化集群其他 master 的证书、 etcd 配置、kubelet 配置、kube-apiserver配置、kube-controller-manager 配置等。\n各个master节点上对应的kubeadm配置文件：\n\n```\ncvm tf-k8s-m1：kubeadm-config.tf-k8s-m1.yaml\ncvm tf-k8s-m2：kubeadm-config.tf-k8s-m2.yaml\ncvm tf-k8s-m3：kubeadm-config.tf-k8s-m3.yaml\n```\n\n### 2.4 安装master镜像和执行kubeadm初始化\n#### 2.4.1 拉取镜像到本地\n因为 k8s.gcr.io 国内无法访问，我们可以选择通过阿里云的镜像仓库（kubeadm-config.tf-k8s-m1*.yaml 配置文件中已经指定使用阿里云镜像仓库  registry.aliyuncs.com/google_containers），将所需的镜像 pull 到本地。\n我们可以通过以下命令，来查看是否已经成功指定了阿里云的镜像仓库,在tf-k8s-m1机器上，通过`kubeadm config images list`命令来查看，结果如下:\n\n```\n[kube@tf-k8s-m1 ~]$ kubeadm config images list --config kubeadm-config.tf-k8s-m1.yaml\nregistry.aliyuncs.com/google_containers/kube-apiserver:v1.13.3\nregistry.aliyuncs.com/google_containers/kube-controller-manager:v1.13.3\nregistry.aliyuncs.com/google_containers/kube-scheduler:v1.13.3\nregistry.aliyuncs.com/google_containers/kube-proxy:v1.13.3\nregistry.aliyuncs.com/google_containers/pause:3.1\nregistry.aliyuncs.com/google_containers/etcd:3.2.24\nregistry.aliyuncs.com/google_containers/coredns:1.2.6\n\n```\n接下来，分别在tf-k8s-m1、tf-k8s-m2、tf-k8s-m3机器上，拉取相关镜像\n\n```\n[kube@tf-k8s-m1 ~]$ sudo kubeadm config images pull --config kubeadm-config.tf-k8s-m1.yaml\n[kube@tf-k8s-m2 ~]$ sudo kubeadm config images pull --config kubeadm-config.tf-k8s-m2.yaml\n[kube@tf-k8s-m3 ~]$ sudo kubeadm config images pull --config kubeadm-config.tf-k8s-m3.yaml\n```\n执行成功后，应该能够看到本地已经拉取的镜像\n\n```\n[kube@tf-k8s-m1 ~]$ sudo docker images\nREPOSITORY                                                                     TAG                 IMAGE ID            CREATED             SIZE\nregistry.aliyuncs.com/google_containers/kube-apiserver                         v1.13.3             fe242e556a99        2 weeks ago         181MB\nregistry.aliyuncs.com/google_containers/kube-proxy                             v1.13.3             98db19758ad4        2 weeks ago         80.3MB\nregistry.aliyuncs.com/google_containers/kube-controller-manager                v1.13.3             0482f6400933        2 weeks ago         146MB\nregistry.aliyuncs.com/google_containers/kube-scheduler                         v1.13.3             3a6f709e97a0        2 weeks ago         79.6MB\nquay.io/coreos/flannel                                                         v0.11.0-amd64       ff281650a721        2 weeks ago         52.6MB\nregistry.cn-hangzhou.aliyuncs.com/google_containers/nginx-ingress-controller   0.21.0              01bd760f276c        2 months ago        568MB\nregistry.aliyuncs.com/google_containers/coredns                                1.2.6               f59dcacceff4        3 months ago        40MB\nregistry.aliyuncs.com/google_containers/etcd                                   3.2.24              3cab8e1b9802        5 months ago        220MB\nregistry.aliyuncs.com/google_containers/pause                                  3.1                 da86e6ba6ca1        14 months ago       742kB\n```\n\n#### 2.4.2 安装master tf-k8s-m1\n我们目标是要搭建一个高可用的 master 集群，所以需要在三台 master tf-k8s-m1 tf-k8s-m2 tf-k8s-m3机器上分别通过 kubeadm 进行初始化。\n由于 tf-k8s-m2 和 tf-k8s-m3 的初始化需要依赖 tf-k8s-m1 初始化成功后所生成的证书文件，所以这里需要先在 m01 初始化。\n\n```\n[kube@tf-k8s-m1 ~]$  sudo kubeadm init --config kubeadm-config.tf-k8s-m1.yaml \n```\n初始化成功后，会看到如下日志：\n**备注：如果初始化失败，则可以通过`kubeadm reset --force`命令重置之前kubeadm init命令的执行结果，恢复一个干净的环境**\n\n```\n[init] Using Kubernetes version: v1.13.3\n[preflight] Running pre-flight checks\n[preflight] Pulling images required for setting up a Kubernetes cluster\n[preflight] This might take a minute or two, depending on the speed of your internet connection\n[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'\n[kubelet-start] Writing kubelet environment file with flags to file \"/var/lib/kubelet/kubeadm-flags.env\"\n[kubelet-start] Writing kubelet configuration to file \"/var/lib/kubelet/config.yaml\"\n[kubelet-start] Activating the kubelet service\n[certs] Using certificateDir folder \"/etc/kubernetes/pki\"\n[certs] Generating \"ca\" certificate and key\n[certs] Generating \"apiserver\" certificate and key\n[certs] apiserver serving cert is signed for DNS names [m01 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local api.k8s.hiko.im api.k8s.hiko.im] and IPs [10.96.0.1 10.0.2.15]\n[certs] Generating \"apiserver-kubelet-client\" certificate and key\n[certs] Generating \"front-proxy-ca\" certificate and key\n[certs] Generating \"front-proxy-client\" certificate and key\n[certs] Generating \"etcd/ca\" certificate and key\n[certs] Generating \"etcd/server\" certificate and key\n[certs] etcd/server serving cert is signed for DNS names [m01 localhost m01] and IPs [10.0.2.15 127.0.0.1 ::1 192.168.33.10]\n[certs] Generating \"etcd/peer\" certificate and key\n[certs] etcd/peer serving cert is signed for DNS names [m01 localhost m01] and IPs [10.0.2.15 127.0.0.1 ::1 192.168.33.10]\n[certs] Generating \"etcd/healthcheck-client\" certificate and key\n[certs] Generating \"apiserver-etcd-client\" certificate and key\n[certs] Generating \"sa\" key and public key\n[kubeconfig] Using kubeconfig folder \"/etc/kubernetes\"\n[kubeconfig] Writing \"admin.conf\" kubeconfig file\n[kubeconfig] Writing \"kubelet.conf\" kubeconfig file\n[kubeconfig] Writing \"controller-manager.conf\" kubeconfig file\n[kubeconfig] Writing \"scheduler.conf\" kubeconfig file\n[control-plane] Using manifest folder \"/etc/kubernetes/manifests\"\n[control-plane] Creating static Pod manifest for \"kube-apiserver\"\n[control-plane] Creating static Pod manifest for \"kube-controller-manager\"\n[control-plane] Creating static Pod manifest for \"kube-scheduler\"\n[etcd] Creating static Pod manifest for local etcd in \"/etc/kubernetes/manifests\"\n[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory \"/etc/kubernetes/manifests\". This can take up to 4m0s\n[apiclient] All control plane components are healthy after 19.009523 seconds\n[uploadconfig] storing the configuration used in ConfigMap \"kubeadm-config\" in the \"kube-system\" Namespace\n[kubelet] Creating a ConfigMap \"kubelet-config-1.13\" in namespace kube-system with the configuration for the kubelets in the cluster\n[patchnode] Uploading the CRI Socket information \"/var/run/dockershim.sock\" to the Node API object \"m01\" as an annotation\n[mark-control-plane] Marking the node m01 as control-plane by adding the label \"node-role.kubernetes.io/master=''\"\n[mark-control-plane] Marking the node m01 as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]\n[bootstrap-token] Using token: a1t7c1.mzltpc72dc3wzj9y\n[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles\n[bootstraptoken] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials\n[bootstraptoken] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token\n[bootstraptoken] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster\n[bootstraptoken] creating the \"cluster-info\" ConfigMap in the \"kube-public\" namespace\n[addons] Applied essential addon: CoreDNS\n[addons] Applied essential addon: kube-proxy\n\nYour Kubernetes master has initialized successfully!\n\nTo start using your cluster, you need to run the following as a regular user:\n\n  mkdir -p $HOME/.kube\n  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n  sudo chown $(id -u):$(id -g) $HOME/.kube/config\n\nYou should now deploy a pod network to the cluster.\nRun \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at:\n  https://kubernetes.io/docs/concepts/cluster-administration/addons/\n\nYou can now join any number of machines by running the following on each node\nas root:\n\n  kubeadm join api.k8s.hiko.im:6443 --token a1t7c1.mzltpc72dc3wzj9y --discovery-token-ca-cert-hash sha256:05f44b111174613055975f012fc11fe09bdcd746bd7b3c8d99060c52619f8738\n\n```\n至此，就完成了第一台master的初始化工作。\n\n#### 2.4.3 kube用户配置\n为了让tf-k8s-m1的 kube 用户能通过 kubectl 管理集群，接着我们需要给tf-k8s-m1 的 kube 用户配置管理集群的配置。在tf-k8s-m1机器上创建config.using.cluster.sh脚本，具体如下：\n\n```\n## 创建脚本：config.using.cluster.sh\n\n#!/bin/sh\n\n# 为 kube 用户配置\nmkdir -p $HOME/.kube\nsudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nsudo chown $(id -u):$(id -g) $HOME/.kube/config\n```\n执行config.using.cluster.sh脚本\n\n```\nchmod a+x config.using.cluster.sh\nsh ./config.using.cluster.sh\n```\n验证结果，通过`kubectl`命令查看集群状态，结果如下：\n\n```\n[kube@tf-k8s-m1 ~]$ kubectl cluster-info\nKubernetes master is running at https://api.tf-k8s.xiangwushuo.com:6443\nKubeDNS is running at https://api.tf-k8s.xiangwushuo.com:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n```\n查看集群所有的pods信息，结果如下：\n\n```\n[kube@tf-k8s-m1 ~]$ kubectl get pods --all-namespaces\n\nNAMESPACE     NAME                          READY   STATUS    RESTARTS   AGE\nkube-system   coredns-78d4cf999f-cw79l      0/1     Pending   0          47m\nkube-system   coredns-78d4cf999f-w8j47      0/1     Pending   0          47m\nkube-system   etcd-m01                      1/1     Running   0          47m\nkube-system   kube-apiserver-m01            1/1     Running   0          46m\nkube-system   kube-controller-manager-m01   1/1     Running   0          46m\nkube-system   kube-proxy-5954k              1/1     Running   0          47m\nkube-system   kube-scheduler-m01            1/1     Running   0          47m\n```\n其中，由于未安装相关的网络组件，eg:flannel,所有coredn还是显示为pending，暂时没有影响。\n\n#### 2.4.4 安装CNI插件flannel\n**备注：所有的节点都需要安装**\n具体的安装脚本如下：\n\n```\n## 拉取镜像\nsudo docker pull quay.io/coreos/flannel:v0.11.0-amd64\n## 部署\nkubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml\n```\n安装成功之后，通过 `kubectl get pods --all-namespaces`，看到所有 Pod 都正常了.\n\n### 2.5 安装剩余的master\n#### 2.5.1 同步tf-k8s-m1的ca证书\n首先，将 tf-k8s-m1 中的 ca 证书，scp 到其他 master 机器（tf-k8s-m2 tf-k8s-m3）。\n为了方便，这里也是通过脚本来执行，具体如下：\n注意：需要确认 tf-k8s-m1 上的 root 账号可以免密登录到 tf-k8s-m2 和 tf-k8s-m3 的 root 账号。\n\n```\n## 创建脚本：sync.master.ca.sh\n\n#!/bin/sh\n\nvhost=\"tf-k8s-m2 tf-k8s-m3\"\nusr=root\n\nwho=`whoami`\nif [[ \"$who\" != \"$usr\" ]];then\n  echo \"请使用 root 用户执行或者 sudo ./sync.master.ca.sh\"\n  exit 1\nfi\n\necho $who\n\n# 需要从 m01 拷贝的 ca 文件\ncaFiles=(\n/etc/kubernetes/pki/ca.crt\n/etc/kubernetes/pki/ca.key\n/etc/kubernetes/pki/sa.key\n/etc/kubernetes/pki/sa.pub\n/etc/kubernetes/pki/front-proxy-ca.crt\n/etc/kubernetes/pki/front-proxy-ca.key\n/etc/kubernetes/pki/etcd/ca.crt\n/etc/kubernetes/pki/etcd/ca.key\n/etc/kubernetes/admin.conf\n)\n\npkiDir=/etc/kubernetes/pki/etcd\nfor h in $vhost \ndo\n\n  ssh ${usr}@$h \"mkdir -p $pkiDir\"\n  \n  echo \"Dirs for ca scp created, start to scp...\"\n\n  # scp 文件到目标机\n  for f in ${caFiles[@]}\n  do \n    echo \"scp $f ${usr}@$h:$f\"\n    scp $f ${usr}@$h:$f\n  done\n\n  echo \"Ca files transfered for $h ... ok\"\ndone\n```\n执行脚本，将 tf-k8s-m1 相关的 ca 文件传到tf-k8s-m2 和 tf-k8s-m3：\n\n```\nchmod +x sync.master.ca.sh\n\nsudo ./syncaster.ca.sh\n```\n\n#### 2.5.2 安装master tf-k8s-m2\n总共分为四个步骤，分别是:总1. 共分为四个步骤，分别是:\n* 配置证书、初始化 kubelet 配置和启动 kubelet\n\n```\n[kube@tf-k8s-m2 ~]$ sudo kubeadm init phase certs all --config kubeadm-config.tf-k8s-m2.yaml\n[kube@tf-k8s-m2 ~]$ sudo kubeadm init phase etcd local --config kubeadm-config.tf-k8s-m2.yaml\n[kube@tf-k8s-m2 ~]$ sudo kubeadm init phase kubeconfig kubelet --config kubeadm-config.tf-k8s-m2.yaml\n[kube@tf-k8s-m2 ~]$ sudo kubeadm init phase kubelet-start --config kubeadm-config.tf-k8s-m2.yaml\n```\n* 将etcd加入集群\n\n```\n[kube@tf-k8s-m2 root]$ kubectl exec -n kube-system etcd-tf-k8s-m1 -- etcdctl --ca-file /etc/kubernetes/pki/etcd/ca.crt --cert-file /etc/kubernetes/pki/etcd/peer.crt --key-file /etc/kubernetes/pki/etcd/peer.key --endpoints=https://10.0.0.1:2379 member add tf-k8s-m2 https://10.0.0.2:2380\n```\n\n启动kube-apiserver、kube-controller-manager、kube-scheduler\n\n```\n[kube@tf-k8s-m2 ~]$ sudo kubeadm init phase kubeconfig all --config kubeadm-config.m02.yaml\n[kube@tf-k8s-m2 ~]$ sudo kubeadm init phase control-plane all --config kubeadm-config.m02.yaml\n```\n将节点标记为master节点\n\n```\n[kube@tf-k8s-m2 ~]$ sudo kubeadm init phase mark-control-plane --config kubeadm-config.m02.yaml\n```\n\n#### 2.5.3 安装master tf-k8s-m3\n安装过程和安装master tf-k8s-m2是一样的，区别在于使用的kubeadm配置文件为kubeadm-config.tf-k8s-m3.yaml以及etcd加入成员时指定的实例地址不一样。\n完整的流程如下:\n\n```\n# 1.  配置证书、初始化 kubelet 配置和启动 kubelet\nsudo kubeadm init phase certs all --config kubeadm-config.tf-k8s-m3.yaml\nsudo kubeadm init phase etcd local --config kubeadm-config.tf-k8s-m3.yaml\nsudo kubeadm init phase kubeconfig kubelet --config kubeadm-config.tf-k8s-m3.yaml\nsudo kubeadm init phase kubelet-start --config kubeadm-config.tf-k8s-m3.yaml\n\n# 2. 将 etcd 加入集群\nkubectl exec -n kube-system etcd-tf-k8s-m1 -- etcdctl --ca-file /etc/kubernetes/pki/etcd/ca.crt --cert-file /etc/kubernetes/pki/etcd/peer.crt --key-file /etc/kubernetes/pki/etcd/peer.key --endpoints=https://10.0.0.1:2379 member add tf-k8s-m3 https://10.0.0.3:2380\n\n# 3. 启动 kube-apiserver、kube-controller-manager、kube-scheduler\nsudo kubeadm init phase kubeconfig all --config kubeadm-config.tf-k8s-m3.yaml\nsudo kubeadm init phase control-plane all --config kubeadm-config.tf-k8s-m3.yaml\n\n# 4. 将节点标记为 master 节点\nsudo kubeadm init phase mark-control-plane --config kubeadm-config.tf-k8s-m3.yaml\n```\n#### 2.5.4 验证三个master节点\n至此，三个 master 节点安装完成，通过 kubectl get pods --all-namespaces 查看当前集群所有 Pod。\n\n```\n[kube@tf-k8s-m2 ~]$ kubectl  get pods --all-namespaces\nNAMESPACE     NAME                          READY   STATUS    RESTARTS   AGE\nkube-system   coredns-78d4cf999f-j8zsr      1/1     Running   0          170m\nkube-system   coredns-78d4cf999f-lw5qx      1/1     Running   0          171m\nkube-system   etcd-m01                      1/1     Running   8          5h11m\nkube-system   etcd-m02                      1/1     Running   12         97m\nkube-system   etcd-m03                      1/1     Running   0          91m\nkube-system   kube-apiserver-m01            1/1     Running   9          5h11m\nkube-system   kube-apiserver-m02            1/1     Running   0          95m\nkube-system   kube-apiserver-m03            1/1     Running   0          91m\nkube-system   kube-controller-manager-m01   1/1     Running   4          5h11m\nkube-system   kube-controller-manager-m02   1/1     Running   0          95m\nkube-system   kube-controller-manager-m03   1/1     Running   0          91m\nkube-system   kube-flannel-ds-amd64-7b86z   1/1     Running   0          3h31m\nkube-system   kube-flannel-ds-amd64-98qks   1/1     Running   0          91m\nkube-system   kube-flannel-ds-amd64-ljcdp   1/1     Running   0          97m\nkube-system   kube-proxy-krnjq              1/1     Running   0          5h12m\nkube-system   kube-proxy-scb25              1/1     Running   0          91m\nkube-system   kube-proxy-xp4rj              1/1     Running   0          97m\nkube-system   kube-scheduler-m01            1/1     Running   4          5h11m\nkube-system   kube-scheduler-m02            1/1     Running   0          95m\nkube-system   kube-scheduler-m03            1/1     Running   0          91m\n```\n#### 2.5.5 加入工作节点\n这步很简单，只需要在工作节点 tf-k8s-n1 和 tf-k8s-n2 上执行加入集群的命令即可。\n\n可以使用上面安装 master tf-k8s-m1 成功后打印的命令 kubeadm join api.tf-k8s.xiangwushuo.com:6443 --token a1t7c1.mzltpc72dc3wzj9y --discovery-token-ca-cert-hash sha256:05f44b111174613055975f012fc11fe09bdcd746bd7b3c8d99060c52619f8738，也可以重新生成 Token。\n这里演示如何重新生成 Token 和 证书 hash，在 tf-k8s-m1 上执行以下操作：\n\n```\n# 1. 创建 token\n[kube@tf-k8s-m1 ~]$ kubeadm token create \n\n# 控制台打印如：\ngz1v4w.sulpuxkqtnyci92f\n\n# 2.  查看我们创建的 k8s 集群的证书 hash\n[kube@tf-k8s-m1 ~]$ openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2>/dev/null | openssl dgst -sha256 -hex | sed 's/^.* //'\n\n# 控制台打印如：\nb125cd0c80462353d8fa3e4f5034f1e1a1e3cc9bade32acfb235daa867c60f61\n```\n然后使用`kubeadm join`,分别在工作节点tf-k8s-n1与tf-k8s-n2上执行，将节点加入\n集群，如下：\n\n```\nsudo kubeadm join api.tf-k8s.xiangwushuo.com:6443 --token gz1v4w.sulpuxkqtnyci92f --discovery-token-ca-cert-hash sha256:b125cd0c80462353d8fa3e4f5034f1e1a1e3cc9bade32acfb235daa867c60f61\n```\n\n在 tf-k8s-m1 上通过 kubectl get nodes 查看，将看到节点已被加进来（节点刚加进来时，状态可能会是 NotReady，稍等一会就回变成 Ready）。\n\n### 2.6 部署高可用CoreDNS\n默认安装的 CoreDNS 存在单点问题。在 m01 上通过 kubectl get pods -n kube-system -owide 查看当前集群 CoreDNS Pod 分布（如下）。\n\n从列表中，可以看到 CoreDNS 的两个 Pod 都在 m01 上，存在单点问题。\n\n```\n[kube@tf-k8s-m1 ~]$ kubectl get pods -n kube-system -owide\nNAME                                    READY   STATUS    RESTARTS   AGE     IP            NODE        NOMINATED NODE   READINESS GATES\ncoredns-6c67f849c7-h7lcr                1/1     Running   0          4d3h    10.244.3.2    tf-k8s-m1   <none>           <none>\ncoredns-6c67f849c7-mx9k9                1/1     Running   0          4d3h    10.244.4.2    tf-k8s-m1   <none>           <none>\netcd-tf-k8s-m1                          1/1     Running   1          4d5h    10.0.0.1   tf-k8s-m1   <none>           <none>\netcd-tf-k8s-m2                          1/1     Running   7          4d3h    10.0.0.2   tf-k8s-m2   <none>           <none>\netcd-tf-k8s-m3                          1/1     Running   7          4d3h    10.0.0.3   tf-k8s-m3   <none>           <none>\nkube-apiserver-tf-k8s-m1                1/1     Running   0          4d5h    10.0.0.1   tf-k8s-m1   <none>           <none>\nkube-apiserver-tf-k8s-m2                1/1     Running   0          4d3h    10.0.0.2   tf-k8s-m2   <none>           <none>\nkube-apiserver-tf-k8s-m3                1/1     Running   0          4d3h    10.0.0.3   tf-k8s-m3   <none>           <none>\nkube-controller-manager-tf-k8s-m1       1/1     Running   1          4d5h    10.0.0.1   tf-k8s-m1   <none>           <none>\nkube-controller-manager-tf-k8s-m2       1/1     Running   0          4d3h    10.0.0.2   tf-k8s-m2   <none>           <none>\nkube-controller-manager-tf-k8s-m3       1/1     Running   0          4d3h    10.0.0.3   tf-k8s-m3   <none>           <none>\nkube-flannel-ds-amd64-4v6dd             1/1     Running   1          4d3h    10.0.0.5   tf-k8s-n2   <none>           <none>\nkube-flannel-ds-amd64-g6sg5             1/1     Running   0          4d3h    10.0.0.3   tf-k8s-m3   <none>           <none>\nkube-flannel-ds-amd64-ml4w7             1/1     Running   1          4d3h    10.0.0.4   tf-k8s-n1   <none>           <none>\nkube-flannel-ds-amd64-tb27x             1/1     Running   0          4d3h    10.0.0.2   tf-k8s-m2   <none>           <none>\nkube-flannel-ds-amd64-x5dqj             1/1     Running   0          4d4h    10.0.0.1   tf-k8s-m1   <none>           <none>\nkube-proxy-4wbn7                        1/1     Running   0          4d3h    10.0.0.4   tf-k8s-n1   <none>           <none>\nkube-proxy-8dhtz                        1/1     Running   0          4d3h    10.0.0.2   tf-k8s-m2   <none>           <none>\nkube-proxy-l8727                        1/1     Running   0          4d5h    10.0.0.1   tf-k8s-m1   <none>           <none>\nkube-proxy-tz924                        1/1     Running   0          4d3h    10.0.0.5   tf-k8s-n2   <none>           <none>\nkube-proxy-w7tmn                        1/1     Running   0          4d3h    10.0.0.3   tf-k8s-m3   <none>           <none>\nkube-scheduler-tf-k8s-m1                1/1     Running   1          4d5h    10.0.0.1   tf-k8s-m1   <none>           <none>\nkube-scheduler-tf-k8s-m2                1/1     Running   0          4d3h    10.0.0.2   tf-k8s-m2   <none>           <none>\nkube-scheduler-tf-k8s-m3                1/1     Running   0          4d3h    10.0.0.3   tf-k8s-m3   <none>           <none>\nkubernetes-dashboard-847f8cb7b8-hmf9m   1/1     Running   0          3d23h   10.244.4.4    tf-k8s-n2   <none>           <none>\nmetrics-server-8658466f94-pzl6z         1/1     Running   0          4d2h    10.244.3.3    tf-k8s-n1   <none>           <none>\n```\n首先删除CoreDNS的deploy，然后创建新的CoreDNS-HA.yaml配置文件，如下\n\n```\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    k8s-app: kube-dns\n  name: coredns\n  namespace: kube-system\nspec:\n  #集群规模可自行配置\n  replicas: 2\n  selector:\n    matchLabels:\n      k8s-app: kube-dns\n  strategy:\n    rollingUpdate:\n      maxSurge: 25%\n      maxUnavailable: 1\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        k8s-app: kube-dns\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchExpressions:\n                - key: k8s-app\n                  operator: In\n                  values:\n                  - kube-dns\n              topologyKey: kubernetes.io/hostname\n      containers:\n      - args:\n        - -conf\n        - /etc/coredns/Corefile\n        image: registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:1.2.6\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /health\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 60\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 5\n        name: coredns\n        ports:\n        - containerPort: 53\n          name: dns\n          protocol: UDP\n        - containerPort: 53\n          name: dns-tcp\n          protocol: TCP\n        - containerPort: 9153\n          name: metrics\n          protocol: TCP\n        resources:\n          limits:\n            memory: 170Mi\n          requests:\n            cpu: 100m\n            memory: 70Mi\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            add:\n            - NET_BIND_SERVICE\n            drop:\n            - all\n          readOnlyRootFilesystem: true\n        terminationMessagePath: /dev/termination-log\n        terminationMessagePolicy: File\n        volumeMounts:\n        - mountPath: /etc/coredns\n          name: config-volume\n          readOnly: true\n      dnsPolicy: Default\n      restartPolicy: Always\n      schedulerName: default-scheduler\n      securityContext: {}\n      serviceAccount: coredns\n      serviceAccountName: coredns\n      terminationGracePeriodSeconds: 30\n      tolerations:\n      - key: CriticalAddonsOnly\n        operator: Exists\n      - effect: NoSchedule\n        key: node-role.kubernetes.io/master\n      volumes:\n      - configMap:\n          defaultMode: 420\n          items:\n          - key: Corefile\n            path: Corefile\n          name: coredns\n        name: config-volume\n```\n部署新的CoreDNS \n\n```\nkubectl apply -f CoreDNS-HA.yaml\n```\n\n### 2.7 部署监控组件metrics-server\n\nkubernetesv1.11 以后不再支持通过 heaspter 采集监控数据。使用新的监控数据采集组件metrics-server。 metrics-server 比 heaspter 轻量很多，也不做数据的持久化存储，提供实时的监控数据查询。\n\n先将所有文件下载，保存在一个文件夹 metrics-server 里。\n\n修改 metrics-server-deployment.yaml 两处地方，分别是：apiVersion 和 image，最终修改后的 metrics-server-deployment.yaml 如下：\n\n```\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: metrics-server\n  namespace: kube-system\n---\n# 将extensions/v1beta1修改为apps/v1\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: metrics-server\n  namespace: kube-system\n  labels:\n    k8s-app: metrics-server\nspec:\n  selector:\n    matchLabels:\n      k8s-app: metrics-server\n  template:\n    metadata:\n      name: metrics-server\n      labels:\n        k8s-app: metrics-server\n    spec:\n      serviceAccountName: metrics-server\n      volumes:\n      # mount in tmp so we can safely use from-scratch images and/or read-only containers\n      - name: tmp-dir\n        emptyDir: {}\n      containers:\n      - name: metrics-server\n        image: cloudnil/metrics-server-amd64:v0.3.1\n        command:\n          - /metrics-server\n          - --kubelet-insecure-tls\n          - --kubelet-preferred-address-types=InternalIP\n        imagePullPolicy: Always\n        volumeMounts:\n        - name: tmp-dir\n          mountPath: /tmp\n```\n进入刚创建的 metrics-server，执行 kubectl apply -f .  进行部署（注意 -f 后面有个点）,如下：\n\n```\n[kube@tf-k8s-m1 metrics-server]$ kubectl apply -f .\n\nclusterrole.rbac.authorization.k8s.io/system:aggregated-metrics-reader created\nclusterrolebinding.rbac.authorization.k8s.io/metrics-server:system:auth-delegator created\nrolebinding.rbac.authorization.k8s.io/metrics-server-auth-reader created\napiservice.apiregistration.k8s.io/v1beta1.metrics.k8s.io created\nserviceaccount/metrics-server created\ndeployment.apps/metrics-server created\nservice/metrics-server created\nclusterrole.rbac.authorization.k8s.io/system:metrics-server created\nclusterrolebinding.rbac.authorization.k8s.io/system:metrics-server created\n```\n运行`kubectl get pods -n kube-system`，确定metrics-server的pods是否正常running。\n\n### 2.8 部署Nginx-ingress-controller\nNginx-ingress-controller 是 kubernetes 官方提供的集成了 Ingress-controller 和 Nginx 的一个 docker 镜像。\n\n本次部署中，将 Nginx-ingress 部署到 tf-k8s-m1、tf-k8s-m2、tf-k8s-m3上，监听宿主机的 80 端口。\n\n创建 nginx-ingress.yaml 文件，内容如下：\n\n```\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: ingress-nginx\n---\nkind: ConfigMap\napiVersion: v1\nmetadata:\n  name: nginx-configuration\n  namespace: ingress-nginx\n  labels:\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/part-of: ingress-nginx\n---\nkind: ConfigMap\napiVersion: v1\nmetadata:\n  name: tcp-services\n  namespace: ingress-nginx\n  labels:\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/part-of: ingress-nginx\n---\nkind: ConfigMap\napiVersion: v1\nmetadata:\n  name: udp-services\n  namespace: ingress-nginx\n  labels:\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/part-of: ingress-nginx\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: nginx-ingress-serviceaccount\n  namespace: ingress-nginx\n  labels:\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/part-of: ingress-nginx\n---\napiVersion: rbac.authorization.k8s.io/v1beta1\nkind: ClusterRole\nmetadata:\n  name: nginx-ingress-clusterrole\n  labels:\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/part-of: ingress-nginx\nrules:\n  - apiGroups:\n      - \"\"\n    resources:\n      - configmaps\n      - endpoints\n      - nodes\n      - pods\n      - secrets\n    verbs:\n      - list\n      - watch\n  - apiGroups:\n      - \"\"\n    resources:\n      - nodes\n    verbs:\n      - get\n  - apiGroups:\n      - \"\"\n    resources:\n      - services\n    verbs:\n      - get\n      - list\n      - watch\n  - apiGroups:\n      - \"extensions\"\n    resources:\n      - ingresses\n    verbs:\n      - get\n      - list\n      - watch\n  - apiGroups:\n      - \"\"\n    resources:\n      - events\n    verbs:\n      - create\n      - patch\n  - apiGroups:\n      - \"extensions\"\n    resources:\n      - ingresses/status\n    verbs:\n      - update\n---\napiVersion: rbac.authorization.k8s.io/v1beta1\nkind: Role\nmetadata:\n  name: nginx-ingress-role\n  namespace: ingress-nginx\n  labels:\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/part-of: ingress-nginx\nrules:\n  - apiGroups:\n      - \"\"\n    resources:\n      - configmaps\n      - pods\n      - secrets\n      - namespaces\n    verbs:\n      - get\n  - apiGroups:\n      - \"\"\n    resources:\n      - configmaps\n    resourceNames:\n      - \"ingress-controller-leader-nginx\"\n    verbs:\n      - get\n      - update\n  - apiGroups:\n      - \"\"\n    resources:\n      - configmaps\n    verbs:\n      - create\n  - apiGroups:\n      - \"\"\n    resources:\n      - endpoints\n    verbs:\n      - get\n---\napiVersion: rbac.authorization.k8s.io/v1beta1\nkind: RoleBinding\nmetadata:\n  name: nginx-ingress-role-nisa-binding\n  namespace: ingress-nginx\n  labels:\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/part-of: ingress-nginx\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: Role\n  name: nginx-ingress-role\nsubjects:\n  - kind: ServiceAccount\n    name: nginx-ingress-serviceaccount\n    namespace: ingress-nginx\n---\napiVersion: rbac.authorization.k8s.io/v1beta1\nkind: ClusterRoleBinding\nmetadata:\n  name: nginx-ingress-clusterrole-nisa-binding\n  labels:\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/part-of: ingress-nginx\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: nginx-ingress-clusterrole\nsubjects:\n  - kind: ServiceAccount\n    name: nginx-ingress-serviceaccount\n    namespace: ingress-nginx\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-ingress-controller\n  namespace: ingress-nginx\n  labels:\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/part-of: ingress-nginx\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: ingress-nginx\n      app.kubernetes.io/part-of: ingress-nginx\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: ingress-nginx\n        app.kubernetes.io/part-of: ingress-nginx\n      annotations:\n        prometheus.io/port: \"10254\"\n        prometheus.io/scrape: \"true\"\n    spec:\n      hostNetwork: true\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: kubernetes.io/hostname\n                operator: In\n                # 指定部署到三台 master 上\n                values:\n                - tf-k8s-m1\n                - tf-k8s-m2\n                - tf-k8s-m3\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            - labelSelector:\n                matchExpressions:\n                  - key: app.kubernetes.io/name\n                    operator: In\n                    values: \n                    - ingress-nginx\n              topologyKey: \"kubernetes.io/hostname\"\n      tolerations:\n      - key: node-role.kubernetes.io/master\n        effect: NoSchedule\n      serviceAccountName: nginx-ingress-serviceaccount\n      containers:\n        - name: nginx-ingress-controller\n          image: registry.cn-hangzhou.aliyuncs.com/google_containers/nginx-ingress-controller:0.21.0\n          args:\n            - /nginx-ingress-controller\n            - --configmap=/nginx-configuration\n            - --tcp-services-configmap=/tcp-services\n            - --udp-services-configmap=/udp-services\n            # - --publish-service=/ingress-nginx\n            - --annotations-prefix=nginx.ingress.kubernetes.io\n          securityContext:\n            capabilities:\n              drop:\n                - ALL\n              add:\n                - NET_BIND_SERVICE\n            # www-data -> 33\n            runAsUser: 33\n          env:\n            - name: POD_NAME\n              valueFrom:\n                fieldRef:\n                  fieldPath: metadata.name\n            - name: POD_NAMESPACE\n              valueFrom:\n                fieldRef:\n                  fieldPath: metadata.namespace\n          ports:\n            - name: http\n              containerPort: 80\n            - name: https\n              containerPort: 443\n          livenessProbe:\n            failureThreshold: 3\n            httpGet:\n              path: /healthz\n              port: 10254\n              scheme: HTTP\n            initialDelaySeconds: 10\n            periodSeconds: 10\n            successThreshold: 1\n            timeoutSeconds: 1\n          readinessProbe:\n            failureThreshold: 3\n            httpGet:\n              path: /healthz\n              port: 10254\n              scheme: HTTP\n            periodSeconds: 10\n            successThreshold: 1\n            timeoutSeconds: 1\n          resources:\n            limits:\n              cpu: 1\n              memory: 1024Mi\n            requests:\n              cpu: 0.25\n              memory: 512Mi\n```\n部署 nginx ingress，执行命令 kubectl apply -f nginx-ingress.yaml\n\n### 2.9 部署kubernetes-dashboard\n#### 2.9.1 Dashboard 配置\n新建部署 dashboard 的资源配置文件：kubernetes-dashboard.yaml，内容如下：\n\n```\napiVersion: v1\nkind: Secret\nmetadata:\n  labels:\n    k8s-app: kubernetes-dashboard\n  name: kubernetes-dashboard-certs\n  namespace: kube-system\ntype: Opaque\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  labels:\n    k8s-app: kubernetes-dashboard\n  name: kubernetes-dashboard\n  namespace: kube-system\n---\nkind: Role\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  name: kubernetes-dashboard-minimal\n  namespace: kube-system\nrules:\n  # Allow Dashboard to create 'kubernetes-dashboard-key-holder' secret.\n- apiGroups: [\"\"]\n  resources: [\"secrets\"]\n  verbs: [\"create\"]\n  # Allow Dashboard to create 'kubernetes-dashboard-settings' config map.\n- apiGroups: [\"\"]\n  resources: [\"configmaps\"]\n  verbs: [\"create\"]\n  # Allow Dashboard to get, update and delete Dashboard exclusive secrets.\n- apiGroups: [\"\"]\n  resources: [\"secrets\"]\n  resourceNames: [\"kubernetes-dashboard-key-holder\", \"kubernetes-dashboard-certs\"]\n  verbs: [\"get\", \"update\", \"delete\"]\n  # Allow Dashboard to get and update 'kubernetes-dashboard-settings' config map.\n- apiGroups: [\"\"]\n  resources: [\"configmaps\"]\n  resourceNames: [\"kubernetes-dashboard-settings\"]\n  verbs: [\"get\", \"update\"]\n  # Allow Dashboard to get metrics from heapster.\n- apiGroups: [\"\"]\n  resources: [\"services\"]\n  resourceNames: [\"heapster\"]\n  verbs: [\"proxy\"]\n- apiGroups: [\"\"]\n  resources: [\"services/proxy\"]\n  resourceNames: [\"heapster\", \"http:heapster:\", \"https:heapster:\"]\n  verbs: [\"get\"]\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: kubernetes-dashboard-minimal\n  namespace: kube-system\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: Role\n  name: kubernetes-dashboard-minimal\nsubjects:\n- kind: ServiceAccount\n  name: kubernetes-dashboard\n  namespace: kube-system\n---\nkind: Deployment\napiVersion: apps/v1\nmetadata:\n  labels:\n    k8s-app: kubernetes-dashboard\n  name: kubernetes-dashboard\n  namespace: kube-system\nspec:\n  replicas: 1\n  revisionHistoryLimit: 10\n  selector:\n    matchLabels:\n      k8s-app: kubernetes-dashboard\n  template:\n    metadata:\n      labels:\n        k8s-app: kubernetes-dashboard\n    spec:\n      containers:\n      - name: kubernetes-dashboard\n        # 使用阿里云的镜像\n        image: registry.cn-hangzhou.aliyuncs.com/google_containers/kubernetes-dashboard-amd64:v1.10.0\n        ports:\n        - containerPort: 8443\n          protocol: TCP\n        args:\n          - --auto-generate-certificates\n        volumeMounts:\n        - name: kubernetes-dashboard-certs\n          mountPath: /certs\n          # Create on-disk volume to store exec logs\n        - mountPath: /tmp\n          name: tmp-volume\n        livenessProbe:\n          httpGet:\n            scheme: HTTPS\n            path: /\n            port: 8443\n          initialDelaySeconds: 30\n          timeoutSeconds: 30\n      volumes:\n      - name: kubernetes-dashboard-certs\n        secret:\n          secretName: kubernetes-dashboard-certs\n      - name: tmp-volume\n        emptyDir: {}\n      serviceAccountName: kubernetes-dashboard\n      tolerations:\n      - key: node-role.kubernetes.io/master\n        effect: NoSchedule\n---\nkind: Service\napiVersion: v1\nmetadata:\n  labels:\n    k8s-app: kubernetes-dashboard\n  name: kubernetes-dashboard\n  namespace: kube-system\nspec:\n  ports:\n    - port: 443\n      targetPort: 8443\n  selector:\n    k8s-app: kubernetes-dashboard\n---\n# 配置 ingress 配置，待会部署完 ingress 之后，就可以通过以下配置的域名访问\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: dashboard-ingress\n  namespace: kube-system\n  annotations:\n    # 如果通过 HTTP 访问，跳转到 HTTPS\n    nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\n    nginx.ingress.kubernetes.io/rewrite-target: /\n    # 指定转发协议为 HTTPS，因为 ingress 默认转发协议是 HTTP，而 kubernetes-dashboard 默认是 HTTPS\n    nginx.ingress.kubernetes.io/backend-protocol: \"HTTPS\"\nspec:\n  # 指定使用的 secret (刚刚创建的 secret)\n  tls:\n   - secretName: secret-ca-tf-k8s-xiangwushuo-com\n  rules:\n  # 指定访问 dashboard 的域名\n  - host: dashboard.tf-k8s.xiangwushuo.com\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: kubernetes-dashboard\n          servicePort: 443\n```\n执行部署 kubernetes-dashboard，命令 kubectl apply -f kubernetes-dashboard.yaml.\n\n在本地笔记本电脑上访问dashboard的时候，需要将dashboard.tf-k8s.xiangwushuo.com域名解析到三台master的IP（配置代理），简单地，可以直接在本地/etc/hosts添加\n\n```\n## 172.66.23.13 为tf-k8s-m1的外网IP\n172.66.23.13 dashboard.tf-k8s.xiangwushuo.com\n```\n从浏览器访问: http://dashboard.tf-k8s.xiangwushuo.com\n![](/images/dashboard-login.png)\n\n\n#### 2.9.2 HTTPS 访问 Dashboard\n由于通过 HTTP 访问 dashboard 会无法登录进去 dashboard 的问题，所以这里我们将 dashboard 的服务配置成 HTTPS 进行访问。\n总共三步:\n签证书（或者使用权威的证书机构颁发的证书）\n\n```\nopenssl req -x509 -nodes -days 3650 -newkey rsa:2048 -keyout ./tf-k8s.xiangwushuo.com.key -out ./tf-k8s.xiangwushuo.com.crt -subj \"/CN=*.xiangwushuo.com\"\n```\n\n创建 k8s Secret 资源\n\n```\nkubectl -n kube-system create secret tls secret-ca-tf-k8s-xiangwushuo-com --key ./tf-k8s.xiangwushuo.com.key --cert tf-k8s.xiangwushuo.com.crt \n```\n\n配置 dashboard 的 ingress 为 HTTPS 访问服务,修改 kubernetes-dashboard.yaml，将其中的 Ingress 配置改为支持 HTTPS，具体配置如下：\n\n```\n...省略...\n\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: dashboard-ingress\n  namespace: kube-system\n  annotations:\n    # 如果通过 HTTP 访问，跳转到 HTTPS\n    nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\n    nginx.ingress.kubernetes.io/rewrite-target: /\n    # 指定转发协议为 HTTPS，因为 ingress 默认转发协议是 HTTP，而 kubernetes-dashboard 默认是 HTTPS\n    nginx.ingress.kubernetes.io/backend-protocol: \"HTTPS\"\nspec:\n  # 指定使用的 secret (刚刚创建的 secret)\n  tls:\n   - secretName: secret-ca-k8s-hiko-im\n  rules:\n  # 指定访问 dashboard 的域名\n  - host: dashboard.k8s.hiko.im\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: kubernetes-dashboard\n          servicePort: 443\n\n```\n使用 kubectl apply -f kubernetes-dashboard.yaml 让配置生效。\n\n#### 2.9.3 .3 登录 Dashboard\n登录 dashboard 需要做几个事情（不用担心，一个脚本搞定）:\n\n新建 sa 的账号（也叫 serviceaccount）\n集群角色绑定（将第 1 步新建的账号，绑定到 cluster-admin 这个角色上）\n查看 Token 以及 Token 中的 secrect （secrect 中的 token 字段就是来登录的）\n执行以下脚本，获得登录的 Token:\n\n```\n\n## 创建脚本：create.dashboard.token.sh\n\n#!/bin/sh\n\nkubectl create sa dashboard-admin -n kube-system\nkubectl create clusterrolebinding dashboard-admin --clusterrole=cluster-admin --serviceaccount=kube-system:dashboard-admin\nADMIN_SECRET=$(kubectl get secrets -n kube-system | grep dashboard-admin | awk '{print $1}')\nDASHBOARD_LOGIN_TOKEN=$(kubectl describe secret -n kube-system ${ADMIN_SECRET} | grep -E '^token' | awk '{print $2}')\necho ${DASHBOARD_LOGIN_TOKEN}\n```\n\n复制 Token 去登录就行，Token 样例：\n\n```\n\neyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJkYXNoYm9hcmQtYWRtaW4tdG9rZW4tNWtnZHoiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoiZGFzaGJvYXJkLWFkbWluIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiYWQxNDAyMjQtMDYxNC0xMWU5LTkxMDgtNTI1NDAwODQ4MWQ1Iiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmUtc3lzdGVtOmRhc2hib2FyZC1hZG1pbiJ9.ry4xYI6TFF6J8xXsilu0qhuBeRjSNqVPq3OUzl62Ad3e2wM-biC5pPlKNmJLfJzurxnQrqp59VjmVeTA8BZiF7S6hqlrk8XE9_LFlItUvq3rp5wFuhJuVol8Yoi4UJFzUYQF6baH0O3R10aK33g2WmWLIg79OFAkeMMHrLthbL2pc_p_kG13_qDXlEuVgnIAFsKzxnrCCUfZ2GwGsHEFEqTGBCb0u6x3AZqfQgbN3DALkjjNTyTLP5Ok-LJ3Ug8SZZQBksvTeXCGXZDfk2LDDIvp_DyM7nTL3CTT5cQ3g4aBTFAae47NAkQkmjZg0mxvJH0xVnxrvXLND8FLLkzMxg\n```\n\n## 3. 参考文献\n[1. kubeadm 1.13 安装高可用 kubernetes v1.13.1 集群](https://www.ctolib.com/HikoQiu-kubeadm-install-k8s.html)\n[2. 如何在CentOS 7上修改主机名](https://www.jianshu.com/p/39d7000dfa47)\n[3. Linux之ssh免密登录](https://blog.csdn.net/mmd0308/article/details/73825953)\n[4. sudo与visudo的超细用法说明](http://blog.51cto.com/chenfage/1830424)\n[5. kubeadm HA master(v1.13.0)离线包 + 自动化脚本 + 常用插件 For Centos/Fedora](https://www.kubernetes.org.cn/4948.html)\n[6. github.coreos.flannel](https://github.com/coreos/flannel)\n[7. Kubernetes Handbook——Kubernetes中文指南/云原生应用架构实践手册](https://jimmysong.io/kubernetes-handbook/)\n\n","slug":"kubeadm1-13创建HAkubernetes集群","published":1,"updated":"2019-02-18T09:31:11.000Z","_id":"cjsa3xp5q000o3lxy4v4oz4zc","comments":1,"layout":"post","photos":[],"link":"","content":"<p>[TOC]</p>\n<h2 id=\"一、环境准备\"><a href=\"#一、环境准备\" class=\"headerlink\" title=\"一、环境准备\"></a>一、环境准备</h2><h3 id=\"1-1-硬件设备环境\"><a href=\"#1-1-硬件设备环境\" class=\"headerlink\" title=\"1.1 硬件设备环境\"></a>1.1 硬件设备环境</h3><p>采用5台腾讯云的CVM作为kubernetes的部署环境，具体信息如下：</p>\n<table>\n<thead>\n<tr>\n<th>主机名</th>\n<th>IP</th>\n<th>配置</th>\n<th>备注</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>（Old）VM_0_1_centos；（New）tf-k8s-m1</td>\n<td>10.0.0.1</td>\n<td>4c 8g</td>\n<td>k8s的master，同时也是etcd节点</td>\n</tr>\n<tr>\n<td>（Old）VM_0_2_centos；（New）tf-k8s-m2</td>\n<td>10.0.0.2</td>\n<td>4c 8g</td>\n<td>k8s的master，同时也是etcd节点</td>\n</tr>\n<tr>\n<td>（Old）VM_0_3_centos；（New）tf-k8s-m3</td>\n<td>10.0.0.3</td>\n<td>4c 8g</td>\n<td>k8s的master，同时也是etcd节点</td>\n</tr>\n<tr>\n<td>（Old）VM_0_4_centos；（New）tf-k8s-n1</td>\n<td>10.0.0.4</td>\n<td>4c 8g</td>\n<td>工作节点 node，容器编排最终 pod 工作节点</td>\n</tr>\n<tr>\n<td>（Old）VM_0_5_centos；（New）tf-k8s-n2</td>\n<td>10.0.0.5</td>\n<td>4c 8g</td>\n<td>工作节点 node，容器编排最终 pod 工作节点</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"1-2-软件环境\"><a href=\"#1-2-软件环境\" class=\"headerlink\" title=\"1.2 软件环境\"></a>1.2 软件环境</h3><table>\n<thead>\n<tr>\n<th>环境</th>\n<th>简介</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>操作系统</td>\n<td>CentOS7</td>\n</tr>\n<tr>\n<td>kubeadm</td>\n<td>1.13.3</td>\n</tr>\n<tr>\n<td>kubernetes</td>\n<td>1.13.3</td>\n</tr>\n<tr>\n<td>Docker</td>\n<td>docker-ce 18.06.2</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"1-3-相关系统设置\"><a href=\"#1-3-相关系统设置\" class=\"headerlink\" title=\"1.3 相关系统设置\"></a>1.3 相关系统设置</h3><p>在正式安装之前，需要在每台机器上对以下配置进行修改：</p>\n<ul>\n<li>关闭防火墙，selinux</li>\n<li>关闭系统的swap功能</li>\n<li>关闭Linux swap空间的swappiness</li>\n<li>配置L2网桥在转发包时会被iptables的FORWARD规则所过滤，该配置被CNI插件需要，更多信息请参考<a href=\"https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/#network-plugin-requirements\" target=\"_blank\" rel=\"noopener\">Network Plugin Requirements</a></li>\n<li>升级内核到最新（centos7 默认的内核是3.10.0-862.el7.x86_64 ,可以使用命令‘uname -a’进行查看），原因见<a href=\"https://github.com/Lentil1016/kubeadm-ha/issues/19\" target=\"_blank\" rel=\"noopener\">请问下为什么要用4.18版本内核</a></li>\n<li>开启IPVS</li>\n<li>修改主机名（如果主机名中含有一些特殊字符，则需要调整主机名，不然在后续操作中会出现错误）<br>具体的配置修改执行脚本如下：</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># ---------- 关闭防火墙和selinux -----------</span><br><span class=\"line\">systemctl stop firewalld</span><br><span class=\"line\">systemctl disable firewalld</span><br><span class=\"line\">setenforce 0</span><br><span class=\"line\">sed -i &quot;s/SELINUX=enforcing/SELINUX=disabled/g&quot; /etc/selinux/config</span><br><span class=\"line\"></span><br><span class=\"line\"># ---------- 关闭交换分区 -----------</span><br><span class=\"line\">swapoff -a</span><br><span class=\"line\">yes | cp /etc/fstab /etc/fstab_bak</span><br><span class=\"line\">cat /etc/fstab_bak |grep -v swap &gt; /etc/fstab</span><br><span class=\"line\"></span><br><span class=\"line\"># ---------- 设置网桥包经IPTables，core文件生成路径 -----------</span><br><span class=\"line\">echo &quot;&quot;&quot;</span><br><span class=\"line\">vm.swappiness = 0</span><br><span class=\"line\">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class=\"line\">net.bridge.bridge-nf-call-iptables = 1</span><br><span class=\"line\">&quot;&quot;&quot; &gt; /etc/sysctl.conf</span><br><span class=\"line\">modprobe br_netfilter</span><br><span class=\"line\">sysctl -p</span><br><span class=\"line\"></span><br><span class=\"line\"># ---------- 同步时间 -----------</span><br><span class=\"line\">yum install -y ntpdate</span><br><span class=\"line\">ntpdate -u ntp.api.bz</span><br><span class=\"line\"></span><br><span class=\"line\"># ---------- 升级内核 -----------</span><br><span class=\"line\">rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-2.el7.elrepo.noarch.rpm ;yum --enablerepo=elrepo-kernel install kernel-ml-devel kernel-ml -y</span><br><span class=\"line\"># 查看启动配置里是否有最新的内核</span><br><span class=\"line\">cat /boot/grub2/grub.cfg | grep menuentry</span><br><span class=\"line\"># 修改默认启动项</span><br><span class=\"line\">grub2-set-default 0</span><br><span class=\"line\"># 检查默认内核版本是否大于4.14，否则请调整默认启动参数</span><br><span class=\"line\">grub2-editenv list</span><br><span class=\"line\">#重启以更换内核</span><br><span class=\"line\">reboot</span><br><span class=\"line\">#查看内核信息</span><br><span class=\"line\">uname -a</span><br><span class=\"line\"></span><br><span class=\"line\"># ---------- 确认内核版本后，开启IPVS -----------</span><br><span class=\"line\">uname -a</span><br><span class=\"line\">cat &gt; /etc/sysconfig/modules/ipvs.modules &lt;&lt;EOF</span><br><span class=\"line\">#!/bin/bash</span><br><span class=\"line\">ipvs_modules=&quot;ip_vs ip_vs_lc ip_vs_wlc ip_vs_rr ip_vs_wrr ip_vs_lblc ip_vs_lblcr ip_vs_dh ip_vs_sh ip_vs_fo ip_vs_nq ip_vs_sed ip_vs_ftp nf_conntrack&quot;</span><br><span class=\"line\">for kernel_module in \\$&#123;ipvs_modules&#125;; do</span><br><span class=\"line\"> /sbin/modinfo -F filename \\$&#123;kernel_module&#125; &gt; /dev/null 2&gt;&amp;1</span><br><span class=\"line\"> if [ $? -eq 0 ]; then</span><br><span class=\"line\"> /sbin/modprobe \\$&#123;kernel_module&#125;</span><br><span class=\"line\"> fi</span><br><span class=\"line\">done</span><br><span class=\"line\">EOF</span><br><span class=\"line\">chmod 755 /etc/sysconfig/modules/ipvs.modules &amp;&amp; bash /etc/sysconfig/modules/ipvs.modules &amp;&amp; lsmod | grep ip_vs</span><br><span class=\"line\"></span><br><span class=\"line\"># ---------- 修改主机名 -----------</span><br><span class=\"line\"># 这里以VM_0_17_centos主机为例，其他的主机分别修改成相应的主机名</span><br><span class=\"line\">hostnamectl set-hostname tf-k8s-m1</span><br></pre></td></tr></table></figure>\n<h3 id=\"1-3-配置集群内各个机器之间的免密码登录\"><a href=\"#1-3-配置集群内各个机器之间的免密码登录\" class=\"headerlink\" title=\"1.3 配置集群内各个机器之间的免密码登录\"></a>1.3 配置集群内各个机器之间的免密码登录</h3><h4 id=\"1-3-1-配置hosts\"><a href=\"#1-3-1-配置hosts\" class=\"headerlink\" title=\"1.3.1 配置hosts\"></a>1.3.1 配置hosts</h4><p>为了便于后续的操作，我们需要给每一台设备配置下hosts域名信息，具体如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># vi /etc/hosts</span><br><span class=\"line\">10.0.0.1 tf-k8s-m1 api.tf-k8s.xiangwushuo.com</span><br><span class=\"line\">10.0.0.2 tf-k8s-m2</span><br><span class=\"line\">10.0.0.3 tf-k8s-m3</span><br><span class=\"line\">10.0.0.4 tf-k8s-n1</span><br><span class=\"line\">10.0.0.5 tf-k8s-n2</span><br><span class=\"line\">10.0.0.1 dashboard.tf-k8s.xiangwushuo.com</span><br></pre></td></tr></table></figure>\n<h4 id=\"1-3-2-新建用户\"><a href=\"#1-3-2-新建用户\" class=\"headerlink\" title=\"1.3.2 新建用户\"></a>1.3.2 新建用户</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># useradd kube</span><br><span class=\"line\"># visudo</span><br><span class=\"line\">%wheel  ALL=(ALL)       ALL</span><br><span class=\"line\">kube    ALL=(ALL)       NOPASSWD:ALL</span><br></pre></td></tr></table></figure>\n<p>备注：visudo命令是用来给kube用户添加sudo密码</p>\n<h4 id=\"1-3-3-设置免密登录\"><a href=\"#1-3-3-设置免密登录\" class=\"headerlink\" title=\"1.3.3 设置免密登录\"></a>1.3.3 设置免密登录</h4><ol>\n<li>各个设备的root用户&amp;kube用户（不同用户配置不同的）都生成各自的免密登录的ssh的私钥与公钥</li>\n</ol>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">## 为root用户生成ssh的私钥与公钥</span><br><span class=\"line\">ssh-keygen</span><br></pre></td></tr></table></figure>\n<p>在/root目录下，会生成一个.ssh目录，.ssh目录下会生成以下三个文件：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">-rw------- 1 root root 2398 Feb 13 15:18 authorized_keys</span><br><span class=\"line\">-rw------- 1 root root 1679 Feb 13 14:47 id_rsa</span><br><span class=\"line\">-rw-r--r-- 1 root root  401 Feb 13 14:47 id_rsa.pub</span><br></pre></td></tr></table></figure>\n<p>authorized_keys文件存储了本设备认证授权的其他设备的公钥信息；id_rsa存储了本设备的私钥信息；id_rsa.pub存储了本设备的公钥信息。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">## 为kube用户生成ssh的私钥与公钥</span><br><span class=\"line\">su kube</span><br><span class=\"line\">ssh-keygen</span><br></pre></td></tr></table></figure>\n<p>在/home/kube目录下，会生成一个.ssh目录，并包含相关文件。</p>\n<ol start=\"2\">\n<li>各个设备上都创建好各自的ssh免密登录公钥与私钥后，需要将各自的公钥copy至其他的设备上，并将公钥信息添加到各个设备的authorized_keys文件中。<br>备注：也需要将各个节点自己的公钥copy至自己的authorized_keys文件中，这样自己才可以ssh自己。</li>\n</ol>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">## 将每一台节点上的公钥都同步到相应的目录下</span><br><span class=\"line\"># ll</span><br><span class=\"line\">-rw-r--r-- 1 root root  401 Feb 13 15:15 tf-k8s-m1-id_rsa.pub</span><br><span class=\"line\">-rw-r--r-- 1 root root  401 Feb 13 15:15 tf-k8s-m2-id_rsa.pub</span><br><span class=\"line\">-rw-r--r-- 1 root root  401 Feb 13 15:15 tf-k8s-m3-id_rsa.pub</span><br><span class=\"line\">-rw-r--r-- 1 root root  401 Feb 13 15:15 tf-k8s-n1-id_rsa.pub</span><br><span class=\"line\">-rw-r--r-- 1 root root  401 Feb 13 15:15 tf-k8s-n2-id_rsa.pub</span><br><span class=\"line\">## 将每台节点的公钥追加至authorized_keys文件中</span><br><span class=\"line\">cat tf-k8s-m1-id_rsa.pub &gt; authorized_keys</span><br><span class=\"line\">cat tf-k8s-m2-id_rsa.pub &gt; authorized_keys</span><br><span class=\"line\">cat tf-k8s-m3-id_rsa.pub &gt; authorized_keys</span><br><span class=\"line\">cat tf-k8s-n1-id_rsa.pub &gt; authorized_keys</span><br><span class=\"line\">cat tf-k8s-n2-id_rsa.pub &gt; authorized_keys</span><br></pre></td></tr></table></figure>\n<p>测试是否能够正常使用ssh免密登录</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ssh root@tf-k8s-m1</span><br><span class=\"line\">ssh root@tf-k8s-m2</span><br><span class=\"line\">ssh root@tf-k8s-m3</span><br><span class=\"line\">ssh root@tf-k8s-n1</span><br><span class=\"line\">ssh root@tf-k8s-n2</span><br></pre></td></tr></table></figure>\n<p><strong>提示</strong>：如果其他机器上的 root 下的 /root/.ssh/authorized_keys 不存在，可以手动创建。要注意的是：authorized_keys 的权限需要是 600。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">## 如果 authorized_keys 的权限不是 600，执行修改权限的命令。</span><br><span class=\"line\">chmod 600 authorized_keys</span><br></pre></td></tr></table></figure>\n<h2 id=\"二、安装步骤\"><a href=\"#二、安装步骤\" class=\"headerlink\" title=\"二、安装步骤\"></a>二、安装步骤</h2><p>以下操作，可以都切换至kube用户下进行操作。</p>\n<h3 id=\"2-1-安装docker\"><a href=\"#2-1-安装docker\" class=\"headerlink\" title=\"2.1 安装docker\"></a>2.1 安装docker</h3><p>由于kubeadm的ha模式对docker的版本是有一定的要求的，因此，本教程中安装官方推荐的docker版本。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 安装依赖包</span><br><span class=\"line\">yum install -y yum-utils device-mapper-persistent-data lvm2</span><br><span class=\"line\"></span><br><span class=\"line\"># 添加Docker软件包源</span><br><span class=\"line\">yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo</span><br><span class=\"line\"></span><br><span class=\"line\">#关闭测试版本list（只显示稳定版）</span><br><span class=\"line\">sudo yum-config-manager --enable docker-ce-edge</span><br><span class=\"line\">sudo yum-config-manager --enable docker-ce-test</span><br><span class=\"line\"></span><br><span class=\"line\"># 更新yum包索引</span><br><span class=\"line\">yum makecache fast</span><br><span class=\"line\"></span><br><span class=\"line\">#NO.1 指定版本安装</span><br><span class=\"line\">yum list docker-ce --showduplicates|sort -r  </span><br><span class=\"line\">yum install docker-ce-18.06.2.ce -y</span><br></pre></td></tr></table></figure>\n<p>为了方便操作，我们在tf-k8s-m1节点上，创建一个批量部署docker的脚本。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">## 创建install.docker.sh</span><br><span class=\"line\"></span><br><span class=\"line\">#!/bin/sh</span><br><span class=\"line\"></span><br><span class=\"line\">vhosts=&quot;tf-k8s-m1 tf-k8s-m2 tf-k8s-m3 tf-k8s-n1 tf-k8s-n2&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">for h in $vhosts</span><br><span class=\"line\">do</span><br><span class=\"line\">    echo &quot;Install docker for $h&quot;</span><br><span class=\"line\">    ssh kube@$h &quot;sudo yum install docker-ce-18.06.2.ce -y &amp;&amp; sudo systemctl enable docker &amp;&amp; systemctl start docker&quot;</span><br><span class=\"line\">done</span><br></pre></td></tr></table></figure>\n<p>执行install.docker.sh脚本</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">chmod a+x install.docker.sh</span><br><span class=\"line\">sh ./install.docker.sh</span><br></pre></td></tr></table></figure>\n<h3 id=\"2-2-安装kubernetes-yum源和kubelet、kubeadm、kubectl组件\"><a href=\"#2-2-安装kubernetes-yum源和kubelet、kubeadm、kubectl组件\" class=\"headerlink\" title=\"2.2 安装kubernetes yum源和kubelet、kubeadm、kubectl组件\"></a>2.2 安装kubernetes yum源和kubelet、kubeadm、kubectl组件</h3><h4 id=\"2-2-1-所有机器上配置-kubernetes-repo-yum-源\"><a href=\"#2-2-1-所有机器上配置-kubernetes-repo-yum-源\" class=\"headerlink\" title=\"2.2.1 所有机器上配置 kubernetes.repo yum 源\"></a>2.2.1 所有机器上配置 kubernetes.repo yum 源</h4><p>详细的安装脚本如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">## 创建脚本：install.k8s.repo.sh</span><br><span class=\"line\"></span><br><span class=\"line\">#!/bin/sh</span><br><span class=\"line\"></span><br><span class=\"line\">vhost=&quot;tf-k8s-m1 tf-k8s-m2 tf-k8s-m3 tf-k8s-n1 tf-k8s-n2&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">## 设置为阿里云 kubernetes 仓库</span><br><span class=\"line\">cat &lt;&lt;EOF &gt; kubernetes.repo</span><br><span class=\"line\">[kubernetes]</span><br><span class=\"line\">name=Kubernetes</span><br><span class=\"line\">baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/</span><br><span class=\"line\">enabled=1</span><br><span class=\"line\">gpgcheck=1</span><br><span class=\"line\">repo_gpgcheck=1</span><br><span class=\"line\">gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg</span><br><span class=\"line\">EOF</span><br><span class=\"line\"></span><br><span class=\"line\">mvCmd=&quot;sudo cp ~/kubernetes.repo /etc/yum.repos.d/&quot;</span><br><span class=\"line\">for h in $vhost</span><br><span class=\"line\">do</span><br><span class=\"line\">  echo &quot;Setup kubernetes repository for $h&quot;</span><br><span class=\"line\">  scp ./kubernetes.repo kube@$h:~</span><br><span class=\"line\">  ssh kube@$h $mvCmd</span><br><span class=\"line\">done</span><br></pre></td></tr></table></figure>\n<p>执行install.k8s.repo.sh脚本</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">chmod a+x install.k8s.repo.sh</span><br><span class=\"line\">sh ./install.k8s.repo.sh</span><br></pre></td></tr></table></figure>\n<h4 id=\"2-2-2-所有机器上安装-kubelet、kubeadm、kubectl组件\"><a href=\"#2-2-2-所有机器上安装-kubelet、kubeadm、kubectl组件\" class=\"headerlink\" title=\"2.2.2 所有机器上安装 kubelet、kubeadm、kubectl组件\"></a>2.2.2 所有机器上安装 kubelet、kubeadm、kubectl组件</h4><p>详细安装脚本如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">## 创建脚本：install.k8s.basic.sh</span><br><span class=\"line\"></span><br><span class=\"line\">#!/bin/sh</span><br><span class=\"line\"></span><br><span class=\"line\">vhost=&quot;tf-k8s-m1 tf-k8s-m2 tf-k8s-m3 tf-k8s-n1 tf-k8s-n2&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">## 安装 kubelet kubeadm kubectl</span><br><span class=\"line\">installCmd=&quot;sudo yum install -y kubelet kubeadm kubectl &amp;&amp; sudo systemctl enable kubelet&quot;</span><br><span class=\"line\">for h in $vhost</span><br><span class=\"line\">do</span><br><span class=\"line\">  echo &quot;Install kubelet kubeadm kubectl for : $h&quot;</span><br><span class=\"line\">  ssh kube@$h $installCmd</span><br><span class=\"line\">done</span><br></pre></td></tr></table></figure>\n<p>执行install.k8s.baisc.sh脚本</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">chmod a+x install.k8s.basic.sh</span><br><span class=\"line\">sh ./install.k8s.basic.sh</span><br></pre></td></tr></table></figure>\n<h3 id=\"2-3-初始化kubeadm配置文件\"><a href=\"#2-3-初始化kubeadm配置文件\" class=\"headerlink\" title=\"2.3 初始化kubeadm配置文件\"></a>2.3 初始化kubeadm配置文件</h3><p>创建三台master机器tf-k8s-m1,tf-k8s-m2,tf-k8s-m3的kubeadm配置文件，其中主要是配置生成证书的域配置、etcd集群配置。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">## 创建脚本：init.kubeadm.config.sh</span><br><span class=\"line\"></span><br><span class=\"line\">#!/bin/sh</span><br><span class=\"line\"></span><br><span class=\"line\">## 1. 配置参数 </span><br><span class=\"line\">## vhost 主机名和 vhostIP IP 一一对应</span><br><span class=\"line\">vhost=(tf-k8s-m1 tf-k8s-m2 tf-k8s-m3)</span><br><span class=\"line\">vhostIP=(10.0.0.1 10.0.0.2 10.0.0.3)</span><br><span class=\"line\"></span><br><span class=\"line\">domain=api.tf-k8s.xiangwushuo.com</span><br><span class=\"line\"></span><br><span class=\"line\">## etcd 初始化 m01 m02 m03 集群配置</span><br><span class=\"line\">etcdInitCluster=(</span><br><span class=\"line\">tf-k8s-m1=https://10.0.0.1:2380</span><br><span class=\"line\">tf-k8s-m1=https://10.0.0.1:2380,tf-k8s-m2=https://10.0.0.2:2380</span><br><span class=\"line\">tf-k8s-m1=https://10.0.0.1:2380,tf-k8s-m2=https://10.0.0.2:2380,tf-k8s-m3=https://10.0.0.3:2380</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">## etcd 初始化时，m01 m02 m03 分别的初始化集群状态</span><br><span class=\"line\">initClusterStatus=(</span><br><span class=\"line\">new</span><br><span class=\"line\">existing</span><br><span class=\"line\">existing</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">## 2.遍历 master 主机名和对应 IP</span><br><span class=\"line\">## 生成对应的 kubeadmn 配置文件 </span><br><span class=\"line\">for i in `seq 0 $(($&#123;#vhost[*]&#125;-1))`</span><br><span class=\"line\">do</span><br><span class=\"line\"></span><br><span class=\"line\">h=$&#123;vhost[$&#123;i&#125;]&#125; </span><br><span class=\"line\">ip=$&#123;vhostIP[$&#123;i&#125;]&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">echo &quot;--&gt; $h - $ip&quot;</span><br><span class=\"line\">  </span><br><span class=\"line\">## 生成 kubeadm 配置模板</span><br><span class=\"line\">cat &lt;&lt;EOF &gt; kubeadm-config.$h.yaml</span><br><span class=\"line\">apiVersion: kubeadm.k8s.io/v1beta1</span><br><span class=\"line\">kind: InitConfiguration</span><br><span class=\"line\">localAPIEndpoint:</span><br><span class=\"line\">  advertiseAddress: $ip</span><br><span class=\"line\">  bindPort: 6443</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: kubeadm.k8s.io/v1beta1</span><br><span class=\"line\">kind: ClusterConfiguration</span><br><span class=\"line\">kubernetesVersion: v1.13.3</span><br><span class=\"line\"></span><br><span class=\"line\"># 指定阿里云镜像仓库</span><br><span class=\"line\">imageRepository: registry.aliyuncs.com/google_containers</span><br><span class=\"line\"></span><br><span class=\"line\"># apiServerCertSANs 填所有的 masterip、lbip、其它可能需要通过它访问 apiserver 的地址、域名或主机名等，</span><br><span class=\"line\"># 如阿里fip，证书中会允许这些ip</span><br><span class=\"line\"># 这里填一个自定义的域名</span><br><span class=\"line\">apiServer:</span><br><span class=\"line\">  certSANs:</span><br><span class=\"line\">  - &quot;$domain&quot;</span><br><span class=\"line\">controlPlaneEndpoint: &quot;$domain:6443&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">## Etcd 配置</span><br><span class=\"line\">etcd:</span><br><span class=\"line\">  local:</span><br><span class=\"line\">    extraArgs:</span><br><span class=\"line\">      listen-client-urls: &quot;https://127.0.0.1:2379,https://$ip:2379&quot;</span><br><span class=\"line\">      advertise-client-urls: &quot;https://$ip:2379&quot;</span><br><span class=\"line\">      listen-peer-urls: &quot;https://$ip:2380&quot;</span><br><span class=\"line\">      initial-advertise-peer-urls: &quot;https://$ip:2380&quot;</span><br><span class=\"line\">      initial-cluster: &quot;$&#123;etcdInitCluster[$&#123;i&#125;]&#125;&quot;</span><br><span class=\"line\">      initial-cluster-state: $&#123;initClusterStatus[$&#123;i&#125;]&#125;</span><br><span class=\"line\">    serverCertSANs:</span><br><span class=\"line\">      - $h</span><br><span class=\"line\">      - $ip</span><br><span class=\"line\">    peerCertSANs:</span><br><span class=\"line\">      - $h</span><br><span class=\"line\">      - $ip</span><br><span class=\"line\">networking:</span><br><span class=\"line\">  podSubnet: &quot;10.244.0.0/16&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">EOF</span><br><span class=\"line\"></span><br><span class=\"line\">echo &quot;kubeadm-config.$h.yaml created ... ok&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">## 3. 分发到其他 master 机器 </span><br><span class=\"line\">scp kubeadm-config.$h.yaml kube@$h:~</span><br><span class=\"line\">echo &quot;scp kubeadm-config.$h.yaml ... ok&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">done</span><br></pre></td></tr></table></figure>\n<p>执行init.kubeadm.config.sh脚本</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">chmod a+x init.kubeadm.config.sh</span><br><span class=\"line\">sh ./init.kubeadm.config.sh</span><br></pre></td></tr></table></figure>\n<p>执行成功之后，可以在tf-k8s-m1, tf-k8s-m2, tf-k8s-m3的 kube 用户的 home 目录（/home/kube）能看到对应的 kubeadm-config.tf-k8s-m1*.yaml 配置文件。 这个配置文件主要是用于后续初始化集群其他 master 的证书、 etcd 配置、kubelet 配置、kube-apiserver配置、kube-controller-manager 配置等。<br>各个master节点上对应的kubeadm配置文件：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cvm tf-k8s-m1：kubeadm-config.tf-k8s-m1.yaml</span><br><span class=\"line\">cvm tf-k8s-m2：kubeadm-config.tf-k8s-m2.yaml</span><br><span class=\"line\">cvm tf-k8s-m3：kubeadm-config.tf-k8s-m3.yaml</span><br></pre></td></tr></table></figure>\n<h3 id=\"2-4-安装master镜像和执行kubeadm初始化\"><a href=\"#2-4-安装master镜像和执行kubeadm初始化\" class=\"headerlink\" title=\"2.4 安装master镜像和执行kubeadm初始化\"></a>2.4 安装master镜像和执行kubeadm初始化</h3><h4 id=\"2-4-1-拉取镜像到本地\"><a href=\"#2-4-1-拉取镜像到本地\" class=\"headerlink\" title=\"2.4.1 拉取镜像到本地\"></a>2.4.1 拉取镜像到本地</h4><p>因为 k8s.gcr.io 国内无法访问，我们可以选择通过阿里云的镜像仓库（kubeadm-config.tf-k8s-m1*.yaml 配置文件中已经指定使用阿里云镜像仓库  registry.aliyuncs.com/google_containers），将所需的镜像 pull 到本地。<br>我们可以通过以下命令，来查看是否已经成功指定了阿里云的镜像仓库,在tf-k8s-m1机器上，通过<code>kubeadm config images list</code>命令来查看，结果如下:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[kube@tf-k8s-m1 ~]$ kubeadm config images list --config kubeadm-config.tf-k8s-m1.yaml</span><br><span class=\"line\">registry.aliyuncs.com/google_containers/kube-apiserver:v1.13.3</span><br><span class=\"line\">registry.aliyuncs.com/google_containers/kube-controller-manager:v1.13.3</span><br><span class=\"line\">registry.aliyuncs.com/google_containers/kube-scheduler:v1.13.3</span><br><span class=\"line\">registry.aliyuncs.com/google_containers/kube-proxy:v1.13.3</span><br><span class=\"line\">registry.aliyuncs.com/google_containers/pause:3.1</span><br><span class=\"line\">registry.aliyuncs.com/google_containers/etcd:3.2.24</span><br><span class=\"line\">registry.aliyuncs.com/google_containers/coredns:1.2.6</span><br></pre></td></tr></table></figure>\n<p>接下来，分别在tf-k8s-m1、tf-k8s-m2、tf-k8s-m3机器上，拉取相关镜像</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[kube@tf-k8s-m1 ~]$ sudo kubeadm config images pull --config kubeadm-config.tf-k8s-m1.yaml</span><br><span class=\"line\">[kube@tf-k8s-m2 ~]$ sudo kubeadm config images pull --config kubeadm-config.tf-k8s-m2.yaml</span><br><span class=\"line\">[kube@tf-k8s-m3 ~]$ sudo kubeadm config images pull --config kubeadm-config.tf-k8s-m3.yaml</span><br></pre></td></tr></table></figure>\n<p>执行成功后，应该能够看到本地已经拉取的镜像</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[kube@tf-k8s-m1 ~]$ sudo docker images</span><br><span class=\"line\">REPOSITORY                                                                     TAG                 IMAGE ID            CREATED             SIZE</span><br><span class=\"line\">registry.aliyuncs.com/google_containers/kube-apiserver                         v1.13.3             fe242e556a99        2 weeks ago         181MB</span><br><span class=\"line\">registry.aliyuncs.com/google_containers/kube-proxy                             v1.13.3             98db19758ad4        2 weeks ago         80.3MB</span><br><span class=\"line\">registry.aliyuncs.com/google_containers/kube-controller-manager                v1.13.3             0482f6400933        2 weeks ago         146MB</span><br><span class=\"line\">registry.aliyuncs.com/google_containers/kube-scheduler                         v1.13.3             3a6f709e97a0        2 weeks ago         79.6MB</span><br><span class=\"line\">quay.io/coreos/flannel                                                         v0.11.0-amd64       ff281650a721        2 weeks ago         52.6MB</span><br><span class=\"line\">registry.cn-hangzhou.aliyuncs.com/google_containers/nginx-ingress-controller   0.21.0              01bd760f276c        2 months ago        568MB</span><br><span class=\"line\">registry.aliyuncs.com/google_containers/coredns                                1.2.6               f59dcacceff4        3 months ago        40MB</span><br><span class=\"line\">registry.aliyuncs.com/google_containers/etcd                                   3.2.24              3cab8e1b9802        5 months ago        220MB</span><br><span class=\"line\">registry.aliyuncs.com/google_containers/pause                                  3.1                 da86e6ba6ca1        14 months ago       742kB</span><br></pre></td></tr></table></figure>\n<h4 id=\"2-4-2-安装master-tf-k8s-m1\"><a href=\"#2-4-2-安装master-tf-k8s-m1\" class=\"headerlink\" title=\"2.4.2 安装master tf-k8s-m1\"></a>2.4.2 安装master tf-k8s-m1</h4><p>我们目标是要搭建一个高可用的 master 集群，所以需要在三台 master tf-k8s-m1 tf-k8s-m2 tf-k8s-m3机器上分别通过 kubeadm 进行初始化。<br>由于 tf-k8s-m2 和 tf-k8s-m3 的初始化需要依赖 tf-k8s-m1 初始化成功后所生成的证书文件，所以这里需要先在 m01 初始化。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[kube@tf-k8s-m1 ~]$  sudo kubeadm init --config kubeadm-config.tf-k8s-m1.yaml</span><br></pre></td></tr></table></figure>\n<p>初始化成功后，会看到如下日志：<br><strong>备注：如果初始化失败，则可以通过<code>kubeadm reset --force</code>命令重置之前kubeadm init命令的执行结果，恢复一个干净的环境</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[init] Using Kubernetes version: v1.13.3</span><br><span class=\"line\">[preflight] Running pre-flight checks</span><br><span class=\"line\">[preflight] Pulling images required for setting up a Kubernetes cluster</span><br><span class=\"line\">[preflight] This might take a minute or two, depending on the speed of your internet connection</span><br><span class=\"line\">[preflight] You can also perform this action in beforehand using &apos;kubeadm config images pull&apos;</span><br><span class=\"line\">[kubelet-start] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;</span><br><span class=\"line\">[kubelet-start] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;</span><br><span class=\"line\">[kubelet-start] Activating the kubelet service</span><br><span class=\"line\">[certs] Using certificateDir folder &quot;/etc/kubernetes/pki&quot;</span><br><span class=\"line\">[certs] Generating &quot;ca&quot; certificate and key</span><br><span class=\"line\">[certs] Generating &quot;apiserver&quot; certificate and key</span><br><span class=\"line\">[certs] apiserver serving cert is signed for DNS names [m01 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local api.k8s.hiko.im api.k8s.hiko.im] and IPs [10.96.0.1 10.0.2.15]</span><br><span class=\"line\">[certs] Generating &quot;apiserver-kubelet-client&quot; certificate and key</span><br><span class=\"line\">[certs] Generating &quot;front-proxy-ca&quot; certificate and key</span><br><span class=\"line\">[certs] Generating &quot;front-proxy-client&quot; certificate and key</span><br><span class=\"line\">[certs] Generating &quot;etcd/ca&quot; certificate and key</span><br><span class=\"line\">[certs] Generating &quot;etcd/server&quot; certificate and key</span><br><span class=\"line\">[certs] etcd/server serving cert is signed for DNS names [m01 localhost m01] and IPs [10.0.2.15 127.0.0.1 ::1 192.168.33.10]</span><br><span class=\"line\">[certs] Generating &quot;etcd/peer&quot; certificate and key</span><br><span class=\"line\">[certs] etcd/peer serving cert is signed for DNS names [m01 localhost m01] and IPs [10.0.2.15 127.0.0.1 ::1 192.168.33.10]</span><br><span class=\"line\">[certs] Generating &quot;etcd/healthcheck-client&quot; certificate and key</span><br><span class=\"line\">[certs] Generating &quot;apiserver-etcd-client&quot; certificate and key</span><br><span class=\"line\">[certs] Generating &quot;sa&quot; key and public key</span><br><span class=\"line\">[kubeconfig] Using kubeconfig folder &quot;/etc/kubernetes&quot;</span><br><span class=\"line\">[kubeconfig] Writing &quot;admin.conf&quot; kubeconfig file</span><br><span class=\"line\">[kubeconfig] Writing &quot;kubelet.conf&quot; kubeconfig file</span><br><span class=\"line\">[kubeconfig] Writing &quot;controller-manager.conf&quot; kubeconfig file</span><br><span class=\"line\">[kubeconfig] Writing &quot;scheduler.conf&quot; kubeconfig file</span><br><span class=\"line\">[control-plane] Using manifest folder &quot;/etc/kubernetes/manifests&quot;</span><br><span class=\"line\">[control-plane] Creating static Pod manifest for &quot;kube-apiserver&quot;</span><br><span class=\"line\">[control-plane] Creating static Pod manifest for &quot;kube-controller-manager&quot;</span><br><span class=\"line\">[control-plane] Creating static Pod manifest for &quot;kube-scheduler&quot;</span><br><span class=\"line\">[etcd] Creating static Pod manifest for local etcd in &quot;/etc/kubernetes/manifests&quot;</span><br><span class=\"line\">[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory &quot;/etc/kubernetes/manifests&quot;. This can take up to 4m0s</span><br><span class=\"line\">[apiclient] All control plane components are healthy after 19.009523 seconds</span><br><span class=\"line\">[uploadconfig] storing the configuration used in ConfigMap &quot;kubeadm-config&quot; in the &quot;kube-system&quot; Namespace</span><br><span class=\"line\">[kubelet] Creating a ConfigMap &quot;kubelet-config-1.13&quot; in namespace kube-system with the configuration for the kubelets in the cluster</span><br><span class=\"line\">[patchnode] Uploading the CRI Socket information &quot;/var/run/dockershim.sock&quot; to the Node API object &quot;m01&quot; as an annotation</span><br><span class=\"line\">[mark-control-plane] Marking the node m01 as control-plane by adding the label &quot;node-role.kubernetes.io/master=&apos;&apos;&quot;</span><br><span class=\"line\">[mark-control-plane] Marking the node m01 as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]</span><br><span class=\"line\">[bootstrap-token] Using token: a1t7c1.mzltpc72dc3wzj9y</span><br><span class=\"line\">[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles</span><br><span class=\"line\">[bootstraptoken] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials</span><br><span class=\"line\">[bootstraptoken] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token</span><br><span class=\"line\">[bootstraptoken] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster</span><br><span class=\"line\">[bootstraptoken] creating the &quot;cluster-info&quot; ConfigMap in the &quot;kube-public&quot; namespace</span><br><span class=\"line\">[addons] Applied essential addon: CoreDNS</span><br><span class=\"line\">[addons] Applied essential addon: kube-proxy</span><br><span class=\"line\"></span><br><span class=\"line\">Your Kubernetes master has initialized successfully!</span><br><span class=\"line\"></span><br><span class=\"line\">To start using your cluster, you need to run the following as a regular user:</span><br><span class=\"line\"></span><br><span class=\"line\">  mkdir -p $HOME/.kube</span><br><span class=\"line\">  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class=\"line\">  sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class=\"line\"></span><br><span class=\"line\">You should now deploy a pod network to the cluster.</span><br><span class=\"line\">Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:</span><br><span class=\"line\">  https://kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><span class=\"line\"></span><br><span class=\"line\">You can now join any number of machines by running the following on each node</span><br><span class=\"line\">as root:</span><br><span class=\"line\"></span><br><span class=\"line\">  kubeadm join api.k8s.hiko.im:6443 --token a1t7c1.mzltpc72dc3wzj9y --discovery-token-ca-cert-hash sha256:05f44b111174613055975f012fc11fe09bdcd746bd7b3c8d99060c52619f8738</span><br></pre></td></tr></table></figure>\n<p>至此，就完成了第一台master的初始化工作。</p>\n<h4 id=\"2-4-3-kube用户配置\"><a href=\"#2-4-3-kube用户配置\" class=\"headerlink\" title=\"2.4.3 kube用户配置\"></a>2.4.3 kube用户配置</h4><p>为了让tf-k8s-m1的 kube 用户能通过 kubectl 管理集群，接着我们需要给tf-k8s-m1 的 kube 用户配置管理集群的配置。在tf-k8s-m1机器上创建config.using.cluster.sh脚本，具体如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">## 创建脚本：config.using.cluster.sh</span><br><span class=\"line\"></span><br><span class=\"line\">#!/bin/sh</span><br><span class=\"line\"></span><br><span class=\"line\"># 为 kube 用户配置</span><br><span class=\"line\">mkdir -p $HOME/.kube</span><br><span class=\"line\">sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class=\"line\">sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br></pre></td></tr></table></figure>\n<p>执行config.using.cluster.sh脚本</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">chmod a+x config.using.cluster.sh</span><br><span class=\"line\">sh ./config.using.cluster.sh</span><br></pre></td></tr></table></figure>\n<p>验证结果，通过<code>kubectl</code>命令查看集群状态，结果如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[kube@tf-k8s-m1 ~]$ kubectl cluster-info</span><br><span class=\"line\">Kubernetes master is running at https://api.tf-k8s.xiangwushuo.com:6443</span><br><span class=\"line\">KubeDNS is running at https://api.tf-k8s.xiangwushuo.com:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy</span><br><span class=\"line\"></span><br><span class=\"line\">To further debug and diagnose cluster problems, use &apos;kubectl cluster-info dump&apos;.</span><br></pre></td></tr></table></figure>\n<p>查看集群所有的pods信息，结果如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[kube@tf-k8s-m1 ~]$ kubectl get pods --all-namespaces</span><br><span class=\"line\"></span><br><span class=\"line\">NAMESPACE     NAME                          READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">kube-system   coredns-78d4cf999f-cw79l      0/1     Pending   0          47m</span><br><span class=\"line\">kube-system   coredns-78d4cf999f-w8j47      0/1     Pending   0          47m</span><br><span class=\"line\">kube-system   etcd-m01                      1/1     Running   0          47m</span><br><span class=\"line\">kube-system   kube-apiserver-m01            1/1     Running   0          46m</span><br><span class=\"line\">kube-system   kube-controller-manager-m01   1/1     Running   0          46m</span><br><span class=\"line\">kube-system   kube-proxy-5954k              1/1     Running   0          47m</span><br><span class=\"line\">kube-system   kube-scheduler-m01            1/1     Running   0          47m</span><br></pre></td></tr></table></figure>\n<p>其中，由于未安装相关的网络组件，eg:flannel,所有coredn还是显示为pending，暂时没有影响。</p>\n<h4 id=\"2-4-4-安装CNI插件flannel\"><a href=\"#2-4-4-安装CNI插件flannel\" class=\"headerlink\" title=\"2.4.4 安装CNI插件flannel\"></a>2.4.4 安装CNI插件flannel</h4><p><strong>备注：所有的节点都需要安装</strong><br>具体的安装脚本如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">## 拉取镜像</span><br><span class=\"line\">sudo docker pull quay.io/coreos/flannel:v0.11.0-amd64</span><br><span class=\"line\">## 部署</span><br><span class=\"line\">kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml</span><br></pre></td></tr></table></figure>\n<p>安装成功之后，通过 <code>kubectl get pods --all-namespaces</code>，看到所有 Pod 都正常了.</p>\n<h3 id=\"2-5-安装剩余的master\"><a href=\"#2-5-安装剩余的master\" class=\"headerlink\" title=\"2.5 安装剩余的master\"></a>2.5 安装剩余的master</h3><h4 id=\"2-5-1-同步tf-k8s-m1的ca证书\"><a href=\"#2-5-1-同步tf-k8s-m1的ca证书\" class=\"headerlink\" title=\"2.5.1 同步tf-k8s-m1的ca证书\"></a>2.5.1 同步tf-k8s-m1的ca证书</h4><p>首先，将 tf-k8s-m1 中的 ca 证书，scp 到其他 master 机器（tf-k8s-m2 tf-k8s-m3）。<br>为了方便，这里也是通过脚本来执行，具体如下：<br>注意：需要确认 tf-k8s-m1 上的 root 账号可以免密登录到 tf-k8s-m2 和 tf-k8s-m3 的 root 账号。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">## 创建脚本：sync.master.ca.sh</span><br><span class=\"line\"></span><br><span class=\"line\">#!/bin/sh</span><br><span class=\"line\"></span><br><span class=\"line\">vhost=&quot;tf-k8s-m2 tf-k8s-m3&quot;</span><br><span class=\"line\">usr=root</span><br><span class=\"line\"></span><br><span class=\"line\">who=`whoami`</span><br><span class=\"line\">if [[ &quot;$who&quot; != &quot;$usr&quot; ]];then</span><br><span class=\"line\">  echo &quot;请使用 root 用户执行或者 sudo ./sync.master.ca.sh&quot;</span><br><span class=\"line\">  exit 1</span><br><span class=\"line\">fi</span><br><span class=\"line\"></span><br><span class=\"line\">echo $who</span><br><span class=\"line\"></span><br><span class=\"line\"># 需要从 m01 拷贝的 ca 文件</span><br><span class=\"line\">caFiles=(</span><br><span class=\"line\">/etc/kubernetes/pki/ca.crt</span><br><span class=\"line\">/etc/kubernetes/pki/ca.key</span><br><span class=\"line\">/etc/kubernetes/pki/sa.key</span><br><span class=\"line\">/etc/kubernetes/pki/sa.pub</span><br><span class=\"line\">/etc/kubernetes/pki/front-proxy-ca.crt</span><br><span class=\"line\">/etc/kubernetes/pki/front-proxy-ca.key</span><br><span class=\"line\">/etc/kubernetes/pki/etcd/ca.crt</span><br><span class=\"line\">/etc/kubernetes/pki/etcd/ca.key</span><br><span class=\"line\">/etc/kubernetes/admin.conf</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">pkiDir=/etc/kubernetes/pki/etcd</span><br><span class=\"line\">for h in $vhost </span><br><span class=\"line\">do</span><br><span class=\"line\"></span><br><span class=\"line\">  ssh $&#123;usr&#125;@$h &quot;mkdir -p $pkiDir&quot;</span><br><span class=\"line\">  </span><br><span class=\"line\">  echo &quot;Dirs for ca scp created, start to scp...&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">  # scp 文件到目标机</span><br><span class=\"line\">  for f in $&#123;caFiles[@]&#125;</span><br><span class=\"line\">  do </span><br><span class=\"line\">    echo &quot;scp $f $&#123;usr&#125;@$h:$f&quot;</span><br><span class=\"line\">    scp $f $&#123;usr&#125;@$h:$f</span><br><span class=\"line\">  done</span><br><span class=\"line\"></span><br><span class=\"line\">  echo &quot;Ca files transfered for $h ... ok&quot;</span><br><span class=\"line\">done</span><br></pre></td></tr></table></figure>\n<p>执行脚本，将 tf-k8s-m1 相关的 ca 文件传到tf-k8s-m2 和 tf-k8s-m3：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">chmod +x sync.master.ca.sh</span><br><span class=\"line\"></span><br><span class=\"line\">sudo ./syncaster.ca.sh</span><br></pre></td></tr></table></figure>\n<h4 id=\"2-5-2-安装master-tf-k8s-m2\"><a href=\"#2-5-2-安装master-tf-k8s-m2\" class=\"headerlink\" title=\"2.5.2 安装master tf-k8s-m2\"></a>2.5.2 安装master tf-k8s-m2</h4><p>总共分为四个步骤，分别是:总1. 共分为四个步骤，分别是:</p>\n<ul>\n<li>配置证书、初始化 kubelet 配置和启动 kubelet</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[kube@tf-k8s-m2 ~]$ sudo kubeadm init phase certs all --config kubeadm-config.tf-k8s-m2.yaml</span><br><span class=\"line\">[kube@tf-k8s-m2 ~]$ sudo kubeadm init phase etcd local --config kubeadm-config.tf-k8s-m2.yaml</span><br><span class=\"line\">[kube@tf-k8s-m2 ~]$ sudo kubeadm init phase kubeconfig kubelet --config kubeadm-config.tf-k8s-m2.yaml</span><br><span class=\"line\">[kube@tf-k8s-m2 ~]$ sudo kubeadm init phase kubelet-start --config kubeadm-config.tf-k8s-m2.yaml</span><br></pre></td></tr></table></figure>\n<ul>\n<li>将etcd加入集群</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[kube@tf-k8s-m2 root]$ kubectl exec -n kube-system etcd-tf-k8s-m1 -- etcdctl --ca-file /etc/kubernetes/pki/etcd/ca.crt --cert-file /etc/kubernetes/pki/etcd/peer.crt --key-file /etc/kubernetes/pki/etcd/peer.key --endpoints=https://10.0.0.1:2379 member add tf-k8s-m2 https://10.0.0.2:2380</span><br></pre></td></tr></table></figure>\n<p>启动kube-apiserver、kube-controller-manager、kube-scheduler</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[kube@tf-k8s-m2 ~]$ sudo kubeadm init phase kubeconfig all --config kubeadm-config.m02.yaml</span><br><span class=\"line\">[kube@tf-k8s-m2 ~]$ sudo kubeadm init phase control-plane all --config kubeadm-config.m02.yaml</span><br></pre></td></tr></table></figure>\n<p>将节点标记为master节点</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[kube@tf-k8s-m2 ~]$ sudo kubeadm init phase mark-control-plane --config kubeadm-config.m02.yaml</span><br></pre></td></tr></table></figure>\n<h4 id=\"2-5-3-安装master-tf-k8s-m3\"><a href=\"#2-5-3-安装master-tf-k8s-m3\" class=\"headerlink\" title=\"2.5.3 安装master tf-k8s-m3\"></a>2.5.3 安装master tf-k8s-m3</h4><p>安装过程和安装master tf-k8s-m2是一样的，区别在于使用的kubeadm配置文件为kubeadm-config.tf-k8s-m3.yaml以及etcd加入成员时指定的实例地址不一样。<br>完整的流程如下:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 1.  配置证书、初始化 kubelet 配置和启动 kubelet</span><br><span class=\"line\">sudo kubeadm init phase certs all --config kubeadm-config.tf-k8s-m3.yaml</span><br><span class=\"line\">sudo kubeadm init phase etcd local --config kubeadm-config.tf-k8s-m3.yaml</span><br><span class=\"line\">sudo kubeadm init phase kubeconfig kubelet --config kubeadm-config.tf-k8s-m3.yaml</span><br><span class=\"line\">sudo kubeadm init phase kubelet-start --config kubeadm-config.tf-k8s-m3.yaml</span><br><span class=\"line\"></span><br><span class=\"line\"># 2. 将 etcd 加入集群</span><br><span class=\"line\">kubectl exec -n kube-system etcd-tf-k8s-m1 -- etcdctl --ca-file /etc/kubernetes/pki/etcd/ca.crt --cert-file /etc/kubernetes/pki/etcd/peer.crt --key-file /etc/kubernetes/pki/etcd/peer.key --endpoints=https://10.0.0.1:2379 member add tf-k8s-m3 https://10.0.0.3:2380</span><br><span class=\"line\"></span><br><span class=\"line\"># 3. 启动 kube-apiserver、kube-controller-manager、kube-scheduler</span><br><span class=\"line\">sudo kubeadm init phase kubeconfig all --config kubeadm-config.tf-k8s-m3.yaml</span><br><span class=\"line\">sudo kubeadm init phase control-plane all --config kubeadm-config.tf-k8s-m3.yaml</span><br><span class=\"line\"></span><br><span class=\"line\"># 4. 将节点标记为 master 节点</span><br><span class=\"line\">sudo kubeadm init phase mark-control-plane --config kubeadm-config.tf-k8s-m3.yaml</span><br></pre></td></tr></table></figure>\n<h4 id=\"2-5-4-验证三个master节点\"><a href=\"#2-5-4-验证三个master节点\" class=\"headerlink\" title=\"2.5.4 验证三个master节点\"></a>2.5.4 验证三个master节点</h4><p>至此，三个 master 节点安装完成，通过 kubectl get pods –all-namespaces 查看当前集群所有 Pod。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[kube@tf-k8s-m2 ~]$ kubectl  get pods --all-namespaces</span><br><span class=\"line\">NAMESPACE     NAME                          READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">kube-system   coredns-78d4cf999f-j8zsr      1/1     Running   0          170m</span><br><span class=\"line\">kube-system   coredns-78d4cf999f-lw5qx      1/1     Running   0          171m</span><br><span class=\"line\">kube-system   etcd-m01                      1/1     Running   8          5h11m</span><br><span class=\"line\">kube-system   etcd-m02                      1/1     Running   12         97m</span><br><span class=\"line\">kube-system   etcd-m03                      1/1     Running   0          91m</span><br><span class=\"line\">kube-system   kube-apiserver-m01            1/1     Running   9          5h11m</span><br><span class=\"line\">kube-system   kube-apiserver-m02            1/1     Running   0          95m</span><br><span class=\"line\">kube-system   kube-apiserver-m03            1/1     Running   0          91m</span><br><span class=\"line\">kube-system   kube-controller-manager-m01   1/1     Running   4          5h11m</span><br><span class=\"line\">kube-system   kube-controller-manager-m02   1/1     Running   0          95m</span><br><span class=\"line\">kube-system   kube-controller-manager-m03   1/1     Running   0          91m</span><br><span class=\"line\">kube-system   kube-flannel-ds-amd64-7b86z   1/1     Running   0          3h31m</span><br><span class=\"line\">kube-system   kube-flannel-ds-amd64-98qks   1/1     Running   0          91m</span><br><span class=\"line\">kube-system   kube-flannel-ds-amd64-ljcdp   1/1     Running   0          97m</span><br><span class=\"line\">kube-system   kube-proxy-krnjq              1/1     Running   0          5h12m</span><br><span class=\"line\">kube-system   kube-proxy-scb25              1/1     Running   0          91m</span><br><span class=\"line\">kube-system   kube-proxy-xp4rj              1/1     Running   0          97m</span><br><span class=\"line\">kube-system   kube-scheduler-m01            1/1     Running   4          5h11m</span><br><span class=\"line\">kube-system   kube-scheduler-m02            1/1     Running   0          95m</span><br><span class=\"line\">kube-system   kube-scheduler-m03            1/1     Running   0          91m</span><br></pre></td></tr></table></figure>\n<h4 id=\"2-5-5-加入工作节点\"><a href=\"#2-5-5-加入工作节点\" class=\"headerlink\" title=\"2.5.5 加入工作节点\"></a>2.5.5 加入工作节点</h4><p>这步很简单，只需要在工作节点 tf-k8s-n1 和 tf-k8s-n2 上执行加入集群的命令即可。</p>\n<p>可以使用上面安装 master tf-k8s-m1 成功后打印的命令 kubeadm join api.tf-k8s.xiangwushuo.com:6443 –token a1t7c1.mzltpc72dc3wzj9y –discovery-token-ca-cert-hash sha256:05f44b111174613055975f012fc11fe09bdcd746bd7b3c8d99060c52619f8738，也可以重新生成 Token。<br>这里演示如何重新生成 Token 和 证书 hash，在 tf-k8s-m1 上执行以下操作：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 1. 创建 token</span><br><span class=\"line\">[kube@tf-k8s-m1 ~]$ kubeadm token create </span><br><span class=\"line\"></span><br><span class=\"line\"># 控制台打印如：</span><br><span class=\"line\">gz1v4w.sulpuxkqtnyci92f</span><br><span class=\"line\"></span><br><span class=\"line\"># 2.  查看我们创建的 k8s 集群的证书 hash</span><br><span class=\"line\">[kube@tf-k8s-m1 ~]$ openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2&gt;/dev/null | openssl dgst -sha256 -hex | sed &apos;s/^.* //&apos;</span><br><span class=\"line\"></span><br><span class=\"line\"># 控制台打印如：</span><br><span class=\"line\">b125cd0c80462353d8fa3e4f5034f1e1a1e3cc9bade32acfb235daa867c60f61</span><br></pre></td></tr></table></figure>\n<p>然后使用<code>kubeadm join</code>,分别在工作节点tf-k8s-n1与tf-k8s-n2上执行，将节点加入<br>集群，如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo kubeadm join api.tf-k8s.xiangwushuo.com:6443 --token gz1v4w.sulpuxkqtnyci92f --discovery-token-ca-cert-hash sha256:b125cd0c80462353d8fa3e4f5034f1e1a1e3cc9bade32acfb235daa867c60f61</span><br></pre></td></tr></table></figure>\n<p>在 tf-k8s-m1 上通过 kubectl get nodes 查看，将看到节点已被加进来（节点刚加进来时，状态可能会是 NotReady，稍等一会就回变成 Ready）。</p>\n<h3 id=\"2-6-部署高可用CoreDNS\"><a href=\"#2-6-部署高可用CoreDNS\" class=\"headerlink\" title=\"2.6 部署高可用CoreDNS\"></a>2.6 部署高可用CoreDNS</h3><p>默认安装的 CoreDNS 存在单点问题。在 m01 上通过 kubectl get pods -n kube-system -owide 查看当前集群 CoreDNS Pod 分布（如下）。</p>\n<p>从列表中，可以看到 CoreDNS 的两个 Pod 都在 m01 上，存在单点问题。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[kube@tf-k8s-m1 ~]$ kubectl get pods -n kube-system -owide</span><br><span class=\"line\">NAME                                    READY   STATUS    RESTARTS   AGE     IP            NODE        NOMINATED NODE   READINESS GATES</span><br><span class=\"line\">coredns-6c67f849c7-h7lcr                1/1     Running   0          4d3h    10.244.3.2    tf-k8s-m1   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">coredns-6c67f849c7-mx9k9                1/1     Running   0          4d3h    10.244.4.2    tf-k8s-m1   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">etcd-tf-k8s-m1                          1/1     Running   1          4d5h    10.0.0.1   tf-k8s-m1   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">etcd-tf-k8s-m2                          1/1     Running   7          4d3h    10.0.0.2   tf-k8s-m2   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">etcd-tf-k8s-m3                          1/1     Running   7          4d3h    10.0.0.3   tf-k8s-m3   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-apiserver-tf-k8s-m1                1/1     Running   0          4d5h    10.0.0.1   tf-k8s-m1   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-apiserver-tf-k8s-m2                1/1     Running   0          4d3h    10.0.0.2   tf-k8s-m2   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-apiserver-tf-k8s-m3                1/1     Running   0          4d3h    10.0.0.3   tf-k8s-m3   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-controller-manager-tf-k8s-m1       1/1     Running   1          4d5h    10.0.0.1   tf-k8s-m1   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-controller-manager-tf-k8s-m2       1/1     Running   0          4d3h    10.0.0.2   tf-k8s-m2   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-controller-manager-tf-k8s-m3       1/1     Running   0          4d3h    10.0.0.3   tf-k8s-m3   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-flannel-ds-amd64-4v6dd             1/1     Running   1          4d3h    10.0.0.5   tf-k8s-n2   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-flannel-ds-amd64-g6sg5             1/1     Running   0          4d3h    10.0.0.3   tf-k8s-m3   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-flannel-ds-amd64-ml4w7             1/1     Running   1          4d3h    10.0.0.4   tf-k8s-n1   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-flannel-ds-amd64-tb27x             1/1     Running   0          4d3h    10.0.0.2   tf-k8s-m2   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-flannel-ds-amd64-x5dqj             1/1     Running   0          4d4h    10.0.0.1   tf-k8s-m1   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-proxy-4wbn7                        1/1     Running   0          4d3h    10.0.0.4   tf-k8s-n1   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-proxy-8dhtz                        1/1     Running   0          4d3h    10.0.0.2   tf-k8s-m2   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-proxy-l8727                        1/1     Running   0          4d5h    10.0.0.1   tf-k8s-m1   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-proxy-tz924                        1/1     Running   0          4d3h    10.0.0.5   tf-k8s-n2   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-proxy-w7tmn                        1/1     Running   0          4d3h    10.0.0.3   tf-k8s-m3   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-scheduler-tf-k8s-m1                1/1     Running   1          4d5h    10.0.0.1   tf-k8s-m1   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-scheduler-tf-k8s-m2                1/1     Running   0          4d3h    10.0.0.2   tf-k8s-m2   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-scheduler-tf-k8s-m3                1/1     Running   0          4d3h    10.0.0.3   tf-k8s-m3   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kubernetes-dashboard-847f8cb7b8-hmf9m   1/1     Running   0          3d23h   10.244.4.4    tf-k8s-n2   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">metrics-server-8658466f94-pzl6z         1/1     Running   0          4d2h    10.244.3.3    tf-k8s-n1   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure>\n<p>首先删除CoreDNS的deploy，然后创建新的CoreDNS-HA.yaml配置文件，如下</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: apps/v1</span><br><span class=\"line\">kind: Deployment</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    k8s-app: kube-dns</span><br><span class=\"line\">  name: coredns</span><br><span class=\"line\">  namespace: kube-system</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  #集群规模可自行配置</span><br><span class=\"line\">  replicas: 2</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    matchLabels:</span><br><span class=\"line\">      k8s-app: kube-dns</span><br><span class=\"line\">  strategy:</span><br><span class=\"line\">    rollingUpdate:</span><br><span class=\"line\">      maxSurge: 25%</span><br><span class=\"line\">      maxUnavailable: 1</span><br><span class=\"line\">    type: RollingUpdate</span><br><span class=\"line\">  template:</span><br><span class=\"line\">    metadata:</span><br><span class=\"line\">      labels:</span><br><span class=\"line\">        k8s-app: kube-dns</span><br><span class=\"line\">    spec:</span><br><span class=\"line\">      affinity:</span><br><span class=\"line\">        podAntiAffinity:</span><br><span class=\"line\">          preferredDuringSchedulingIgnoredDuringExecution:</span><br><span class=\"line\">          - weight: 100</span><br><span class=\"line\">            podAffinityTerm:</span><br><span class=\"line\">              labelSelector:</span><br><span class=\"line\">                matchExpressions:</span><br><span class=\"line\">                - key: k8s-app</span><br><span class=\"line\">                  operator: In</span><br><span class=\"line\">                  values:</span><br><span class=\"line\">                  - kube-dns</span><br><span class=\"line\">              topologyKey: kubernetes.io/hostname</span><br><span class=\"line\">      containers:</span><br><span class=\"line\">      - args:</span><br><span class=\"line\">        - -conf</span><br><span class=\"line\">        - /etc/coredns/Corefile</span><br><span class=\"line\">        image: registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:1.2.6</span><br><span class=\"line\">        imagePullPolicy: IfNotPresent</span><br><span class=\"line\">        livenessProbe:</span><br><span class=\"line\">          failureThreshold: 5</span><br><span class=\"line\">          httpGet:</span><br><span class=\"line\">            path: /health</span><br><span class=\"line\">            port: 8080</span><br><span class=\"line\">            scheme: HTTP</span><br><span class=\"line\">          initialDelaySeconds: 60</span><br><span class=\"line\">          periodSeconds: 10</span><br><span class=\"line\">          successThreshold: 1</span><br><span class=\"line\">          timeoutSeconds: 5</span><br><span class=\"line\">        name: coredns</span><br><span class=\"line\">        ports:</span><br><span class=\"line\">        - containerPort: 53</span><br><span class=\"line\">          name: dns</span><br><span class=\"line\">          protocol: UDP</span><br><span class=\"line\">        - containerPort: 53</span><br><span class=\"line\">          name: dns-tcp</span><br><span class=\"line\">          protocol: TCP</span><br><span class=\"line\">        - containerPort: 9153</span><br><span class=\"line\">          name: metrics</span><br><span class=\"line\">          protocol: TCP</span><br><span class=\"line\">        resources:</span><br><span class=\"line\">          limits:</span><br><span class=\"line\">            memory: 170Mi</span><br><span class=\"line\">          requests:</span><br><span class=\"line\">            cpu: 100m</span><br><span class=\"line\">            memory: 70Mi</span><br><span class=\"line\">        securityContext:</span><br><span class=\"line\">          allowPrivilegeEscalation: false</span><br><span class=\"line\">          capabilities:</span><br><span class=\"line\">            add:</span><br><span class=\"line\">            - NET_BIND_SERVICE</span><br><span class=\"line\">            drop:</span><br><span class=\"line\">            - all</span><br><span class=\"line\">          readOnlyRootFilesystem: true</span><br><span class=\"line\">        terminationMessagePath: /dev/termination-log</span><br><span class=\"line\">        terminationMessagePolicy: File</span><br><span class=\"line\">        volumeMounts:</span><br><span class=\"line\">        - mountPath: /etc/coredns</span><br><span class=\"line\">          name: config-volume</span><br><span class=\"line\">          readOnly: true</span><br><span class=\"line\">      dnsPolicy: Default</span><br><span class=\"line\">      restartPolicy: Always</span><br><span class=\"line\">      schedulerName: default-scheduler</span><br><span class=\"line\">      securityContext: &#123;&#125;</span><br><span class=\"line\">      serviceAccount: coredns</span><br><span class=\"line\">      serviceAccountName: coredns</span><br><span class=\"line\">      terminationGracePeriodSeconds: 30</span><br><span class=\"line\">      tolerations:</span><br><span class=\"line\">      - key: CriticalAddonsOnly</span><br><span class=\"line\">        operator: Exists</span><br><span class=\"line\">      - effect: NoSchedule</span><br><span class=\"line\">        key: node-role.kubernetes.io/master</span><br><span class=\"line\">      volumes:</span><br><span class=\"line\">      - configMap:</span><br><span class=\"line\">          defaultMode: 420</span><br><span class=\"line\">          items:</span><br><span class=\"line\">          - key: Corefile</span><br><span class=\"line\">            path: Corefile</span><br><span class=\"line\">          name: coredns</span><br><span class=\"line\">        name: config-volume</span><br></pre></td></tr></table></figure>\n<p>部署新的CoreDNS </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl apply -f CoreDNS-HA.yaml</span><br></pre></td></tr></table></figure>\n<h3 id=\"2-7-部署监控组件metrics-server\"><a href=\"#2-7-部署监控组件metrics-server\" class=\"headerlink\" title=\"2.7 部署监控组件metrics-server\"></a>2.7 部署监控组件metrics-server</h3><p>kubernetesv1.11 以后不再支持通过 heaspter 采集监控数据。使用新的监控数据采集组件metrics-server。 metrics-server 比 heaspter 轻量很多，也不做数据的持久化存储，提供实时的监控数据查询。</p>\n<p>先将所有文件下载，保存在一个文件夹 metrics-server 里。</p>\n<p>修改 metrics-server-deployment.yaml 两处地方，分别是：apiVersion 和 image，最终修改后的 metrics-server-deployment.yaml 如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">---</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: ServiceAccount</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: metrics-server</span><br><span class=\"line\">  namespace: kube-system</span><br><span class=\"line\">---</span><br><span class=\"line\"># 将extensions/v1beta1修改为apps/v1</span><br><span class=\"line\">apiVersion: apps/v1</span><br><span class=\"line\">kind: Deployment</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: metrics-server</span><br><span class=\"line\">  namespace: kube-system</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    k8s-app: metrics-server</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    matchLabels:</span><br><span class=\"line\">      k8s-app: metrics-server</span><br><span class=\"line\">  template:</span><br><span class=\"line\">    metadata:</span><br><span class=\"line\">      name: metrics-server</span><br><span class=\"line\">      labels:</span><br><span class=\"line\">        k8s-app: metrics-server</span><br><span class=\"line\">    spec:</span><br><span class=\"line\">      serviceAccountName: metrics-server</span><br><span class=\"line\">      volumes:</span><br><span class=\"line\">      # mount in tmp so we can safely use from-scratch images and/or read-only containers</span><br><span class=\"line\">      - name: tmp-dir</span><br><span class=\"line\">        emptyDir: &#123;&#125;</span><br><span class=\"line\">      containers:</span><br><span class=\"line\">      - name: metrics-server</span><br><span class=\"line\">        image: cloudnil/metrics-server-amd64:v0.3.1</span><br><span class=\"line\">        command:</span><br><span class=\"line\">          - /metrics-server</span><br><span class=\"line\">          - --kubelet-insecure-tls</span><br><span class=\"line\">          - --kubelet-preferred-address-types=InternalIP</span><br><span class=\"line\">        imagePullPolicy: Always</span><br><span class=\"line\">        volumeMounts:</span><br><span class=\"line\">        - name: tmp-dir</span><br><span class=\"line\">          mountPath: /tmp</span><br></pre></td></tr></table></figure>\n<p>进入刚创建的 metrics-server，执行 kubectl apply -f .  进行部署（注意 -f 后面有个点）,如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[kube@tf-k8s-m1 metrics-server]$ kubectl apply -f .</span><br><span class=\"line\"></span><br><span class=\"line\">clusterrole.rbac.authorization.k8s.io/system:aggregated-metrics-reader created</span><br><span class=\"line\">clusterrolebinding.rbac.authorization.k8s.io/metrics-server:system:auth-delegator created</span><br><span class=\"line\">rolebinding.rbac.authorization.k8s.io/metrics-server-auth-reader created</span><br><span class=\"line\">apiservice.apiregistration.k8s.io/v1beta1.metrics.k8s.io created</span><br><span class=\"line\">serviceaccount/metrics-server created</span><br><span class=\"line\">deployment.apps/metrics-server created</span><br><span class=\"line\">service/metrics-server created</span><br><span class=\"line\">clusterrole.rbac.authorization.k8s.io/system:metrics-server created</span><br><span class=\"line\">clusterrolebinding.rbac.authorization.k8s.io/system:metrics-server created</span><br></pre></td></tr></table></figure>\n<p>运行<code>kubectl get pods -n kube-system</code>，确定metrics-server的pods是否正常running。</p>\n<h3 id=\"2-8-部署Nginx-ingress-controller\"><a href=\"#2-8-部署Nginx-ingress-controller\" class=\"headerlink\" title=\"2.8 部署Nginx-ingress-controller\"></a>2.8 部署Nginx-ingress-controller</h3><p>Nginx-ingress-controller 是 kubernetes 官方提供的集成了 Ingress-controller 和 Nginx 的一个 docker 镜像。</p>\n<p>本次部署中，将 Nginx-ingress 部署到 tf-k8s-m1、tf-k8s-m2、tf-k8s-m3上，监听宿主机的 80 端口。</p>\n<p>创建 nginx-ingress.yaml 文件，内容如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br><span class=\"line\">187</span><br><span class=\"line\">188</span><br><span class=\"line\">189</span><br><span class=\"line\">190</span><br><span class=\"line\">191</span><br><span class=\"line\">192</span><br><span class=\"line\">193</span><br><span class=\"line\">194</span><br><span class=\"line\">195</span><br><span class=\"line\">196</span><br><span class=\"line\">197</span><br><span class=\"line\">198</span><br><span class=\"line\">199</span><br><span class=\"line\">200</span><br><span class=\"line\">201</span><br><span class=\"line\">202</span><br><span class=\"line\">203</span><br><span class=\"line\">204</span><br><span class=\"line\">205</span><br><span class=\"line\">206</span><br><span class=\"line\">207</span><br><span class=\"line\">208</span><br><span class=\"line\">209</span><br><span class=\"line\">210</span><br><span class=\"line\">211</span><br><span class=\"line\">212</span><br><span class=\"line\">213</span><br><span class=\"line\">214</span><br><span class=\"line\">215</span><br><span class=\"line\">216</span><br><span class=\"line\">217</span><br><span class=\"line\">218</span><br><span class=\"line\">219</span><br><span class=\"line\">220</span><br><span class=\"line\">221</span><br><span class=\"line\">222</span><br><span class=\"line\">223</span><br><span class=\"line\">224</span><br><span class=\"line\">225</span><br><span class=\"line\">226</span><br><span class=\"line\">227</span><br><span class=\"line\">228</span><br><span class=\"line\">229</span><br><span class=\"line\">230</span><br><span class=\"line\">231</span><br><span class=\"line\">232</span><br><span class=\"line\">233</span><br><span class=\"line\">234</span><br><span class=\"line\">235</span><br><span class=\"line\">236</span><br><span class=\"line\">237</span><br><span class=\"line\">238</span><br><span class=\"line\">239</span><br><span class=\"line\">240</span><br><span class=\"line\">241</span><br><span class=\"line\">242</span><br><span class=\"line\">243</span><br><span class=\"line\">244</span><br><span class=\"line\">245</span><br><span class=\"line\">246</span><br><span class=\"line\">247</span><br><span class=\"line\">248</span><br><span class=\"line\">249</span><br><span class=\"line\">250</span><br><span class=\"line\">251</span><br><span class=\"line\">252</span><br><span class=\"line\">253</span><br><span class=\"line\">254</span><br><span class=\"line\">255</span><br><span class=\"line\">256</span><br><span class=\"line\">257</span><br><span class=\"line\">258</span><br><span class=\"line\">259</span><br><span class=\"line\">260</span><br><span class=\"line\">261</span><br><span class=\"line\">262</span><br><span class=\"line\">263</span><br><span class=\"line\">264</span><br><span class=\"line\">265</span><br><span class=\"line\">266</span><br><span class=\"line\">267</span><br><span class=\"line\">268</span><br><span class=\"line\">269</span><br><span class=\"line\">270</span><br><span class=\"line\">271</span><br><span class=\"line\">272</span><br><span class=\"line\">273</span><br><span class=\"line\">274</span><br><span class=\"line\">275</span><br><span class=\"line\">276</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Namespace</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: ingress-nginx</span><br><span class=\"line\">---</span><br><span class=\"line\">kind: ConfigMap</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: nginx-configuration</span><br><span class=\"line\">  namespace: ingress-nginx</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app.kubernetes.io/name: ingress-nginx</span><br><span class=\"line\">    app.kubernetes.io/part-of: ingress-nginx</span><br><span class=\"line\">---</span><br><span class=\"line\">kind: ConfigMap</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: tcp-services</span><br><span class=\"line\">  namespace: ingress-nginx</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app.kubernetes.io/name: ingress-nginx</span><br><span class=\"line\">    app.kubernetes.io/part-of: ingress-nginx</span><br><span class=\"line\">---</span><br><span class=\"line\">kind: ConfigMap</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: udp-services</span><br><span class=\"line\">  namespace: ingress-nginx</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app.kubernetes.io/name: ingress-nginx</span><br><span class=\"line\">    app.kubernetes.io/part-of: ingress-nginx</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: ServiceAccount</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: nginx-ingress-serviceaccount</span><br><span class=\"line\">  namespace: ingress-nginx</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app.kubernetes.io/name: ingress-nginx</span><br><span class=\"line\">    app.kubernetes.io/part-of: ingress-nginx</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: rbac.authorization.k8s.io/v1beta1</span><br><span class=\"line\">kind: ClusterRole</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: nginx-ingress-clusterrole</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app.kubernetes.io/name: ingress-nginx</span><br><span class=\"line\">    app.kubernetes.io/part-of: ingress-nginx</span><br><span class=\"line\">rules:</span><br><span class=\"line\">  - apiGroups:</span><br><span class=\"line\">      - &quot;&quot;</span><br><span class=\"line\">    resources:</span><br><span class=\"line\">      - configmaps</span><br><span class=\"line\">      - endpoints</span><br><span class=\"line\">      - nodes</span><br><span class=\"line\">      - pods</span><br><span class=\"line\">      - secrets</span><br><span class=\"line\">    verbs:</span><br><span class=\"line\">      - list</span><br><span class=\"line\">      - watch</span><br><span class=\"line\">  - apiGroups:</span><br><span class=\"line\">      - &quot;&quot;</span><br><span class=\"line\">    resources:</span><br><span class=\"line\">      - nodes</span><br><span class=\"line\">    verbs:</span><br><span class=\"line\">      - get</span><br><span class=\"line\">  - apiGroups:</span><br><span class=\"line\">      - &quot;&quot;</span><br><span class=\"line\">    resources:</span><br><span class=\"line\">      - services</span><br><span class=\"line\">    verbs:</span><br><span class=\"line\">      - get</span><br><span class=\"line\">      - list</span><br><span class=\"line\">      - watch</span><br><span class=\"line\">  - apiGroups:</span><br><span class=\"line\">      - &quot;extensions&quot;</span><br><span class=\"line\">    resources:</span><br><span class=\"line\">      - ingresses</span><br><span class=\"line\">    verbs:</span><br><span class=\"line\">      - get</span><br><span class=\"line\">      - list</span><br><span class=\"line\">      - watch</span><br><span class=\"line\">  - apiGroups:</span><br><span class=\"line\">      - &quot;&quot;</span><br><span class=\"line\">    resources:</span><br><span class=\"line\">      - events</span><br><span class=\"line\">    verbs:</span><br><span class=\"line\">      - create</span><br><span class=\"line\">      - patch</span><br><span class=\"line\">  - apiGroups:</span><br><span class=\"line\">      - &quot;extensions&quot;</span><br><span class=\"line\">    resources:</span><br><span class=\"line\">      - ingresses/status</span><br><span class=\"line\">    verbs:</span><br><span class=\"line\">      - update</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: rbac.authorization.k8s.io/v1beta1</span><br><span class=\"line\">kind: Role</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: nginx-ingress-role</span><br><span class=\"line\">  namespace: ingress-nginx</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app.kubernetes.io/name: ingress-nginx</span><br><span class=\"line\">    app.kubernetes.io/part-of: ingress-nginx</span><br><span class=\"line\">rules:</span><br><span class=\"line\">  - apiGroups:</span><br><span class=\"line\">      - &quot;&quot;</span><br><span class=\"line\">    resources:</span><br><span class=\"line\">      - configmaps</span><br><span class=\"line\">      - pods</span><br><span class=\"line\">      - secrets</span><br><span class=\"line\">      - namespaces</span><br><span class=\"line\">    verbs:</span><br><span class=\"line\">      - get</span><br><span class=\"line\">  - apiGroups:</span><br><span class=\"line\">      - &quot;&quot;</span><br><span class=\"line\">    resources:</span><br><span class=\"line\">      - configmaps</span><br><span class=\"line\">    resourceNames:</span><br><span class=\"line\">      - &quot;ingress-controller-leader-nginx&quot;</span><br><span class=\"line\">    verbs:</span><br><span class=\"line\">      - get</span><br><span class=\"line\">      - update</span><br><span class=\"line\">  - apiGroups:</span><br><span class=\"line\">      - &quot;&quot;</span><br><span class=\"line\">    resources:</span><br><span class=\"line\">      - configmaps</span><br><span class=\"line\">    verbs:</span><br><span class=\"line\">      - create</span><br><span class=\"line\">  - apiGroups:</span><br><span class=\"line\">      - &quot;&quot;</span><br><span class=\"line\">    resources:</span><br><span class=\"line\">      - endpoints</span><br><span class=\"line\">    verbs:</span><br><span class=\"line\">      - get</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: rbac.authorization.k8s.io/v1beta1</span><br><span class=\"line\">kind: RoleBinding</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: nginx-ingress-role-nisa-binding</span><br><span class=\"line\">  namespace: ingress-nginx</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app.kubernetes.io/name: ingress-nginx</span><br><span class=\"line\">    app.kubernetes.io/part-of: ingress-nginx</span><br><span class=\"line\">roleRef:</span><br><span class=\"line\">  apiGroup: rbac.authorization.k8s.io</span><br><span class=\"line\">  kind: Role</span><br><span class=\"line\">  name: nginx-ingress-role</span><br><span class=\"line\">subjects:</span><br><span class=\"line\">  - kind: ServiceAccount</span><br><span class=\"line\">    name: nginx-ingress-serviceaccount</span><br><span class=\"line\">    namespace: ingress-nginx</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: rbac.authorization.k8s.io/v1beta1</span><br><span class=\"line\">kind: ClusterRoleBinding</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: nginx-ingress-clusterrole-nisa-binding</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app.kubernetes.io/name: ingress-nginx</span><br><span class=\"line\">    app.kubernetes.io/part-of: ingress-nginx</span><br><span class=\"line\">roleRef:</span><br><span class=\"line\">  apiGroup: rbac.authorization.k8s.io</span><br><span class=\"line\">  kind: ClusterRole</span><br><span class=\"line\">  name: nginx-ingress-clusterrole</span><br><span class=\"line\">subjects:</span><br><span class=\"line\">  - kind: ServiceAccount</span><br><span class=\"line\">    name: nginx-ingress-serviceaccount</span><br><span class=\"line\">    namespace: ingress-nginx</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: apps/v1</span><br><span class=\"line\">kind: Deployment</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: nginx-ingress-controller</span><br><span class=\"line\">  namespace: ingress-nginx</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app.kubernetes.io/name: ingress-nginx</span><br><span class=\"line\">    app.kubernetes.io/part-of: ingress-nginx</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  replicas: 3</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    matchLabels:</span><br><span class=\"line\">      app.kubernetes.io/name: ingress-nginx</span><br><span class=\"line\">      app.kubernetes.io/part-of: ingress-nginx</span><br><span class=\"line\">  template:</span><br><span class=\"line\">    metadata:</span><br><span class=\"line\">      labels:</span><br><span class=\"line\">        app.kubernetes.io/name: ingress-nginx</span><br><span class=\"line\">        app.kubernetes.io/part-of: ingress-nginx</span><br><span class=\"line\">      annotations:</span><br><span class=\"line\">        prometheus.io/port: &quot;10254&quot;</span><br><span class=\"line\">        prometheus.io/scrape: &quot;true&quot;</span><br><span class=\"line\">    spec:</span><br><span class=\"line\">      hostNetwork: true</span><br><span class=\"line\">      affinity:</span><br><span class=\"line\">        nodeAffinity:</span><br><span class=\"line\">          requiredDuringSchedulingIgnoredDuringExecution:</span><br><span class=\"line\">            nodeSelectorTerms:</span><br><span class=\"line\">            - matchExpressions:</span><br><span class=\"line\">              - key: kubernetes.io/hostname</span><br><span class=\"line\">                operator: In</span><br><span class=\"line\">                # 指定部署到三台 master 上</span><br><span class=\"line\">                values:</span><br><span class=\"line\">                - tf-k8s-m1</span><br><span class=\"line\">                - tf-k8s-m2</span><br><span class=\"line\">                - tf-k8s-m3</span><br><span class=\"line\">        podAntiAffinity:</span><br><span class=\"line\">          requiredDuringSchedulingIgnoredDuringExecution:</span><br><span class=\"line\">            - labelSelector:</span><br><span class=\"line\">                matchExpressions:</span><br><span class=\"line\">                  - key: app.kubernetes.io/name</span><br><span class=\"line\">                    operator: In</span><br><span class=\"line\">                    values: </span><br><span class=\"line\">                    - ingress-nginx</span><br><span class=\"line\">              topologyKey: &quot;kubernetes.io/hostname&quot;</span><br><span class=\"line\">      tolerations:</span><br><span class=\"line\">      - key: node-role.kubernetes.io/master</span><br><span class=\"line\">        effect: NoSchedule</span><br><span class=\"line\">      serviceAccountName: nginx-ingress-serviceaccount</span><br><span class=\"line\">      containers:</span><br><span class=\"line\">        - name: nginx-ingress-controller</span><br><span class=\"line\">          image: registry.cn-hangzhou.aliyuncs.com/google_containers/nginx-ingress-controller:0.21.0</span><br><span class=\"line\">          args:</span><br><span class=\"line\">            - /nginx-ingress-controller</span><br><span class=\"line\">            - --configmap=/nginx-configuration</span><br><span class=\"line\">            - --tcp-services-configmap=/tcp-services</span><br><span class=\"line\">            - --udp-services-configmap=/udp-services</span><br><span class=\"line\">            # - --publish-service=/ingress-nginx</span><br><span class=\"line\">            - --annotations-prefix=nginx.ingress.kubernetes.io</span><br><span class=\"line\">          securityContext:</span><br><span class=\"line\">            capabilities:</span><br><span class=\"line\">              drop:</span><br><span class=\"line\">                - ALL</span><br><span class=\"line\">              add:</span><br><span class=\"line\">                - NET_BIND_SERVICE</span><br><span class=\"line\">            # www-data -&gt; 33</span><br><span class=\"line\">            runAsUser: 33</span><br><span class=\"line\">          env:</span><br><span class=\"line\">            - name: POD_NAME</span><br><span class=\"line\">              valueFrom:</span><br><span class=\"line\">                fieldRef:</span><br><span class=\"line\">                  fieldPath: metadata.name</span><br><span class=\"line\">            - name: POD_NAMESPACE</span><br><span class=\"line\">              valueFrom:</span><br><span class=\"line\">                fieldRef:</span><br><span class=\"line\">                  fieldPath: metadata.namespace</span><br><span class=\"line\">          ports:</span><br><span class=\"line\">            - name: http</span><br><span class=\"line\">              containerPort: 80</span><br><span class=\"line\">            - name: https</span><br><span class=\"line\">              containerPort: 443</span><br><span class=\"line\">          livenessProbe:</span><br><span class=\"line\">            failureThreshold: 3</span><br><span class=\"line\">            httpGet:</span><br><span class=\"line\">              path: /healthz</span><br><span class=\"line\">              port: 10254</span><br><span class=\"line\">              scheme: HTTP</span><br><span class=\"line\">            initialDelaySeconds: 10</span><br><span class=\"line\">            periodSeconds: 10</span><br><span class=\"line\">            successThreshold: 1</span><br><span class=\"line\">            timeoutSeconds: 1</span><br><span class=\"line\">          readinessProbe:</span><br><span class=\"line\">            failureThreshold: 3</span><br><span class=\"line\">            httpGet:</span><br><span class=\"line\">              path: /healthz</span><br><span class=\"line\">              port: 10254</span><br><span class=\"line\">              scheme: HTTP</span><br><span class=\"line\">            periodSeconds: 10</span><br><span class=\"line\">            successThreshold: 1</span><br><span class=\"line\">            timeoutSeconds: 1</span><br><span class=\"line\">          resources:</span><br><span class=\"line\">            limits:</span><br><span class=\"line\">              cpu: 1</span><br><span class=\"line\">              memory: 1024Mi</span><br><span class=\"line\">            requests:</span><br><span class=\"line\">              cpu: 0.25</span><br><span class=\"line\">              memory: 512Mi</span><br></pre></td></tr></table></figure>\n<p>部署 nginx ingress，执行命令 kubectl apply -f nginx-ingress.yaml</p>\n<h3 id=\"2-9-部署kubernetes-dashboard\"><a href=\"#2-9-部署kubernetes-dashboard\" class=\"headerlink\" title=\"2.9 部署kubernetes-dashboard\"></a>2.9 部署kubernetes-dashboard</h3><h4 id=\"2-9-1-Dashboard-配置\"><a href=\"#2-9-1-Dashboard-配置\" class=\"headerlink\" title=\"2.9.1 Dashboard 配置\"></a>2.9.1 Dashboard 配置</h4><p>新建部署 dashboard 的资源配置文件：kubernetes-dashboard.yaml，内容如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Secret</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    k8s-app: kubernetes-dashboard</span><br><span class=\"line\">  name: kubernetes-dashboard-certs</span><br><span class=\"line\">  namespace: kube-system</span><br><span class=\"line\">type: Opaque</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: ServiceAccount</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    k8s-app: kubernetes-dashboard</span><br><span class=\"line\">  name: kubernetes-dashboard</span><br><span class=\"line\">  namespace: kube-system</span><br><span class=\"line\">---</span><br><span class=\"line\">kind: Role</span><br><span class=\"line\">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: kubernetes-dashboard-minimal</span><br><span class=\"line\">  namespace: kube-system</span><br><span class=\"line\">rules:</span><br><span class=\"line\">  # Allow Dashboard to create &apos;kubernetes-dashboard-key-holder&apos; secret.</span><br><span class=\"line\">- apiGroups: [&quot;&quot;]</span><br><span class=\"line\">  resources: [&quot;secrets&quot;]</span><br><span class=\"line\">  verbs: [&quot;create&quot;]</span><br><span class=\"line\">  # Allow Dashboard to create &apos;kubernetes-dashboard-settings&apos; config map.</span><br><span class=\"line\">- apiGroups: [&quot;&quot;]</span><br><span class=\"line\">  resources: [&quot;configmaps&quot;]</span><br><span class=\"line\">  verbs: [&quot;create&quot;]</span><br><span class=\"line\">  # Allow Dashboard to get, update and delete Dashboard exclusive secrets.</span><br><span class=\"line\">- apiGroups: [&quot;&quot;]</span><br><span class=\"line\">  resources: [&quot;secrets&quot;]</span><br><span class=\"line\">  resourceNames: [&quot;kubernetes-dashboard-key-holder&quot;, &quot;kubernetes-dashboard-certs&quot;]</span><br><span class=\"line\">  verbs: [&quot;get&quot;, &quot;update&quot;, &quot;delete&quot;]</span><br><span class=\"line\">  # Allow Dashboard to get and update &apos;kubernetes-dashboard-settings&apos; config map.</span><br><span class=\"line\">- apiGroups: [&quot;&quot;]</span><br><span class=\"line\">  resources: [&quot;configmaps&quot;]</span><br><span class=\"line\">  resourceNames: [&quot;kubernetes-dashboard-settings&quot;]</span><br><span class=\"line\">  verbs: [&quot;get&quot;, &quot;update&quot;]</span><br><span class=\"line\">  # Allow Dashboard to get metrics from heapster.</span><br><span class=\"line\">- apiGroups: [&quot;&quot;]</span><br><span class=\"line\">  resources: [&quot;services&quot;]</span><br><span class=\"line\">  resourceNames: [&quot;heapster&quot;]</span><br><span class=\"line\">  verbs: [&quot;proxy&quot;]</span><br><span class=\"line\">- apiGroups: [&quot;&quot;]</span><br><span class=\"line\">  resources: [&quot;services/proxy&quot;]</span><br><span class=\"line\">  resourceNames: [&quot;heapster&quot;, &quot;http:heapster:&quot;, &quot;https:heapster:&quot;]</span><br><span class=\"line\">  verbs: [&quot;get&quot;]</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class=\"line\">kind: RoleBinding</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: kubernetes-dashboard-minimal</span><br><span class=\"line\">  namespace: kube-system</span><br><span class=\"line\">roleRef:</span><br><span class=\"line\">  apiGroup: rbac.authorization.k8s.io</span><br><span class=\"line\">  kind: Role</span><br><span class=\"line\">  name: kubernetes-dashboard-minimal</span><br><span class=\"line\">subjects:</span><br><span class=\"line\">- kind: ServiceAccount</span><br><span class=\"line\">  name: kubernetes-dashboard</span><br><span class=\"line\">  namespace: kube-system</span><br><span class=\"line\">---</span><br><span class=\"line\">kind: Deployment</span><br><span class=\"line\">apiVersion: apps/v1</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    k8s-app: kubernetes-dashboard</span><br><span class=\"line\">  name: kubernetes-dashboard</span><br><span class=\"line\">  namespace: kube-system</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  replicas: 1</span><br><span class=\"line\">  revisionHistoryLimit: 10</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    matchLabels:</span><br><span class=\"line\">      k8s-app: kubernetes-dashboard</span><br><span class=\"line\">  template:</span><br><span class=\"line\">    metadata:</span><br><span class=\"line\">      labels:</span><br><span class=\"line\">        k8s-app: kubernetes-dashboard</span><br><span class=\"line\">    spec:</span><br><span class=\"line\">      containers:</span><br><span class=\"line\">      - name: kubernetes-dashboard</span><br><span class=\"line\">        # 使用阿里云的镜像</span><br><span class=\"line\">        image: registry.cn-hangzhou.aliyuncs.com/google_containers/kubernetes-dashboard-amd64:v1.10.0</span><br><span class=\"line\">        ports:</span><br><span class=\"line\">        - containerPort: 8443</span><br><span class=\"line\">          protocol: TCP</span><br><span class=\"line\">        args:</span><br><span class=\"line\">          - --auto-generate-certificates</span><br><span class=\"line\">        volumeMounts:</span><br><span class=\"line\">        - name: kubernetes-dashboard-certs</span><br><span class=\"line\">          mountPath: /certs</span><br><span class=\"line\">          # Create on-disk volume to store exec logs</span><br><span class=\"line\">        - mountPath: /tmp</span><br><span class=\"line\">          name: tmp-volume</span><br><span class=\"line\">        livenessProbe:</span><br><span class=\"line\">          httpGet:</span><br><span class=\"line\">            scheme: HTTPS</span><br><span class=\"line\">            path: /</span><br><span class=\"line\">            port: 8443</span><br><span class=\"line\">          initialDelaySeconds: 30</span><br><span class=\"line\">          timeoutSeconds: 30</span><br><span class=\"line\">      volumes:</span><br><span class=\"line\">      - name: kubernetes-dashboard-certs</span><br><span class=\"line\">        secret:</span><br><span class=\"line\">          secretName: kubernetes-dashboard-certs</span><br><span class=\"line\">      - name: tmp-volume</span><br><span class=\"line\">        emptyDir: &#123;&#125;</span><br><span class=\"line\">      serviceAccountName: kubernetes-dashboard</span><br><span class=\"line\">      tolerations:</span><br><span class=\"line\">      - key: node-role.kubernetes.io/master</span><br><span class=\"line\">        effect: NoSchedule</span><br><span class=\"line\">---</span><br><span class=\"line\">kind: Service</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    k8s-app: kubernetes-dashboard</span><br><span class=\"line\">  name: kubernetes-dashboard</span><br><span class=\"line\">  namespace: kube-system</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  ports:</span><br><span class=\"line\">    - port: 443</span><br><span class=\"line\">      targetPort: 8443</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    k8s-app: kubernetes-dashboard</span><br><span class=\"line\">---</span><br><span class=\"line\"># 配置 ingress 配置，待会部署完 ingress 之后，就可以通过以下配置的域名访问</span><br><span class=\"line\">apiVersion: extensions/v1beta1</span><br><span class=\"line\">kind: Ingress</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: dashboard-ingress</span><br><span class=\"line\">  namespace: kube-system</span><br><span class=\"line\">  annotations:</span><br><span class=\"line\">    # 如果通过 HTTP 访问，跳转到 HTTPS</span><br><span class=\"line\">    nginx.ingress.kubernetes.io/ssl-redirect: &quot;true&quot;</span><br><span class=\"line\">    nginx.ingress.kubernetes.io/rewrite-target: /</span><br><span class=\"line\">    # 指定转发协议为 HTTPS，因为 ingress 默认转发协议是 HTTP，而 kubernetes-dashboard 默认是 HTTPS</span><br><span class=\"line\">    nginx.ingress.kubernetes.io/backend-protocol: &quot;HTTPS&quot;</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  # 指定使用的 secret (刚刚创建的 secret)</span><br><span class=\"line\">  tls:</span><br><span class=\"line\">   - secretName: secret-ca-tf-k8s-xiangwushuo-com</span><br><span class=\"line\">  rules:</span><br><span class=\"line\">  # 指定访问 dashboard 的域名</span><br><span class=\"line\">  - host: dashboard.tf-k8s.xiangwushuo.com</span><br><span class=\"line\">    http:</span><br><span class=\"line\">      paths:</span><br><span class=\"line\">      - path: /</span><br><span class=\"line\">        backend:</span><br><span class=\"line\">          serviceName: kubernetes-dashboard</span><br><span class=\"line\">          servicePort: 443</span><br></pre></td></tr></table></figure>\n<p>执行部署 kubernetes-dashboard，命令 kubectl apply -f kubernetes-dashboard.yaml.</p>\n<p>在本地笔记本电脑上访问dashboard的时候，需要将dashboard.tf-k8s.xiangwushuo.com域名解析到三台master的IP（配置代理），简单地，可以直接在本地/etc/hosts添加</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">## 172.66.23.13 为tf-k8s-m1的外网IP</span><br><span class=\"line\">172.66.23.13 dashboard.tf-k8s.xiangwushuo.com</span><br></pre></td></tr></table></figure>\n<p>从浏览器访问: <a href=\"http://dashboard.tf-k8s.xiangwushuo.com\" target=\"_blank\" rel=\"noopener\">http://dashboard.tf-k8s.xiangwushuo.com</a><br><img src=\"/images/dashboard-login.png\" alt=\"\"></p>\n<h4 id=\"2-9-2-HTTPS-访问-Dashboard\"><a href=\"#2-9-2-HTTPS-访问-Dashboard\" class=\"headerlink\" title=\"2.9.2 HTTPS 访问 Dashboard\"></a>2.9.2 HTTPS 访问 Dashboard</h4><p>由于通过 HTTP 访问 dashboard 会无法登录进去 dashboard 的问题，所以这里我们将 dashboard 的服务配置成 HTTPS 进行访问。<br>总共三步:<br>签证书（或者使用权威的证书机构颁发的证书）</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">openssl req -x509 -nodes -days 3650 -newkey rsa:2048 -keyout ./tf-k8s.xiangwushuo.com.key -out ./tf-k8s.xiangwushuo.com.crt -subj &quot;/CN=*.xiangwushuo.com&quot;</span><br></pre></td></tr></table></figure>\n<p>创建 k8s Secret 资源</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl -n kube-system create secret tls secret-ca-tf-k8s-xiangwushuo-com --key ./tf-k8s.xiangwushuo.com.key --cert tf-k8s.xiangwushuo.com.crt</span><br></pre></td></tr></table></figure>\n<p>配置 dashboard 的 ingress 为 HTTPS 访问服务,修改 kubernetes-dashboard.yaml，将其中的 Ingress 配置改为支持 HTTPS，具体配置如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">...省略...</span><br><span class=\"line\"></span><br><span class=\"line\">apiVersion: extensions/v1beta1</span><br><span class=\"line\">kind: Ingress</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: dashboard-ingress</span><br><span class=\"line\">  namespace: kube-system</span><br><span class=\"line\">  annotations:</span><br><span class=\"line\">    # 如果通过 HTTP 访问，跳转到 HTTPS</span><br><span class=\"line\">    nginx.ingress.kubernetes.io/ssl-redirect: &quot;true&quot;</span><br><span class=\"line\">    nginx.ingress.kubernetes.io/rewrite-target: /</span><br><span class=\"line\">    # 指定转发协议为 HTTPS，因为 ingress 默认转发协议是 HTTP，而 kubernetes-dashboard 默认是 HTTPS</span><br><span class=\"line\">    nginx.ingress.kubernetes.io/backend-protocol: &quot;HTTPS&quot;</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  # 指定使用的 secret (刚刚创建的 secret)</span><br><span class=\"line\">  tls:</span><br><span class=\"line\">   - secretName: secret-ca-k8s-hiko-im</span><br><span class=\"line\">  rules:</span><br><span class=\"line\">  # 指定访问 dashboard 的域名</span><br><span class=\"line\">  - host: dashboard.k8s.hiko.im</span><br><span class=\"line\">    http:</span><br><span class=\"line\">      paths:</span><br><span class=\"line\">      - path: /</span><br><span class=\"line\">        backend:</span><br><span class=\"line\">          serviceName: kubernetes-dashboard</span><br><span class=\"line\">          servicePort: 443</span><br></pre></td></tr></table></figure>\n<p>使用 kubectl apply -f kubernetes-dashboard.yaml 让配置生效。</p>\n<h4 id=\"2-9-3-3-登录-Dashboard\"><a href=\"#2-9-3-3-登录-Dashboard\" class=\"headerlink\" title=\"2.9.3 .3 登录 Dashboard\"></a>2.9.3 .3 登录 Dashboard</h4><p>登录 dashboard 需要做几个事情（不用担心，一个脚本搞定）:</p>\n<p>新建 sa 的账号（也叫 serviceaccount）<br>集群角色绑定（将第 1 步新建的账号，绑定到 cluster-admin 这个角色上）<br>查看 Token 以及 Token 中的 secrect （secrect 中的 token 字段就是来登录的）<br>执行以下脚本，获得登录的 Token:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">## 创建脚本：create.dashboard.token.sh</span><br><span class=\"line\"></span><br><span class=\"line\">#!/bin/sh</span><br><span class=\"line\"></span><br><span class=\"line\">kubectl create sa dashboard-admin -n kube-system</span><br><span class=\"line\">kubectl create clusterrolebinding dashboard-admin --clusterrole=cluster-admin --serviceaccount=kube-system:dashboard-admin</span><br><span class=\"line\">ADMIN_SECRET=$(kubectl get secrets -n kube-system | grep dashboard-admin | awk &apos;&#123;print $1&#125;&apos;)</span><br><span class=\"line\">DASHBOARD_LOGIN_TOKEN=$(kubectl describe secret -n kube-system $&#123;ADMIN_SECRET&#125; | grep -E &apos;^token&apos; | awk &apos;&#123;print $2&#125;&apos;)</span><br><span class=\"line\">echo $&#123;DASHBOARD_LOGIN_TOKEN&#125;</span><br></pre></td></tr></table></figure>\n<p>复制 Token 去登录就行，Token 样例：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJkYXNoYm9hcmQtYWRtaW4tdG9rZW4tNWtnZHoiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoiZGFzaGJvYXJkLWFkbWluIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiYWQxNDAyMjQtMDYxNC0xMWU5LTkxMDgtNTI1NDAwODQ4MWQ1Iiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmUtc3lzdGVtOmRhc2hib2FyZC1hZG1pbiJ9.ry4xYI6TFF6J8xXsilu0qhuBeRjSNqVPq3OUzl62Ad3e2wM-biC5pPlKNmJLfJzurxnQrqp59VjmVeTA8BZiF7S6hqlrk8XE9_LFlItUvq3rp5wFuhJuVol8Yoi4UJFzUYQF6baH0O3R10aK33g2WmWLIg79OFAkeMMHrLthbL2pc_p_kG13_qDXlEuVgnIAFsKzxnrCCUfZ2GwGsHEFEqTGBCb0u6x3AZqfQgbN3DALkjjNTyTLP5Ok-LJ3Ug8SZZQBksvTeXCGXZDfk2LDDIvp_DyM7nTL3CTT5cQ3g4aBTFAae47NAkQkmjZg0mxvJH0xVnxrvXLND8FLLkzMxg</span><br></pre></td></tr></table></figure>\n<h2 id=\"3-参考文献\"><a href=\"#3-参考文献\" class=\"headerlink\" title=\"3. 参考文献\"></a>3. 参考文献</h2><p><a href=\"https://www.ctolib.com/HikoQiu-kubeadm-install-k8s.html\" target=\"_blank\" rel=\"noopener\">1. kubeadm 1.13 安装高可用 kubernetes v1.13.1 集群</a><br><a href=\"https://www.jianshu.com/p/39d7000dfa47\" target=\"_blank\" rel=\"noopener\">2. 如何在CentOS 7上修改主机名</a><br><a href=\"https://blog.csdn.net/mmd0308/article/details/73825953\" target=\"_blank\" rel=\"noopener\">3. Linux之ssh免密登录</a><br><a href=\"http://blog.51cto.com/chenfage/1830424\" target=\"_blank\" rel=\"noopener\">4. sudo与visudo的超细用法说明</a><br><a href=\"https://www.kubernetes.org.cn/4948.html\" target=\"_blank\" rel=\"noopener\">5. kubeadm HA master(v1.13.0)离线包 + 自动化脚本 + 常用插件 For Centos/Fedora</a><br><a href=\"https://github.com/coreos/flannel\" target=\"_blank\" rel=\"noopener\">6. github.coreos.flannel</a><br><a href=\"https://jimmysong.io/kubernetes-handbook/\" target=\"_blank\" rel=\"noopener\">7. Kubernetes Handbook——Kubernetes中文指南/云原生应用架构实践手册</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>[TOC]</p>\n<h2 id=\"一、环境准备\"><a href=\"#一、环境准备\" class=\"headerlink\" title=\"一、环境准备\"></a>一、环境准备</h2><h3 id=\"1-1-硬件设备环境\"><a href=\"#1-1-硬件设备环境\" class=\"headerlink\" title=\"1.1 硬件设备环境\"></a>1.1 硬件设备环境</h3><p>采用5台腾讯云的CVM作为kubernetes的部署环境，具体信息如下：</p>\n<table>\n<thead>\n<tr>\n<th>主机名</th>\n<th>IP</th>\n<th>配置</th>\n<th>备注</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>（Old）VM_0_1_centos；（New）tf-k8s-m1</td>\n<td>10.0.0.1</td>\n<td>4c 8g</td>\n<td>k8s的master，同时也是etcd节点</td>\n</tr>\n<tr>\n<td>（Old）VM_0_2_centos；（New）tf-k8s-m2</td>\n<td>10.0.0.2</td>\n<td>4c 8g</td>\n<td>k8s的master，同时也是etcd节点</td>\n</tr>\n<tr>\n<td>（Old）VM_0_3_centos；（New）tf-k8s-m3</td>\n<td>10.0.0.3</td>\n<td>4c 8g</td>\n<td>k8s的master，同时也是etcd节点</td>\n</tr>\n<tr>\n<td>（Old）VM_0_4_centos；（New）tf-k8s-n1</td>\n<td>10.0.0.4</td>\n<td>4c 8g</td>\n<td>工作节点 node，容器编排最终 pod 工作节点</td>\n</tr>\n<tr>\n<td>（Old）VM_0_5_centos；（New）tf-k8s-n2</td>\n<td>10.0.0.5</td>\n<td>4c 8g</td>\n<td>工作节点 node，容器编排最终 pod 工作节点</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"1-2-软件环境\"><a href=\"#1-2-软件环境\" class=\"headerlink\" title=\"1.2 软件环境\"></a>1.2 软件环境</h3><table>\n<thead>\n<tr>\n<th>环境</th>\n<th>简介</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>操作系统</td>\n<td>CentOS7</td>\n</tr>\n<tr>\n<td>kubeadm</td>\n<td>1.13.3</td>\n</tr>\n<tr>\n<td>kubernetes</td>\n<td>1.13.3</td>\n</tr>\n<tr>\n<td>Docker</td>\n<td>docker-ce 18.06.2</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"1-3-相关系统设置\"><a href=\"#1-3-相关系统设置\" class=\"headerlink\" title=\"1.3 相关系统设置\"></a>1.3 相关系统设置</h3><p>在正式安装之前，需要在每台机器上对以下配置进行修改：</p>\n<ul>\n<li>关闭防火墙，selinux</li>\n<li>关闭系统的swap功能</li>\n<li>关闭Linux swap空间的swappiness</li>\n<li>配置L2网桥在转发包时会被iptables的FORWARD规则所过滤，该配置被CNI插件需要，更多信息请参考<a href=\"https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/#network-plugin-requirements\" target=\"_blank\" rel=\"noopener\">Network Plugin Requirements</a></li>\n<li>升级内核到最新（centos7 默认的内核是3.10.0-862.el7.x86_64 ,可以使用命令‘uname -a’进行查看），原因见<a href=\"https://github.com/Lentil1016/kubeadm-ha/issues/19\" target=\"_blank\" rel=\"noopener\">请问下为什么要用4.18版本内核</a></li>\n<li>开启IPVS</li>\n<li>修改主机名（如果主机名中含有一些特殊字符，则需要调整主机名，不然在后续操作中会出现错误）<br>具体的配置修改执行脚本如下：</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># ---------- 关闭防火墙和selinux -----------</span><br><span class=\"line\">systemctl stop firewalld</span><br><span class=\"line\">systemctl disable firewalld</span><br><span class=\"line\">setenforce 0</span><br><span class=\"line\">sed -i &quot;s/SELINUX=enforcing/SELINUX=disabled/g&quot; /etc/selinux/config</span><br><span class=\"line\"></span><br><span class=\"line\"># ---------- 关闭交换分区 -----------</span><br><span class=\"line\">swapoff -a</span><br><span class=\"line\">yes | cp /etc/fstab /etc/fstab_bak</span><br><span class=\"line\">cat /etc/fstab_bak |grep -v swap &gt; /etc/fstab</span><br><span class=\"line\"></span><br><span class=\"line\"># ---------- 设置网桥包经IPTables，core文件生成路径 -----------</span><br><span class=\"line\">echo &quot;&quot;&quot;</span><br><span class=\"line\">vm.swappiness = 0</span><br><span class=\"line\">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class=\"line\">net.bridge.bridge-nf-call-iptables = 1</span><br><span class=\"line\">&quot;&quot;&quot; &gt; /etc/sysctl.conf</span><br><span class=\"line\">modprobe br_netfilter</span><br><span class=\"line\">sysctl -p</span><br><span class=\"line\"></span><br><span class=\"line\"># ---------- 同步时间 -----------</span><br><span class=\"line\">yum install -y ntpdate</span><br><span class=\"line\">ntpdate -u ntp.api.bz</span><br><span class=\"line\"></span><br><span class=\"line\"># ---------- 升级内核 -----------</span><br><span class=\"line\">rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-2.el7.elrepo.noarch.rpm ;yum --enablerepo=elrepo-kernel install kernel-ml-devel kernel-ml -y</span><br><span class=\"line\"># 查看启动配置里是否有最新的内核</span><br><span class=\"line\">cat /boot/grub2/grub.cfg | grep menuentry</span><br><span class=\"line\"># 修改默认启动项</span><br><span class=\"line\">grub2-set-default 0</span><br><span class=\"line\"># 检查默认内核版本是否大于4.14，否则请调整默认启动参数</span><br><span class=\"line\">grub2-editenv list</span><br><span class=\"line\">#重启以更换内核</span><br><span class=\"line\">reboot</span><br><span class=\"line\">#查看内核信息</span><br><span class=\"line\">uname -a</span><br><span class=\"line\"></span><br><span class=\"line\"># ---------- 确认内核版本后，开启IPVS -----------</span><br><span class=\"line\">uname -a</span><br><span class=\"line\">cat &gt; /etc/sysconfig/modules/ipvs.modules &lt;&lt;EOF</span><br><span class=\"line\">#!/bin/bash</span><br><span class=\"line\">ipvs_modules=&quot;ip_vs ip_vs_lc ip_vs_wlc ip_vs_rr ip_vs_wrr ip_vs_lblc ip_vs_lblcr ip_vs_dh ip_vs_sh ip_vs_fo ip_vs_nq ip_vs_sed ip_vs_ftp nf_conntrack&quot;</span><br><span class=\"line\">for kernel_module in \\$&#123;ipvs_modules&#125;; do</span><br><span class=\"line\"> /sbin/modinfo -F filename \\$&#123;kernel_module&#125; &gt; /dev/null 2&gt;&amp;1</span><br><span class=\"line\"> if [ $? -eq 0 ]; then</span><br><span class=\"line\"> /sbin/modprobe \\$&#123;kernel_module&#125;</span><br><span class=\"line\"> fi</span><br><span class=\"line\">done</span><br><span class=\"line\">EOF</span><br><span class=\"line\">chmod 755 /etc/sysconfig/modules/ipvs.modules &amp;&amp; bash /etc/sysconfig/modules/ipvs.modules &amp;&amp; lsmod | grep ip_vs</span><br><span class=\"line\"></span><br><span class=\"line\"># ---------- 修改主机名 -----------</span><br><span class=\"line\"># 这里以VM_0_17_centos主机为例，其他的主机分别修改成相应的主机名</span><br><span class=\"line\">hostnamectl set-hostname tf-k8s-m1</span><br></pre></td></tr></table></figure>\n<h3 id=\"1-3-配置集群内各个机器之间的免密码登录\"><a href=\"#1-3-配置集群内各个机器之间的免密码登录\" class=\"headerlink\" title=\"1.3 配置集群内各个机器之间的免密码登录\"></a>1.3 配置集群内各个机器之间的免密码登录</h3><h4 id=\"1-3-1-配置hosts\"><a href=\"#1-3-1-配置hosts\" class=\"headerlink\" title=\"1.3.1 配置hosts\"></a>1.3.1 配置hosts</h4><p>为了便于后续的操作，我们需要给每一台设备配置下hosts域名信息，具体如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># vi /etc/hosts</span><br><span class=\"line\">10.0.0.1 tf-k8s-m1 api.tf-k8s.xiangwushuo.com</span><br><span class=\"line\">10.0.0.2 tf-k8s-m2</span><br><span class=\"line\">10.0.0.3 tf-k8s-m3</span><br><span class=\"line\">10.0.0.4 tf-k8s-n1</span><br><span class=\"line\">10.0.0.5 tf-k8s-n2</span><br><span class=\"line\">10.0.0.1 dashboard.tf-k8s.xiangwushuo.com</span><br></pre></td></tr></table></figure>\n<h4 id=\"1-3-2-新建用户\"><a href=\"#1-3-2-新建用户\" class=\"headerlink\" title=\"1.3.2 新建用户\"></a>1.3.2 新建用户</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># useradd kube</span><br><span class=\"line\"># visudo</span><br><span class=\"line\">%wheel  ALL=(ALL)       ALL</span><br><span class=\"line\">kube    ALL=(ALL)       NOPASSWD:ALL</span><br></pre></td></tr></table></figure>\n<p>备注：visudo命令是用来给kube用户添加sudo密码</p>\n<h4 id=\"1-3-3-设置免密登录\"><a href=\"#1-3-3-设置免密登录\" class=\"headerlink\" title=\"1.3.3 设置免密登录\"></a>1.3.3 设置免密登录</h4><ol>\n<li>各个设备的root用户&amp;kube用户（不同用户配置不同的）都生成各自的免密登录的ssh的私钥与公钥</li>\n</ol>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">## 为root用户生成ssh的私钥与公钥</span><br><span class=\"line\">ssh-keygen</span><br></pre></td></tr></table></figure>\n<p>在/root目录下，会生成一个.ssh目录，.ssh目录下会生成以下三个文件：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">-rw------- 1 root root 2398 Feb 13 15:18 authorized_keys</span><br><span class=\"line\">-rw------- 1 root root 1679 Feb 13 14:47 id_rsa</span><br><span class=\"line\">-rw-r--r-- 1 root root  401 Feb 13 14:47 id_rsa.pub</span><br></pre></td></tr></table></figure>\n<p>authorized_keys文件存储了本设备认证授权的其他设备的公钥信息；id_rsa存储了本设备的私钥信息；id_rsa.pub存储了本设备的公钥信息。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">## 为kube用户生成ssh的私钥与公钥</span><br><span class=\"line\">su kube</span><br><span class=\"line\">ssh-keygen</span><br></pre></td></tr></table></figure>\n<p>在/home/kube目录下，会生成一个.ssh目录，并包含相关文件。</p>\n<ol start=\"2\">\n<li>各个设备上都创建好各自的ssh免密登录公钥与私钥后，需要将各自的公钥copy至其他的设备上，并将公钥信息添加到各个设备的authorized_keys文件中。<br>备注：也需要将各个节点自己的公钥copy至自己的authorized_keys文件中，这样自己才可以ssh自己。</li>\n</ol>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">## 将每一台节点上的公钥都同步到相应的目录下</span><br><span class=\"line\"># ll</span><br><span class=\"line\">-rw-r--r-- 1 root root  401 Feb 13 15:15 tf-k8s-m1-id_rsa.pub</span><br><span class=\"line\">-rw-r--r-- 1 root root  401 Feb 13 15:15 tf-k8s-m2-id_rsa.pub</span><br><span class=\"line\">-rw-r--r-- 1 root root  401 Feb 13 15:15 tf-k8s-m3-id_rsa.pub</span><br><span class=\"line\">-rw-r--r-- 1 root root  401 Feb 13 15:15 tf-k8s-n1-id_rsa.pub</span><br><span class=\"line\">-rw-r--r-- 1 root root  401 Feb 13 15:15 tf-k8s-n2-id_rsa.pub</span><br><span class=\"line\">## 将每台节点的公钥追加至authorized_keys文件中</span><br><span class=\"line\">cat tf-k8s-m1-id_rsa.pub &gt; authorized_keys</span><br><span class=\"line\">cat tf-k8s-m2-id_rsa.pub &gt; authorized_keys</span><br><span class=\"line\">cat tf-k8s-m3-id_rsa.pub &gt; authorized_keys</span><br><span class=\"line\">cat tf-k8s-n1-id_rsa.pub &gt; authorized_keys</span><br><span class=\"line\">cat tf-k8s-n2-id_rsa.pub &gt; authorized_keys</span><br></pre></td></tr></table></figure>\n<p>测试是否能够正常使用ssh免密登录</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ssh root@tf-k8s-m1</span><br><span class=\"line\">ssh root@tf-k8s-m2</span><br><span class=\"line\">ssh root@tf-k8s-m3</span><br><span class=\"line\">ssh root@tf-k8s-n1</span><br><span class=\"line\">ssh root@tf-k8s-n2</span><br></pre></td></tr></table></figure>\n<p><strong>提示</strong>：如果其他机器上的 root 下的 /root/.ssh/authorized_keys 不存在，可以手动创建。要注意的是：authorized_keys 的权限需要是 600。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">## 如果 authorized_keys 的权限不是 600，执行修改权限的命令。</span><br><span class=\"line\">chmod 600 authorized_keys</span><br></pre></td></tr></table></figure>\n<h2 id=\"二、安装步骤\"><a href=\"#二、安装步骤\" class=\"headerlink\" title=\"二、安装步骤\"></a>二、安装步骤</h2><p>以下操作，可以都切换至kube用户下进行操作。</p>\n<h3 id=\"2-1-安装docker\"><a href=\"#2-1-安装docker\" class=\"headerlink\" title=\"2.1 安装docker\"></a>2.1 安装docker</h3><p>由于kubeadm的ha模式对docker的版本是有一定的要求的，因此，本教程中安装官方推荐的docker版本。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 安装依赖包</span><br><span class=\"line\">yum install -y yum-utils device-mapper-persistent-data lvm2</span><br><span class=\"line\"></span><br><span class=\"line\"># 添加Docker软件包源</span><br><span class=\"line\">yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo</span><br><span class=\"line\"></span><br><span class=\"line\">#关闭测试版本list（只显示稳定版）</span><br><span class=\"line\">sudo yum-config-manager --enable docker-ce-edge</span><br><span class=\"line\">sudo yum-config-manager --enable docker-ce-test</span><br><span class=\"line\"></span><br><span class=\"line\"># 更新yum包索引</span><br><span class=\"line\">yum makecache fast</span><br><span class=\"line\"></span><br><span class=\"line\">#NO.1 指定版本安装</span><br><span class=\"line\">yum list docker-ce --showduplicates|sort -r  </span><br><span class=\"line\">yum install docker-ce-18.06.2.ce -y</span><br></pre></td></tr></table></figure>\n<p>为了方便操作，我们在tf-k8s-m1节点上，创建一个批量部署docker的脚本。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">## 创建install.docker.sh</span><br><span class=\"line\"></span><br><span class=\"line\">#!/bin/sh</span><br><span class=\"line\"></span><br><span class=\"line\">vhosts=&quot;tf-k8s-m1 tf-k8s-m2 tf-k8s-m3 tf-k8s-n1 tf-k8s-n2&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">for h in $vhosts</span><br><span class=\"line\">do</span><br><span class=\"line\">    echo &quot;Install docker for $h&quot;</span><br><span class=\"line\">    ssh kube@$h &quot;sudo yum install docker-ce-18.06.2.ce -y &amp;&amp; sudo systemctl enable docker &amp;&amp; systemctl start docker&quot;</span><br><span class=\"line\">done</span><br></pre></td></tr></table></figure>\n<p>执行install.docker.sh脚本</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">chmod a+x install.docker.sh</span><br><span class=\"line\">sh ./install.docker.sh</span><br></pre></td></tr></table></figure>\n<h3 id=\"2-2-安装kubernetes-yum源和kubelet、kubeadm、kubectl组件\"><a href=\"#2-2-安装kubernetes-yum源和kubelet、kubeadm、kubectl组件\" class=\"headerlink\" title=\"2.2 安装kubernetes yum源和kubelet、kubeadm、kubectl组件\"></a>2.2 安装kubernetes yum源和kubelet、kubeadm、kubectl组件</h3><h4 id=\"2-2-1-所有机器上配置-kubernetes-repo-yum-源\"><a href=\"#2-2-1-所有机器上配置-kubernetes-repo-yum-源\" class=\"headerlink\" title=\"2.2.1 所有机器上配置 kubernetes.repo yum 源\"></a>2.2.1 所有机器上配置 kubernetes.repo yum 源</h4><p>详细的安装脚本如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">## 创建脚本：install.k8s.repo.sh</span><br><span class=\"line\"></span><br><span class=\"line\">#!/bin/sh</span><br><span class=\"line\"></span><br><span class=\"line\">vhost=&quot;tf-k8s-m1 tf-k8s-m2 tf-k8s-m3 tf-k8s-n1 tf-k8s-n2&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">## 设置为阿里云 kubernetes 仓库</span><br><span class=\"line\">cat &lt;&lt;EOF &gt; kubernetes.repo</span><br><span class=\"line\">[kubernetes]</span><br><span class=\"line\">name=Kubernetes</span><br><span class=\"line\">baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/</span><br><span class=\"line\">enabled=1</span><br><span class=\"line\">gpgcheck=1</span><br><span class=\"line\">repo_gpgcheck=1</span><br><span class=\"line\">gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg</span><br><span class=\"line\">EOF</span><br><span class=\"line\"></span><br><span class=\"line\">mvCmd=&quot;sudo cp ~/kubernetes.repo /etc/yum.repos.d/&quot;</span><br><span class=\"line\">for h in $vhost</span><br><span class=\"line\">do</span><br><span class=\"line\">  echo &quot;Setup kubernetes repository for $h&quot;</span><br><span class=\"line\">  scp ./kubernetes.repo kube@$h:~</span><br><span class=\"line\">  ssh kube@$h $mvCmd</span><br><span class=\"line\">done</span><br></pre></td></tr></table></figure>\n<p>执行install.k8s.repo.sh脚本</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">chmod a+x install.k8s.repo.sh</span><br><span class=\"line\">sh ./install.k8s.repo.sh</span><br></pre></td></tr></table></figure>\n<h4 id=\"2-2-2-所有机器上安装-kubelet、kubeadm、kubectl组件\"><a href=\"#2-2-2-所有机器上安装-kubelet、kubeadm、kubectl组件\" class=\"headerlink\" title=\"2.2.2 所有机器上安装 kubelet、kubeadm、kubectl组件\"></a>2.2.2 所有机器上安装 kubelet、kubeadm、kubectl组件</h4><p>详细安装脚本如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">## 创建脚本：install.k8s.basic.sh</span><br><span class=\"line\"></span><br><span class=\"line\">#!/bin/sh</span><br><span class=\"line\"></span><br><span class=\"line\">vhost=&quot;tf-k8s-m1 tf-k8s-m2 tf-k8s-m3 tf-k8s-n1 tf-k8s-n2&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">## 安装 kubelet kubeadm kubectl</span><br><span class=\"line\">installCmd=&quot;sudo yum install -y kubelet kubeadm kubectl &amp;&amp; sudo systemctl enable kubelet&quot;</span><br><span class=\"line\">for h in $vhost</span><br><span class=\"line\">do</span><br><span class=\"line\">  echo &quot;Install kubelet kubeadm kubectl for : $h&quot;</span><br><span class=\"line\">  ssh kube@$h $installCmd</span><br><span class=\"line\">done</span><br></pre></td></tr></table></figure>\n<p>执行install.k8s.baisc.sh脚本</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">chmod a+x install.k8s.basic.sh</span><br><span class=\"line\">sh ./install.k8s.basic.sh</span><br></pre></td></tr></table></figure>\n<h3 id=\"2-3-初始化kubeadm配置文件\"><a href=\"#2-3-初始化kubeadm配置文件\" class=\"headerlink\" title=\"2.3 初始化kubeadm配置文件\"></a>2.3 初始化kubeadm配置文件</h3><p>创建三台master机器tf-k8s-m1,tf-k8s-m2,tf-k8s-m3的kubeadm配置文件，其中主要是配置生成证书的域配置、etcd集群配置。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">## 创建脚本：init.kubeadm.config.sh</span><br><span class=\"line\"></span><br><span class=\"line\">#!/bin/sh</span><br><span class=\"line\"></span><br><span class=\"line\">## 1. 配置参数 </span><br><span class=\"line\">## vhost 主机名和 vhostIP IP 一一对应</span><br><span class=\"line\">vhost=(tf-k8s-m1 tf-k8s-m2 tf-k8s-m3)</span><br><span class=\"line\">vhostIP=(10.0.0.1 10.0.0.2 10.0.0.3)</span><br><span class=\"line\"></span><br><span class=\"line\">domain=api.tf-k8s.xiangwushuo.com</span><br><span class=\"line\"></span><br><span class=\"line\">## etcd 初始化 m01 m02 m03 集群配置</span><br><span class=\"line\">etcdInitCluster=(</span><br><span class=\"line\">tf-k8s-m1=https://10.0.0.1:2380</span><br><span class=\"line\">tf-k8s-m1=https://10.0.0.1:2380,tf-k8s-m2=https://10.0.0.2:2380</span><br><span class=\"line\">tf-k8s-m1=https://10.0.0.1:2380,tf-k8s-m2=https://10.0.0.2:2380,tf-k8s-m3=https://10.0.0.3:2380</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">## etcd 初始化时，m01 m02 m03 分别的初始化集群状态</span><br><span class=\"line\">initClusterStatus=(</span><br><span class=\"line\">new</span><br><span class=\"line\">existing</span><br><span class=\"line\">existing</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">## 2.遍历 master 主机名和对应 IP</span><br><span class=\"line\">## 生成对应的 kubeadmn 配置文件 </span><br><span class=\"line\">for i in `seq 0 $(($&#123;#vhost[*]&#125;-1))`</span><br><span class=\"line\">do</span><br><span class=\"line\"></span><br><span class=\"line\">h=$&#123;vhost[$&#123;i&#125;]&#125; </span><br><span class=\"line\">ip=$&#123;vhostIP[$&#123;i&#125;]&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">echo &quot;--&gt; $h - $ip&quot;</span><br><span class=\"line\">  </span><br><span class=\"line\">## 生成 kubeadm 配置模板</span><br><span class=\"line\">cat &lt;&lt;EOF &gt; kubeadm-config.$h.yaml</span><br><span class=\"line\">apiVersion: kubeadm.k8s.io/v1beta1</span><br><span class=\"line\">kind: InitConfiguration</span><br><span class=\"line\">localAPIEndpoint:</span><br><span class=\"line\">  advertiseAddress: $ip</span><br><span class=\"line\">  bindPort: 6443</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: kubeadm.k8s.io/v1beta1</span><br><span class=\"line\">kind: ClusterConfiguration</span><br><span class=\"line\">kubernetesVersion: v1.13.3</span><br><span class=\"line\"></span><br><span class=\"line\"># 指定阿里云镜像仓库</span><br><span class=\"line\">imageRepository: registry.aliyuncs.com/google_containers</span><br><span class=\"line\"></span><br><span class=\"line\"># apiServerCertSANs 填所有的 masterip、lbip、其它可能需要通过它访问 apiserver 的地址、域名或主机名等，</span><br><span class=\"line\"># 如阿里fip，证书中会允许这些ip</span><br><span class=\"line\"># 这里填一个自定义的域名</span><br><span class=\"line\">apiServer:</span><br><span class=\"line\">  certSANs:</span><br><span class=\"line\">  - &quot;$domain&quot;</span><br><span class=\"line\">controlPlaneEndpoint: &quot;$domain:6443&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">## Etcd 配置</span><br><span class=\"line\">etcd:</span><br><span class=\"line\">  local:</span><br><span class=\"line\">    extraArgs:</span><br><span class=\"line\">      listen-client-urls: &quot;https://127.0.0.1:2379,https://$ip:2379&quot;</span><br><span class=\"line\">      advertise-client-urls: &quot;https://$ip:2379&quot;</span><br><span class=\"line\">      listen-peer-urls: &quot;https://$ip:2380&quot;</span><br><span class=\"line\">      initial-advertise-peer-urls: &quot;https://$ip:2380&quot;</span><br><span class=\"line\">      initial-cluster: &quot;$&#123;etcdInitCluster[$&#123;i&#125;]&#125;&quot;</span><br><span class=\"line\">      initial-cluster-state: $&#123;initClusterStatus[$&#123;i&#125;]&#125;</span><br><span class=\"line\">    serverCertSANs:</span><br><span class=\"line\">      - $h</span><br><span class=\"line\">      - $ip</span><br><span class=\"line\">    peerCertSANs:</span><br><span class=\"line\">      - $h</span><br><span class=\"line\">      - $ip</span><br><span class=\"line\">networking:</span><br><span class=\"line\">  podSubnet: &quot;10.244.0.0/16&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">EOF</span><br><span class=\"line\"></span><br><span class=\"line\">echo &quot;kubeadm-config.$h.yaml created ... ok&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">## 3. 分发到其他 master 机器 </span><br><span class=\"line\">scp kubeadm-config.$h.yaml kube@$h:~</span><br><span class=\"line\">echo &quot;scp kubeadm-config.$h.yaml ... ok&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">done</span><br></pre></td></tr></table></figure>\n<p>执行init.kubeadm.config.sh脚本</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">chmod a+x init.kubeadm.config.sh</span><br><span class=\"line\">sh ./init.kubeadm.config.sh</span><br></pre></td></tr></table></figure>\n<p>执行成功之后，可以在tf-k8s-m1, tf-k8s-m2, tf-k8s-m3的 kube 用户的 home 目录（/home/kube）能看到对应的 kubeadm-config.tf-k8s-m1*.yaml 配置文件。 这个配置文件主要是用于后续初始化集群其他 master 的证书、 etcd 配置、kubelet 配置、kube-apiserver配置、kube-controller-manager 配置等。<br>各个master节点上对应的kubeadm配置文件：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cvm tf-k8s-m1：kubeadm-config.tf-k8s-m1.yaml</span><br><span class=\"line\">cvm tf-k8s-m2：kubeadm-config.tf-k8s-m2.yaml</span><br><span class=\"line\">cvm tf-k8s-m3：kubeadm-config.tf-k8s-m3.yaml</span><br></pre></td></tr></table></figure>\n<h3 id=\"2-4-安装master镜像和执行kubeadm初始化\"><a href=\"#2-4-安装master镜像和执行kubeadm初始化\" class=\"headerlink\" title=\"2.4 安装master镜像和执行kubeadm初始化\"></a>2.4 安装master镜像和执行kubeadm初始化</h3><h4 id=\"2-4-1-拉取镜像到本地\"><a href=\"#2-4-1-拉取镜像到本地\" class=\"headerlink\" title=\"2.4.1 拉取镜像到本地\"></a>2.4.1 拉取镜像到本地</h4><p>因为 k8s.gcr.io 国内无法访问，我们可以选择通过阿里云的镜像仓库（kubeadm-config.tf-k8s-m1*.yaml 配置文件中已经指定使用阿里云镜像仓库  registry.aliyuncs.com/google_containers），将所需的镜像 pull 到本地。<br>我们可以通过以下命令，来查看是否已经成功指定了阿里云的镜像仓库,在tf-k8s-m1机器上，通过<code>kubeadm config images list</code>命令来查看，结果如下:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[kube@tf-k8s-m1 ~]$ kubeadm config images list --config kubeadm-config.tf-k8s-m1.yaml</span><br><span class=\"line\">registry.aliyuncs.com/google_containers/kube-apiserver:v1.13.3</span><br><span class=\"line\">registry.aliyuncs.com/google_containers/kube-controller-manager:v1.13.3</span><br><span class=\"line\">registry.aliyuncs.com/google_containers/kube-scheduler:v1.13.3</span><br><span class=\"line\">registry.aliyuncs.com/google_containers/kube-proxy:v1.13.3</span><br><span class=\"line\">registry.aliyuncs.com/google_containers/pause:3.1</span><br><span class=\"line\">registry.aliyuncs.com/google_containers/etcd:3.2.24</span><br><span class=\"line\">registry.aliyuncs.com/google_containers/coredns:1.2.6</span><br></pre></td></tr></table></figure>\n<p>接下来，分别在tf-k8s-m1、tf-k8s-m2、tf-k8s-m3机器上，拉取相关镜像</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[kube@tf-k8s-m1 ~]$ sudo kubeadm config images pull --config kubeadm-config.tf-k8s-m1.yaml</span><br><span class=\"line\">[kube@tf-k8s-m2 ~]$ sudo kubeadm config images pull --config kubeadm-config.tf-k8s-m2.yaml</span><br><span class=\"line\">[kube@tf-k8s-m3 ~]$ sudo kubeadm config images pull --config kubeadm-config.tf-k8s-m3.yaml</span><br></pre></td></tr></table></figure>\n<p>执行成功后，应该能够看到本地已经拉取的镜像</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[kube@tf-k8s-m1 ~]$ sudo docker images</span><br><span class=\"line\">REPOSITORY                                                                     TAG                 IMAGE ID            CREATED             SIZE</span><br><span class=\"line\">registry.aliyuncs.com/google_containers/kube-apiserver                         v1.13.3             fe242e556a99        2 weeks ago         181MB</span><br><span class=\"line\">registry.aliyuncs.com/google_containers/kube-proxy                             v1.13.3             98db19758ad4        2 weeks ago         80.3MB</span><br><span class=\"line\">registry.aliyuncs.com/google_containers/kube-controller-manager                v1.13.3             0482f6400933        2 weeks ago         146MB</span><br><span class=\"line\">registry.aliyuncs.com/google_containers/kube-scheduler                         v1.13.3             3a6f709e97a0        2 weeks ago         79.6MB</span><br><span class=\"line\">quay.io/coreos/flannel                                                         v0.11.0-amd64       ff281650a721        2 weeks ago         52.6MB</span><br><span class=\"line\">registry.cn-hangzhou.aliyuncs.com/google_containers/nginx-ingress-controller   0.21.0              01bd760f276c        2 months ago        568MB</span><br><span class=\"line\">registry.aliyuncs.com/google_containers/coredns                                1.2.6               f59dcacceff4        3 months ago        40MB</span><br><span class=\"line\">registry.aliyuncs.com/google_containers/etcd                                   3.2.24              3cab8e1b9802        5 months ago        220MB</span><br><span class=\"line\">registry.aliyuncs.com/google_containers/pause                                  3.1                 da86e6ba6ca1        14 months ago       742kB</span><br></pre></td></tr></table></figure>\n<h4 id=\"2-4-2-安装master-tf-k8s-m1\"><a href=\"#2-4-2-安装master-tf-k8s-m1\" class=\"headerlink\" title=\"2.4.2 安装master tf-k8s-m1\"></a>2.4.2 安装master tf-k8s-m1</h4><p>我们目标是要搭建一个高可用的 master 集群，所以需要在三台 master tf-k8s-m1 tf-k8s-m2 tf-k8s-m3机器上分别通过 kubeadm 进行初始化。<br>由于 tf-k8s-m2 和 tf-k8s-m3 的初始化需要依赖 tf-k8s-m1 初始化成功后所生成的证书文件，所以这里需要先在 m01 初始化。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[kube@tf-k8s-m1 ~]$  sudo kubeadm init --config kubeadm-config.tf-k8s-m1.yaml</span><br></pre></td></tr></table></figure>\n<p>初始化成功后，会看到如下日志：<br><strong>备注：如果初始化失败，则可以通过<code>kubeadm reset --force</code>命令重置之前kubeadm init命令的执行结果，恢复一个干净的环境</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[init] Using Kubernetes version: v1.13.3</span><br><span class=\"line\">[preflight] Running pre-flight checks</span><br><span class=\"line\">[preflight] Pulling images required for setting up a Kubernetes cluster</span><br><span class=\"line\">[preflight] This might take a minute or two, depending on the speed of your internet connection</span><br><span class=\"line\">[preflight] You can also perform this action in beforehand using &apos;kubeadm config images pull&apos;</span><br><span class=\"line\">[kubelet-start] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;</span><br><span class=\"line\">[kubelet-start] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;</span><br><span class=\"line\">[kubelet-start] Activating the kubelet service</span><br><span class=\"line\">[certs] Using certificateDir folder &quot;/etc/kubernetes/pki&quot;</span><br><span class=\"line\">[certs] Generating &quot;ca&quot; certificate and key</span><br><span class=\"line\">[certs] Generating &quot;apiserver&quot; certificate and key</span><br><span class=\"line\">[certs] apiserver serving cert is signed for DNS names [m01 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local api.k8s.hiko.im api.k8s.hiko.im] and IPs [10.96.0.1 10.0.2.15]</span><br><span class=\"line\">[certs] Generating &quot;apiserver-kubelet-client&quot; certificate and key</span><br><span class=\"line\">[certs] Generating &quot;front-proxy-ca&quot; certificate and key</span><br><span class=\"line\">[certs] Generating &quot;front-proxy-client&quot; certificate and key</span><br><span class=\"line\">[certs] Generating &quot;etcd/ca&quot; certificate and key</span><br><span class=\"line\">[certs] Generating &quot;etcd/server&quot; certificate and key</span><br><span class=\"line\">[certs] etcd/server serving cert is signed for DNS names [m01 localhost m01] and IPs [10.0.2.15 127.0.0.1 ::1 192.168.33.10]</span><br><span class=\"line\">[certs] Generating &quot;etcd/peer&quot; certificate and key</span><br><span class=\"line\">[certs] etcd/peer serving cert is signed for DNS names [m01 localhost m01] and IPs [10.0.2.15 127.0.0.1 ::1 192.168.33.10]</span><br><span class=\"line\">[certs] Generating &quot;etcd/healthcheck-client&quot; certificate and key</span><br><span class=\"line\">[certs] Generating &quot;apiserver-etcd-client&quot; certificate and key</span><br><span class=\"line\">[certs] Generating &quot;sa&quot; key and public key</span><br><span class=\"line\">[kubeconfig] Using kubeconfig folder &quot;/etc/kubernetes&quot;</span><br><span class=\"line\">[kubeconfig] Writing &quot;admin.conf&quot; kubeconfig file</span><br><span class=\"line\">[kubeconfig] Writing &quot;kubelet.conf&quot; kubeconfig file</span><br><span class=\"line\">[kubeconfig] Writing &quot;controller-manager.conf&quot; kubeconfig file</span><br><span class=\"line\">[kubeconfig] Writing &quot;scheduler.conf&quot; kubeconfig file</span><br><span class=\"line\">[control-plane] Using manifest folder &quot;/etc/kubernetes/manifests&quot;</span><br><span class=\"line\">[control-plane] Creating static Pod manifest for &quot;kube-apiserver&quot;</span><br><span class=\"line\">[control-plane] Creating static Pod manifest for &quot;kube-controller-manager&quot;</span><br><span class=\"line\">[control-plane] Creating static Pod manifest for &quot;kube-scheduler&quot;</span><br><span class=\"line\">[etcd] Creating static Pod manifest for local etcd in &quot;/etc/kubernetes/manifests&quot;</span><br><span class=\"line\">[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory &quot;/etc/kubernetes/manifests&quot;. This can take up to 4m0s</span><br><span class=\"line\">[apiclient] All control plane components are healthy after 19.009523 seconds</span><br><span class=\"line\">[uploadconfig] storing the configuration used in ConfigMap &quot;kubeadm-config&quot; in the &quot;kube-system&quot; Namespace</span><br><span class=\"line\">[kubelet] Creating a ConfigMap &quot;kubelet-config-1.13&quot; in namespace kube-system with the configuration for the kubelets in the cluster</span><br><span class=\"line\">[patchnode] Uploading the CRI Socket information &quot;/var/run/dockershim.sock&quot; to the Node API object &quot;m01&quot; as an annotation</span><br><span class=\"line\">[mark-control-plane] Marking the node m01 as control-plane by adding the label &quot;node-role.kubernetes.io/master=&apos;&apos;&quot;</span><br><span class=\"line\">[mark-control-plane] Marking the node m01 as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]</span><br><span class=\"line\">[bootstrap-token] Using token: a1t7c1.mzltpc72dc3wzj9y</span><br><span class=\"line\">[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles</span><br><span class=\"line\">[bootstraptoken] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials</span><br><span class=\"line\">[bootstraptoken] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token</span><br><span class=\"line\">[bootstraptoken] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster</span><br><span class=\"line\">[bootstraptoken] creating the &quot;cluster-info&quot; ConfigMap in the &quot;kube-public&quot; namespace</span><br><span class=\"line\">[addons] Applied essential addon: CoreDNS</span><br><span class=\"line\">[addons] Applied essential addon: kube-proxy</span><br><span class=\"line\"></span><br><span class=\"line\">Your Kubernetes master has initialized successfully!</span><br><span class=\"line\"></span><br><span class=\"line\">To start using your cluster, you need to run the following as a regular user:</span><br><span class=\"line\"></span><br><span class=\"line\">  mkdir -p $HOME/.kube</span><br><span class=\"line\">  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class=\"line\">  sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class=\"line\"></span><br><span class=\"line\">You should now deploy a pod network to the cluster.</span><br><span class=\"line\">Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:</span><br><span class=\"line\">  https://kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><span class=\"line\"></span><br><span class=\"line\">You can now join any number of machines by running the following on each node</span><br><span class=\"line\">as root:</span><br><span class=\"line\"></span><br><span class=\"line\">  kubeadm join api.k8s.hiko.im:6443 --token a1t7c1.mzltpc72dc3wzj9y --discovery-token-ca-cert-hash sha256:05f44b111174613055975f012fc11fe09bdcd746bd7b3c8d99060c52619f8738</span><br></pre></td></tr></table></figure>\n<p>至此，就完成了第一台master的初始化工作。</p>\n<h4 id=\"2-4-3-kube用户配置\"><a href=\"#2-4-3-kube用户配置\" class=\"headerlink\" title=\"2.4.3 kube用户配置\"></a>2.4.3 kube用户配置</h4><p>为了让tf-k8s-m1的 kube 用户能通过 kubectl 管理集群，接着我们需要给tf-k8s-m1 的 kube 用户配置管理集群的配置。在tf-k8s-m1机器上创建config.using.cluster.sh脚本，具体如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">## 创建脚本：config.using.cluster.sh</span><br><span class=\"line\"></span><br><span class=\"line\">#!/bin/sh</span><br><span class=\"line\"></span><br><span class=\"line\"># 为 kube 用户配置</span><br><span class=\"line\">mkdir -p $HOME/.kube</span><br><span class=\"line\">sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class=\"line\">sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br></pre></td></tr></table></figure>\n<p>执行config.using.cluster.sh脚本</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">chmod a+x config.using.cluster.sh</span><br><span class=\"line\">sh ./config.using.cluster.sh</span><br></pre></td></tr></table></figure>\n<p>验证结果，通过<code>kubectl</code>命令查看集群状态，结果如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[kube@tf-k8s-m1 ~]$ kubectl cluster-info</span><br><span class=\"line\">Kubernetes master is running at https://api.tf-k8s.xiangwushuo.com:6443</span><br><span class=\"line\">KubeDNS is running at https://api.tf-k8s.xiangwushuo.com:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy</span><br><span class=\"line\"></span><br><span class=\"line\">To further debug and diagnose cluster problems, use &apos;kubectl cluster-info dump&apos;.</span><br></pre></td></tr></table></figure>\n<p>查看集群所有的pods信息，结果如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[kube@tf-k8s-m1 ~]$ kubectl get pods --all-namespaces</span><br><span class=\"line\"></span><br><span class=\"line\">NAMESPACE     NAME                          READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">kube-system   coredns-78d4cf999f-cw79l      0/1     Pending   0          47m</span><br><span class=\"line\">kube-system   coredns-78d4cf999f-w8j47      0/1     Pending   0          47m</span><br><span class=\"line\">kube-system   etcd-m01                      1/1     Running   0          47m</span><br><span class=\"line\">kube-system   kube-apiserver-m01            1/1     Running   0          46m</span><br><span class=\"line\">kube-system   kube-controller-manager-m01   1/1     Running   0          46m</span><br><span class=\"line\">kube-system   kube-proxy-5954k              1/1     Running   0          47m</span><br><span class=\"line\">kube-system   kube-scheduler-m01            1/1     Running   0          47m</span><br></pre></td></tr></table></figure>\n<p>其中，由于未安装相关的网络组件，eg:flannel,所有coredn还是显示为pending，暂时没有影响。</p>\n<h4 id=\"2-4-4-安装CNI插件flannel\"><a href=\"#2-4-4-安装CNI插件flannel\" class=\"headerlink\" title=\"2.4.4 安装CNI插件flannel\"></a>2.4.4 安装CNI插件flannel</h4><p><strong>备注：所有的节点都需要安装</strong><br>具体的安装脚本如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">## 拉取镜像</span><br><span class=\"line\">sudo docker pull quay.io/coreos/flannel:v0.11.0-amd64</span><br><span class=\"line\">## 部署</span><br><span class=\"line\">kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml</span><br></pre></td></tr></table></figure>\n<p>安装成功之后，通过 <code>kubectl get pods --all-namespaces</code>，看到所有 Pod 都正常了.</p>\n<h3 id=\"2-5-安装剩余的master\"><a href=\"#2-5-安装剩余的master\" class=\"headerlink\" title=\"2.5 安装剩余的master\"></a>2.5 安装剩余的master</h3><h4 id=\"2-5-1-同步tf-k8s-m1的ca证书\"><a href=\"#2-5-1-同步tf-k8s-m1的ca证书\" class=\"headerlink\" title=\"2.5.1 同步tf-k8s-m1的ca证书\"></a>2.5.1 同步tf-k8s-m1的ca证书</h4><p>首先，将 tf-k8s-m1 中的 ca 证书，scp 到其他 master 机器（tf-k8s-m2 tf-k8s-m3）。<br>为了方便，这里也是通过脚本来执行，具体如下：<br>注意：需要确认 tf-k8s-m1 上的 root 账号可以免密登录到 tf-k8s-m2 和 tf-k8s-m3 的 root 账号。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">## 创建脚本：sync.master.ca.sh</span><br><span class=\"line\"></span><br><span class=\"line\">#!/bin/sh</span><br><span class=\"line\"></span><br><span class=\"line\">vhost=&quot;tf-k8s-m2 tf-k8s-m3&quot;</span><br><span class=\"line\">usr=root</span><br><span class=\"line\"></span><br><span class=\"line\">who=`whoami`</span><br><span class=\"line\">if [[ &quot;$who&quot; != &quot;$usr&quot; ]];then</span><br><span class=\"line\">  echo &quot;请使用 root 用户执行或者 sudo ./sync.master.ca.sh&quot;</span><br><span class=\"line\">  exit 1</span><br><span class=\"line\">fi</span><br><span class=\"line\"></span><br><span class=\"line\">echo $who</span><br><span class=\"line\"></span><br><span class=\"line\"># 需要从 m01 拷贝的 ca 文件</span><br><span class=\"line\">caFiles=(</span><br><span class=\"line\">/etc/kubernetes/pki/ca.crt</span><br><span class=\"line\">/etc/kubernetes/pki/ca.key</span><br><span class=\"line\">/etc/kubernetes/pki/sa.key</span><br><span class=\"line\">/etc/kubernetes/pki/sa.pub</span><br><span class=\"line\">/etc/kubernetes/pki/front-proxy-ca.crt</span><br><span class=\"line\">/etc/kubernetes/pki/front-proxy-ca.key</span><br><span class=\"line\">/etc/kubernetes/pki/etcd/ca.crt</span><br><span class=\"line\">/etc/kubernetes/pki/etcd/ca.key</span><br><span class=\"line\">/etc/kubernetes/admin.conf</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">pkiDir=/etc/kubernetes/pki/etcd</span><br><span class=\"line\">for h in $vhost </span><br><span class=\"line\">do</span><br><span class=\"line\"></span><br><span class=\"line\">  ssh $&#123;usr&#125;@$h &quot;mkdir -p $pkiDir&quot;</span><br><span class=\"line\">  </span><br><span class=\"line\">  echo &quot;Dirs for ca scp created, start to scp...&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">  # scp 文件到目标机</span><br><span class=\"line\">  for f in $&#123;caFiles[@]&#125;</span><br><span class=\"line\">  do </span><br><span class=\"line\">    echo &quot;scp $f $&#123;usr&#125;@$h:$f&quot;</span><br><span class=\"line\">    scp $f $&#123;usr&#125;@$h:$f</span><br><span class=\"line\">  done</span><br><span class=\"line\"></span><br><span class=\"line\">  echo &quot;Ca files transfered for $h ... ok&quot;</span><br><span class=\"line\">done</span><br></pre></td></tr></table></figure>\n<p>执行脚本，将 tf-k8s-m1 相关的 ca 文件传到tf-k8s-m2 和 tf-k8s-m3：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">chmod +x sync.master.ca.sh</span><br><span class=\"line\"></span><br><span class=\"line\">sudo ./syncaster.ca.sh</span><br></pre></td></tr></table></figure>\n<h4 id=\"2-5-2-安装master-tf-k8s-m2\"><a href=\"#2-5-2-安装master-tf-k8s-m2\" class=\"headerlink\" title=\"2.5.2 安装master tf-k8s-m2\"></a>2.5.2 安装master tf-k8s-m2</h4><p>总共分为四个步骤，分别是:总1. 共分为四个步骤，分别是:</p>\n<ul>\n<li>配置证书、初始化 kubelet 配置和启动 kubelet</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[kube@tf-k8s-m2 ~]$ sudo kubeadm init phase certs all --config kubeadm-config.tf-k8s-m2.yaml</span><br><span class=\"line\">[kube@tf-k8s-m2 ~]$ sudo kubeadm init phase etcd local --config kubeadm-config.tf-k8s-m2.yaml</span><br><span class=\"line\">[kube@tf-k8s-m2 ~]$ sudo kubeadm init phase kubeconfig kubelet --config kubeadm-config.tf-k8s-m2.yaml</span><br><span class=\"line\">[kube@tf-k8s-m2 ~]$ sudo kubeadm init phase kubelet-start --config kubeadm-config.tf-k8s-m2.yaml</span><br></pre></td></tr></table></figure>\n<ul>\n<li>将etcd加入集群</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[kube@tf-k8s-m2 root]$ kubectl exec -n kube-system etcd-tf-k8s-m1 -- etcdctl --ca-file /etc/kubernetes/pki/etcd/ca.crt --cert-file /etc/kubernetes/pki/etcd/peer.crt --key-file /etc/kubernetes/pki/etcd/peer.key --endpoints=https://10.0.0.1:2379 member add tf-k8s-m2 https://10.0.0.2:2380</span><br></pre></td></tr></table></figure>\n<p>启动kube-apiserver、kube-controller-manager、kube-scheduler</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[kube@tf-k8s-m2 ~]$ sudo kubeadm init phase kubeconfig all --config kubeadm-config.m02.yaml</span><br><span class=\"line\">[kube@tf-k8s-m2 ~]$ sudo kubeadm init phase control-plane all --config kubeadm-config.m02.yaml</span><br></pre></td></tr></table></figure>\n<p>将节点标记为master节点</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[kube@tf-k8s-m2 ~]$ sudo kubeadm init phase mark-control-plane --config kubeadm-config.m02.yaml</span><br></pre></td></tr></table></figure>\n<h4 id=\"2-5-3-安装master-tf-k8s-m3\"><a href=\"#2-5-3-安装master-tf-k8s-m3\" class=\"headerlink\" title=\"2.5.3 安装master tf-k8s-m3\"></a>2.5.3 安装master tf-k8s-m3</h4><p>安装过程和安装master tf-k8s-m2是一样的，区别在于使用的kubeadm配置文件为kubeadm-config.tf-k8s-m3.yaml以及etcd加入成员时指定的实例地址不一样。<br>完整的流程如下:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 1.  配置证书、初始化 kubelet 配置和启动 kubelet</span><br><span class=\"line\">sudo kubeadm init phase certs all --config kubeadm-config.tf-k8s-m3.yaml</span><br><span class=\"line\">sudo kubeadm init phase etcd local --config kubeadm-config.tf-k8s-m3.yaml</span><br><span class=\"line\">sudo kubeadm init phase kubeconfig kubelet --config kubeadm-config.tf-k8s-m3.yaml</span><br><span class=\"line\">sudo kubeadm init phase kubelet-start --config kubeadm-config.tf-k8s-m3.yaml</span><br><span class=\"line\"></span><br><span class=\"line\"># 2. 将 etcd 加入集群</span><br><span class=\"line\">kubectl exec -n kube-system etcd-tf-k8s-m1 -- etcdctl --ca-file /etc/kubernetes/pki/etcd/ca.crt --cert-file /etc/kubernetes/pki/etcd/peer.crt --key-file /etc/kubernetes/pki/etcd/peer.key --endpoints=https://10.0.0.1:2379 member add tf-k8s-m3 https://10.0.0.3:2380</span><br><span class=\"line\"></span><br><span class=\"line\"># 3. 启动 kube-apiserver、kube-controller-manager、kube-scheduler</span><br><span class=\"line\">sudo kubeadm init phase kubeconfig all --config kubeadm-config.tf-k8s-m3.yaml</span><br><span class=\"line\">sudo kubeadm init phase control-plane all --config kubeadm-config.tf-k8s-m3.yaml</span><br><span class=\"line\"></span><br><span class=\"line\"># 4. 将节点标记为 master 节点</span><br><span class=\"line\">sudo kubeadm init phase mark-control-plane --config kubeadm-config.tf-k8s-m3.yaml</span><br></pre></td></tr></table></figure>\n<h4 id=\"2-5-4-验证三个master节点\"><a href=\"#2-5-4-验证三个master节点\" class=\"headerlink\" title=\"2.5.4 验证三个master节点\"></a>2.5.4 验证三个master节点</h4><p>至此，三个 master 节点安装完成，通过 kubectl get pods –all-namespaces 查看当前集群所有 Pod。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[kube@tf-k8s-m2 ~]$ kubectl  get pods --all-namespaces</span><br><span class=\"line\">NAMESPACE     NAME                          READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">kube-system   coredns-78d4cf999f-j8zsr      1/1     Running   0          170m</span><br><span class=\"line\">kube-system   coredns-78d4cf999f-lw5qx      1/1     Running   0          171m</span><br><span class=\"line\">kube-system   etcd-m01                      1/1     Running   8          5h11m</span><br><span class=\"line\">kube-system   etcd-m02                      1/1     Running   12         97m</span><br><span class=\"line\">kube-system   etcd-m03                      1/1     Running   0          91m</span><br><span class=\"line\">kube-system   kube-apiserver-m01            1/1     Running   9          5h11m</span><br><span class=\"line\">kube-system   kube-apiserver-m02            1/1     Running   0          95m</span><br><span class=\"line\">kube-system   kube-apiserver-m03            1/1     Running   0          91m</span><br><span class=\"line\">kube-system   kube-controller-manager-m01   1/1     Running   4          5h11m</span><br><span class=\"line\">kube-system   kube-controller-manager-m02   1/1     Running   0          95m</span><br><span class=\"line\">kube-system   kube-controller-manager-m03   1/1     Running   0          91m</span><br><span class=\"line\">kube-system   kube-flannel-ds-amd64-7b86z   1/1     Running   0          3h31m</span><br><span class=\"line\">kube-system   kube-flannel-ds-amd64-98qks   1/1     Running   0          91m</span><br><span class=\"line\">kube-system   kube-flannel-ds-amd64-ljcdp   1/1     Running   0          97m</span><br><span class=\"line\">kube-system   kube-proxy-krnjq              1/1     Running   0          5h12m</span><br><span class=\"line\">kube-system   kube-proxy-scb25              1/1     Running   0          91m</span><br><span class=\"line\">kube-system   kube-proxy-xp4rj              1/1     Running   0          97m</span><br><span class=\"line\">kube-system   kube-scheduler-m01            1/1     Running   4          5h11m</span><br><span class=\"line\">kube-system   kube-scheduler-m02            1/1     Running   0          95m</span><br><span class=\"line\">kube-system   kube-scheduler-m03            1/1     Running   0          91m</span><br></pre></td></tr></table></figure>\n<h4 id=\"2-5-5-加入工作节点\"><a href=\"#2-5-5-加入工作节点\" class=\"headerlink\" title=\"2.5.5 加入工作节点\"></a>2.5.5 加入工作节点</h4><p>这步很简单，只需要在工作节点 tf-k8s-n1 和 tf-k8s-n2 上执行加入集群的命令即可。</p>\n<p>可以使用上面安装 master tf-k8s-m1 成功后打印的命令 kubeadm join api.tf-k8s.xiangwushuo.com:6443 –token a1t7c1.mzltpc72dc3wzj9y –discovery-token-ca-cert-hash sha256:05f44b111174613055975f012fc11fe09bdcd746bd7b3c8d99060c52619f8738，也可以重新生成 Token。<br>这里演示如何重新生成 Token 和 证书 hash，在 tf-k8s-m1 上执行以下操作：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 1. 创建 token</span><br><span class=\"line\">[kube@tf-k8s-m1 ~]$ kubeadm token create </span><br><span class=\"line\"></span><br><span class=\"line\"># 控制台打印如：</span><br><span class=\"line\">gz1v4w.sulpuxkqtnyci92f</span><br><span class=\"line\"></span><br><span class=\"line\"># 2.  查看我们创建的 k8s 集群的证书 hash</span><br><span class=\"line\">[kube@tf-k8s-m1 ~]$ openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2&gt;/dev/null | openssl dgst -sha256 -hex | sed &apos;s/^.* //&apos;</span><br><span class=\"line\"></span><br><span class=\"line\"># 控制台打印如：</span><br><span class=\"line\">b125cd0c80462353d8fa3e4f5034f1e1a1e3cc9bade32acfb235daa867c60f61</span><br></pre></td></tr></table></figure>\n<p>然后使用<code>kubeadm join</code>,分别在工作节点tf-k8s-n1与tf-k8s-n2上执行，将节点加入<br>集群，如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo kubeadm join api.tf-k8s.xiangwushuo.com:6443 --token gz1v4w.sulpuxkqtnyci92f --discovery-token-ca-cert-hash sha256:b125cd0c80462353d8fa3e4f5034f1e1a1e3cc9bade32acfb235daa867c60f61</span><br></pre></td></tr></table></figure>\n<p>在 tf-k8s-m1 上通过 kubectl get nodes 查看，将看到节点已被加进来（节点刚加进来时，状态可能会是 NotReady，稍等一会就回变成 Ready）。</p>\n<h3 id=\"2-6-部署高可用CoreDNS\"><a href=\"#2-6-部署高可用CoreDNS\" class=\"headerlink\" title=\"2.6 部署高可用CoreDNS\"></a>2.6 部署高可用CoreDNS</h3><p>默认安装的 CoreDNS 存在单点问题。在 m01 上通过 kubectl get pods -n kube-system -owide 查看当前集群 CoreDNS Pod 分布（如下）。</p>\n<p>从列表中，可以看到 CoreDNS 的两个 Pod 都在 m01 上，存在单点问题。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[kube@tf-k8s-m1 ~]$ kubectl get pods -n kube-system -owide</span><br><span class=\"line\">NAME                                    READY   STATUS    RESTARTS   AGE     IP            NODE        NOMINATED NODE   READINESS GATES</span><br><span class=\"line\">coredns-6c67f849c7-h7lcr                1/1     Running   0          4d3h    10.244.3.2    tf-k8s-m1   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">coredns-6c67f849c7-mx9k9                1/1     Running   0          4d3h    10.244.4.2    tf-k8s-m1   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">etcd-tf-k8s-m1                          1/1     Running   1          4d5h    10.0.0.1   tf-k8s-m1   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">etcd-tf-k8s-m2                          1/1     Running   7          4d3h    10.0.0.2   tf-k8s-m2   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">etcd-tf-k8s-m3                          1/1     Running   7          4d3h    10.0.0.3   tf-k8s-m3   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-apiserver-tf-k8s-m1                1/1     Running   0          4d5h    10.0.0.1   tf-k8s-m1   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-apiserver-tf-k8s-m2                1/1     Running   0          4d3h    10.0.0.2   tf-k8s-m2   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-apiserver-tf-k8s-m3                1/1     Running   0          4d3h    10.0.0.3   tf-k8s-m3   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-controller-manager-tf-k8s-m1       1/1     Running   1          4d5h    10.0.0.1   tf-k8s-m1   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-controller-manager-tf-k8s-m2       1/1     Running   0          4d3h    10.0.0.2   tf-k8s-m2   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-controller-manager-tf-k8s-m3       1/1     Running   0          4d3h    10.0.0.3   tf-k8s-m3   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-flannel-ds-amd64-4v6dd             1/1     Running   1          4d3h    10.0.0.5   tf-k8s-n2   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-flannel-ds-amd64-g6sg5             1/1     Running   0          4d3h    10.0.0.3   tf-k8s-m3   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-flannel-ds-amd64-ml4w7             1/1     Running   1          4d3h    10.0.0.4   tf-k8s-n1   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-flannel-ds-amd64-tb27x             1/1     Running   0          4d3h    10.0.0.2   tf-k8s-m2   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-flannel-ds-amd64-x5dqj             1/1     Running   0          4d4h    10.0.0.1   tf-k8s-m1   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-proxy-4wbn7                        1/1     Running   0          4d3h    10.0.0.4   tf-k8s-n1   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-proxy-8dhtz                        1/1     Running   0          4d3h    10.0.0.2   tf-k8s-m2   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-proxy-l8727                        1/1     Running   0          4d5h    10.0.0.1   tf-k8s-m1   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-proxy-tz924                        1/1     Running   0          4d3h    10.0.0.5   tf-k8s-n2   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-proxy-w7tmn                        1/1     Running   0          4d3h    10.0.0.3   tf-k8s-m3   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-scheduler-tf-k8s-m1                1/1     Running   1          4d5h    10.0.0.1   tf-k8s-m1   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-scheduler-tf-k8s-m2                1/1     Running   0          4d3h    10.0.0.2   tf-k8s-m2   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-scheduler-tf-k8s-m3                1/1     Running   0          4d3h    10.0.0.3   tf-k8s-m3   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kubernetes-dashboard-847f8cb7b8-hmf9m   1/1     Running   0          3d23h   10.244.4.4    tf-k8s-n2   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">metrics-server-8658466f94-pzl6z         1/1     Running   0          4d2h    10.244.3.3    tf-k8s-n1   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure>\n<p>首先删除CoreDNS的deploy，然后创建新的CoreDNS-HA.yaml配置文件，如下</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: apps/v1</span><br><span class=\"line\">kind: Deployment</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    k8s-app: kube-dns</span><br><span class=\"line\">  name: coredns</span><br><span class=\"line\">  namespace: kube-system</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  #集群规模可自行配置</span><br><span class=\"line\">  replicas: 2</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    matchLabels:</span><br><span class=\"line\">      k8s-app: kube-dns</span><br><span class=\"line\">  strategy:</span><br><span class=\"line\">    rollingUpdate:</span><br><span class=\"line\">      maxSurge: 25%</span><br><span class=\"line\">      maxUnavailable: 1</span><br><span class=\"line\">    type: RollingUpdate</span><br><span class=\"line\">  template:</span><br><span class=\"line\">    metadata:</span><br><span class=\"line\">      labels:</span><br><span class=\"line\">        k8s-app: kube-dns</span><br><span class=\"line\">    spec:</span><br><span class=\"line\">      affinity:</span><br><span class=\"line\">        podAntiAffinity:</span><br><span class=\"line\">          preferredDuringSchedulingIgnoredDuringExecution:</span><br><span class=\"line\">          - weight: 100</span><br><span class=\"line\">            podAffinityTerm:</span><br><span class=\"line\">              labelSelector:</span><br><span class=\"line\">                matchExpressions:</span><br><span class=\"line\">                - key: k8s-app</span><br><span class=\"line\">                  operator: In</span><br><span class=\"line\">                  values:</span><br><span class=\"line\">                  - kube-dns</span><br><span class=\"line\">              topologyKey: kubernetes.io/hostname</span><br><span class=\"line\">      containers:</span><br><span class=\"line\">      - args:</span><br><span class=\"line\">        - -conf</span><br><span class=\"line\">        - /etc/coredns/Corefile</span><br><span class=\"line\">        image: registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:1.2.6</span><br><span class=\"line\">        imagePullPolicy: IfNotPresent</span><br><span class=\"line\">        livenessProbe:</span><br><span class=\"line\">          failureThreshold: 5</span><br><span class=\"line\">          httpGet:</span><br><span class=\"line\">            path: /health</span><br><span class=\"line\">            port: 8080</span><br><span class=\"line\">            scheme: HTTP</span><br><span class=\"line\">          initialDelaySeconds: 60</span><br><span class=\"line\">          periodSeconds: 10</span><br><span class=\"line\">          successThreshold: 1</span><br><span class=\"line\">          timeoutSeconds: 5</span><br><span class=\"line\">        name: coredns</span><br><span class=\"line\">        ports:</span><br><span class=\"line\">        - containerPort: 53</span><br><span class=\"line\">          name: dns</span><br><span class=\"line\">          protocol: UDP</span><br><span class=\"line\">        - containerPort: 53</span><br><span class=\"line\">          name: dns-tcp</span><br><span class=\"line\">          protocol: TCP</span><br><span class=\"line\">        - containerPort: 9153</span><br><span class=\"line\">          name: metrics</span><br><span class=\"line\">          protocol: TCP</span><br><span class=\"line\">        resources:</span><br><span class=\"line\">          limits:</span><br><span class=\"line\">            memory: 170Mi</span><br><span class=\"line\">          requests:</span><br><span class=\"line\">            cpu: 100m</span><br><span class=\"line\">            memory: 70Mi</span><br><span class=\"line\">        securityContext:</span><br><span class=\"line\">          allowPrivilegeEscalation: false</span><br><span class=\"line\">          capabilities:</span><br><span class=\"line\">            add:</span><br><span class=\"line\">            - NET_BIND_SERVICE</span><br><span class=\"line\">            drop:</span><br><span class=\"line\">            - all</span><br><span class=\"line\">          readOnlyRootFilesystem: true</span><br><span class=\"line\">        terminationMessagePath: /dev/termination-log</span><br><span class=\"line\">        terminationMessagePolicy: File</span><br><span class=\"line\">        volumeMounts:</span><br><span class=\"line\">        - mountPath: /etc/coredns</span><br><span class=\"line\">          name: config-volume</span><br><span class=\"line\">          readOnly: true</span><br><span class=\"line\">      dnsPolicy: Default</span><br><span class=\"line\">      restartPolicy: Always</span><br><span class=\"line\">      schedulerName: default-scheduler</span><br><span class=\"line\">      securityContext: &#123;&#125;</span><br><span class=\"line\">      serviceAccount: coredns</span><br><span class=\"line\">      serviceAccountName: coredns</span><br><span class=\"line\">      terminationGracePeriodSeconds: 30</span><br><span class=\"line\">      tolerations:</span><br><span class=\"line\">      - key: CriticalAddonsOnly</span><br><span class=\"line\">        operator: Exists</span><br><span class=\"line\">      - effect: NoSchedule</span><br><span class=\"line\">        key: node-role.kubernetes.io/master</span><br><span class=\"line\">      volumes:</span><br><span class=\"line\">      - configMap:</span><br><span class=\"line\">          defaultMode: 420</span><br><span class=\"line\">          items:</span><br><span class=\"line\">          - key: Corefile</span><br><span class=\"line\">            path: Corefile</span><br><span class=\"line\">          name: coredns</span><br><span class=\"line\">        name: config-volume</span><br></pre></td></tr></table></figure>\n<p>部署新的CoreDNS </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl apply -f CoreDNS-HA.yaml</span><br></pre></td></tr></table></figure>\n<h3 id=\"2-7-部署监控组件metrics-server\"><a href=\"#2-7-部署监控组件metrics-server\" class=\"headerlink\" title=\"2.7 部署监控组件metrics-server\"></a>2.7 部署监控组件metrics-server</h3><p>kubernetesv1.11 以后不再支持通过 heaspter 采集监控数据。使用新的监控数据采集组件metrics-server。 metrics-server 比 heaspter 轻量很多，也不做数据的持久化存储，提供实时的监控数据查询。</p>\n<p>先将所有文件下载，保存在一个文件夹 metrics-server 里。</p>\n<p>修改 metrics-server-deployment.yaml 两处地方，分别是：apiVersion 和 image，最终修改后的 metrics-server-deployment.yaml 如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">---</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: ServiceAccount</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: metrics-server</span><br><span class=\"line\">  namespace: kube-system</span><br><span class=\"line\">---</span><br><span class=\"line\"># 将extensions/v1beta1修改为apps/v1</span><br><span class=\"line\">apiVersion: apps/v1</span><br><span class=\"line\">kind: Deployment</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: metrics-server</span><br><span class=\"line\">  namespace: kube-system</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    k8s-app: metrics-server</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    matchLabels:</span><br><span class=\"line\">      k8s-app: metrics-server</span><br><span class=\"line\">  template:</span><br><span class=\"line\">    metadata:</span><br><span class=\"line\">      name: metrics-server</span><br><span class=\"line\">      labels:</span><br><span class=\"line\">        k8s-app: metrics-server</span><br><span class=\"line\">    spec:</span><br><span class=\"line\">      serviceAccountName: metrics-server</span><br><span class=\"line\">      volumes:</span><br><span class=\"line\">      # mount in tmp so we can safely use from-scratch images and/or read-only containers</span><br><span class=\"line\">      - name: tmp-dir</span><br><span class=\"line\">        emptyDir: &#123;&#125;</span><br><span class=\"line\">      containers:</span><br><span class=\"line\">      - name: metrics-server</span><br><span class=\"line\">        image: cloudnil/metrics-server-amd64:v0.3.1</span><br><span class=\"line\">        command:</span><br><span class=\"line\">          - /metrics-server</span><br><span class=\"line\">          - --kubelet-insecure-tls</span><br><span class=\"line\">          - --kubelet-preferred-address-types=InternalIP</span><br><span class=\"line\">        imagePullPolicy: Always</span><br><span class=\"line\">        volumeMounts:</span><br><span class=\"line\">        - name: tmp-dir</span><br><span class=\"line\">          mountPath: /tmp</span><br></pre></td></tr></table></figure>\n<p>进入刚创建的 metrics-server，执行 kubectl apply -f .  进行部署（注意 -f 后面有个点）,如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[kube@tf-k8s-m1 metrics-server]$ kubectl apply -f .</span><br><span class=\"line\"></span><br><span class=\"line\">clusterrole.rbac.authorization.k8s.io/system:aggregated-metrics-reader created</span><br><span class=\"line\">clusterrolebinding.rbac.authorization.k8s.io/metrics-server:system:auth-delegator created</span><br><span class=\"line\">rolebinding.rbac.authorization.k8s.io/metrics-server-auth-reader created</span><br><span class=\"line\">apiservice.apiregistration.k8s.io/v1beta1.metrics.k8s.io created</span><br><span class=\"line\">serviceaccount/metrics-server created</span><br><span class=\"line\">deployment.apps/metrics-server created</span><br><span class=\"line\">service/metrics-server created</span><br><span class=\"line\">clusterrole.rbac.authorization.k8s.io/system:metrics-server created</span><br><span class=\"line\">clusterrolebinding.rbac.authorization.k8s.io/system:metrics-server created</span><br></pre></td></tr></table></figure>\n<p>运行<code>kubectl get pods -n kube-system</code>，确定metrics-server的pods是否正常running。</p>\n<h3 id=\"2-8-部署Nginx-ingress-controller\"><a href=\"#2-8-部署Nginx-ingress-controller\" class=\"headerlink\" title=\"2.8 部署Nginx-ingress-controller\"></a>2.8 部署Nginx-ingress-controller</h3><p>Nginx-ingress-controller 是 kubernetes 官方提供的集成了 Ingress-controller 和 Nginx 的一个 docker 镜像。</p>\n<p>本次部署中，将 Nginx-ingress 部署到 tf-k8s-m1、tf-k8s-m2、tf-k8s-m3上，监听宿主机的 80 端口。</p>\n<p>创建 nginx-ingress.yaml 文件，内容如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br><span class=\"line\">187</span><br><span class=\"line\">188</span><br><span class=\"line\">189</span><br><span class=\"line\">190</span><br><span class=\"line\">191</span><br><span class=\"line\">192</span><br><span class=\"line\">193</span><br><span class=\"line\">194</span><br><span class=\"line\">195</span><br><span class=\"line\">196</span><br><span class=\"line\">197</span><br><span class=\"line\">198</span><br><span class=\"line\">199</span><br><span class=\"line\">200</span><br><span class=\"line\">201</span><br><span class=\"line\">202</span><br><span class=\"line\">203</span><br><span class=\"line\">204</span><br><span class=\"line\">205</span><br><span class=\"line\">206</span><br><span class=\"line\">207</span><br><span class=\"line\">208</span><br><span class=\"line\">209</span><br><span class=\"line\">210</span><br><span class=\"line\">211</span><br><span class=\"line\">212</span><br><span class=\"line\">213</span><br><span class=\"line\">214</span><br><span class=\"line\">215</span><br><span class=\"line\">216</span><br><span class=\"line\">217</span><br><span class=\"line\">218</span><br><span class=\"line\">219</span><br><span class=\"line\">220</span><br><span class=\"line\">221</span><br><span class=\"line\">222</span><br><span class=\"line\">223</span><br><span class=\"line\">224</span><br><span class=\"line\">225</span><br><span class=\"line\">226</span><br><span class=\"line\">227</span><br><span class=\"line\">228</span><br><span class=\"line\">229</span><br><span class=\"line\">230</span><br><span class=\"line\">231</span><br><span class=\"line\">232</span><br><span class=\"line\">233</span><br><span class=\"line\">234</span><br><span class=\"line\">235</span><br><span class=\"line\">236</span><br><span class=\"line\">237</span><br><span class=\"line\">238</span><br><span class=\"line\">239</span><br><span class=\"line\">240</span><br><span class=\"line\">241</span><br><span class=\"line\">242</span><br><span class=\"line\">243</span><br><span class=\"line\">244</span><br><span class=\"line\">245</span><br><span class=\"line\">246</span><br><span class=\"line\">247</span><br><span class=\"line\">248</span><br><span class=\"line\">249</span><br><span class=\"line\">250</span><br><span class=\"line\">251</span><br><span class=\"line\">252</span><br><span class=\"line\">253</span><br><span class=\"line\">254</span><br><span class=\"line\">255</span><br><span class=\"line\">256</span><br><span class=\"line\">257</span><br><span class=\"line\">258</span><br><span class=\"line\">259</span><br><span class=\"line\">260</span><br><span class=\"line\">261</span><br><span class=\"line\">262</span><br><span class=\"line\">263</span><br><span class=\"line\">264</span><br><span class=\"line\">265</span><br><span class=\"line\">266</span><br><span class=\"line\">267</span><br><span class=\"line\">268</span><br><span class=\"line\">269</span><br><span class=\"line\">270</span><br><span class=\"line\">271</span><br><span class=\"line\">272</span><br><span class=\"line\">273</span><br><span class=\"line\">274</span><br><span class=\"line\">275</span><br><span class=\"line\">276</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Namespace</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: ingress-nginx</span><br><span class=\"line\">---</span><br><span class=\"line\">kind: ConfigMap</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: nginx-configuration</span><br><span class=\"line\">  namespace: ingress-nginx</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app.kubernetes.io/name: ingress-nginx</span><br><span class=\"line\">    app.kubernetes.io/part-of: ingress-nginx</span><br><span class=\"line\">---</span><br><span class=\"line\">kind: ConfigMap</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: tcp-services</span><br><span class=\"line\">  namespace: ingress-nginx</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app.kubernetes.io/name: ingress-nginx</span><br><span class=\"line\">    app.kubernetes.io/part-of: ingress-nginx</span><br><span class=\"line\">---</span><br><span class=\"line\">kind: ConfigMap</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: udp-services</span><br><span class=\"line\">  namespace: ingress-nginx</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app.kubernetes.io/name: ingress-nginx</span><br><span class=\"line\">    app.kubernetes.io/part-of: ingress-nginx</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: ServiceAccount</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: nginx-ingress-serviceaccount</span><br><span class=\"line\">  namespace: ingress-nginx</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app.kubernetes.io/name: ingress-nginx</span><br><span class=\"line\">    app.kubernetes.io/part-of: ingress-nginx</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: rbac.authorization.k8s.io/v1beta1</span><br><span class=\"line\">kind: ClusterRole</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: nginx-ingress-clusterrole</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app.kubernetes.io/name: ingress-nginx</span><br><span class=\"line\">    app.kubernetes.io/part-of: ingress-nginx</span><br><span class=\"line\">rules:</span><br><span class=\"line\">  - apiGroups:</span><br><span class=\"line\">      - &quot;&quot;</span><br><span class=\"line\">    resources:</span><br><span class=\"line\">      - configmaps</span><br><span class=\"line\">      - endpoints</span><br><span class=\"line\">      - nodes</span><br><span class=\"line\">      - pods</span><br><span class=\"line\">      - secrets</span><br><span class=\"line\">    verbs:</span><br><span class=\"line\">      - list</span><br><span class=\"line\">      - watch</span><br><span class=\"line\">  - apiGroups:</span><br><span class=\"line\">      - &quot;&quot;</span><br><span class=\"line\">    resources:</span><br><span class=\"line\">      - nodes</span><br><span class=\"line\">    verbs:</span><br><span class=\"line\">      - get</span><br><span class=\"line\">  - apiGroups:</span><br><span class=\"line\">      - &quot;&quot;</span><br><span class=\"line\">    resources:</span><br><span class=\"line\">      - services</span><br><span class=\"line\">    verbs:</span><br><span class=\"line\">      - get</span><br><span class=\"line\">      - list</span><br><span class=\"line\">      - watch</span><br><span class=\"line\">  - apiGroups:</span><br><span class=\"line\">      - &quot;extensions&quot;</span><br><span class=\"line\">    resources:</span><br><span class=\"line\">      - ingresses</span><br><span class=\"line\">    verbs:</span><br><span class=\"line\">      - get</span><br><span class=\"line\">      - list</span><br><span class=\"line\">      - watch</span><br><span class=\"line\">  - apiGroups:</span><br><span class=\"line\">      - &quot;&quot;</span><br><span class=\"line\">    resources:</span><br><span class=\"line\">      - events</span><br><span class=\"line\">    verbs:</span><br><span class=\"line\">      - create</span><br><span class=\"line\">      - patch</span><br><span class=\"line\">  - apiGroups:</span><br><span class=\"line\">      - &quot;extensions&quot;</span><br><span class=\"line\">    resources:</span><br><span class=\"line\">      - ingresses/status</span><br><span class=\"line\">    verbs:</span><br><span class=\"line\">      - update</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: rbac.authorization.k8s.io/v1beta1</span><br><span class=\"line\">kind: Role</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: nginx-ingress-role</span><br><span class=\"line\">  namespace: ingress-nginx</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app.kubernetes.io/name: ingress-nginx</span><br><span class=\"line\">    app.kubernetes.io/part-of: ingress-nginx</span><br><span class=\"line\">rules:</span><br><span class=\"line\">  - apiGroups:</span><br><span class=\"line\">      - &quot;&quot;</span><br><span class=\"line\">    resources:</span><br><span class=\"line\">      - configmaps</span><br><span class=\"line\">      - pods</span><br><span class=\"line\">      - secrets</span><br><span class=\"line\">      - namespaces</span><br><span class=\"line\">    verbs:</span><br><span class=\"line\">      - get</span><br><span class=\"line\">  - apiGroups:</span><br><span class=\"line\">      - &quot;&quot;</span><br><span class=\"line\">    resources:</span><br><span class=\"line\">      - configmaps</span><br><span class=\"line\">    resourceNames:</span><br><span class=\"line\">      - &quot;ingress-controller-leader-nginx&quot;</span><br><span class=\"line\">    verbs:</span><br><span class=\"line\">      - get</span><br><span class=\"line\">      - update</span><br><span class=\"line\">  - apiGroups:</span><br><span class=\"line\">      - &quot;&quot;</span><br><span class=\"line\">    resources:</span><br><span class=\"line\">      - configmaps</span><br><span class=\"line\">    verbs:</span><br><span class=\"line\">      - create</span><br><span class=\"line\">  - apiGroups:</span><br><span class=\"line\">      - &quot;&quot;</span><br><span class=\"line\">    resources:</span><br><span class=\"line\">      - endpoints</span><br><span class=\"line\">    verbs:</span><br><span class=\"line\">      - get</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: rbac.authorization.k8s.io/v1beta1</span><br><span class=\"line\">kind: RoleBinding</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: nginx-ingress-role-nisa-binding</span><br><span class=\"line\">  namespace: ingress-nginx</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app.kubernetes.io/name: ingress-nginx</span><br><span class=\"line\">    app.kubernetes.io/part-of: ingress-nginx</span><br><span class=\"line\">roleRef:</span><br><span class=\"line\">  apiGroup: rbac.authorization.k8s.io</span><br><span class=\"line\">  kind: Role</span><br><span class=\"line\">  name: nginx-ingress-role</span><br><span class=\"line\">subjects:</span><br><span class=\"line\">  - kind: ServiceAccount</span><br><span class=\"line\">    name: nginx-ingress-serviceaccount</span><br><span class=\"line\">    namespace: ingress-nginx</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: rbac.authorization.k8s.io/v1beta1</span><br><span class=\"line\">kind: ClusterRoleBinding</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: nginx-ingress-clusterrole-nisa-binding</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app.kubernetes.io/name: ingress-nginx</span><br><span class=\"line\">    app.kubernetes.io/part-of: ingress-nginx</span><br><span class=\"line\">roleRef:</span><br><span class=\"line\">  apiGroup: rbac.authorization.k8s.io</span><br><span class=\"line\">  kind: ClusterRole</span><br><span class=\"line\">  name: nginx-ingress-clusterrole</span><br><span class=\"line\">subjects:</span><br><span class=\"line\">  - kind: ServiceAccount</span><br><span class=\"line\">    name: nginx-ingress-serviceaccount</span><br><span class=\"line\">    namespace: ingress-nginx</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: apps/v1</span><br><span class=\"line\">kind: Deployment</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: nginx-ingress-controller</span><br><span class=\"line\">  namespace: ingress-nginx</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app.kubernetes.io/name: ingress-nginx</span><br><span class=\"line\">    app.kubernetes.io/part-of: ingress-nginx</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  replicas: 3</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    matchLabels:</span><br><span class=\"line\">      app.kubernetes.io/name: ingress-nginx</span><br><span class=\"line\">      app.kubernetes.io/part-of: ingress-nginx</span><br><span class=\"line\">  template:</span><br><span class=\"line\">    metadata:</span><br><span class=\"line\">      labels:</span><br><span class=\"line\">        app.kubernetes.io/name: ingress-nginx</span><br><span class=\"line\">        app.kubernetes.io/part-of: ingress-nginx</span><br><span class=\"line\">      annotations:</span><br><span class=\"line\">        prometheus.io/port: &quot;10254&quot;</span><br><span class=\"line\">        prometheus.io/scrape: &quot;true&quot;</span><br><span class=\"line\">    spec:</span><br><span class=\"line\">      hostNetwork: true</span><br><span class=\"line\">      affinity:</span><br><span class=\"line\">        nodeAffinity:</span><br><span class=\"line\">          requiredDuringSchedulingIgnoredDuringExecution:</span><br><span class=\"line\">            nodeSelectorTerms:</span><br><span class=\"line\">            - matchExpressions:</span><br><span class=\"line\">              - key: kubernetes.io/hostname</span><br><span class=\"line\">                operator: In</span><br><span class=\"line\">                # 指定部署到三台 master 上</span><br><span class=\"line\">                values:</span><br><span class=\"line\">                - tf-k8s-m1</span><br><span class=\"line\">                - tf-k8s-m2</span><br><span class=\"line\">                - tf-k8s-m3</span><br><span class=\"line\">        podAntiAffinity:</span><br><span class=\"line\">          requiredDuringSchedulingIgnoredDuringExecution:</span><br><span class=\"line\">            - labelSelector:</span><br><span class=\"line\">                matchExpressions:</span><br><span class=\"line\">                  - key: app.kubernetes.io/name</span><br><span class=\"line\">                    operator: In</span><br><span class=\"line\">                    values: </span><br><span class=\"line\">                    - ingress-nginx</span><br><span class=\"line\">              topologyKey: &quot;kubernetes.io/hostname&quot;</span><br><span class=\"line\">      tolerations:</span><br><span class=\"line\">      - key: node-role.kubernetes.io/master</span><br><span class=\"line\">        effect: NoSchedule</span><br><span class=\"line\">      serviceAccountName: nginx-ingress-serviceaccount</span><br><span class=\"line\">      containers:</span><br><span class=\"line\">        - name: nginx-ingress-controller</span><br><span class=\"line\">          image: registry.cn-hangzhou.aliyuncs.com/google_containers/nginx-ingress-controller:0.21.0</span><br><span class=\"line\">          args:</span><br><span class=\"line\">            - /nginx-ingress-controller</span><br><span class=\"line\">            - --configmap=/nginx-configuration</span><br><span class=\"line\">            - --tcp-services-configmap=/tcp-services</span><br><span class=\"line\">            - --udp-services-configmap=/udp-services</span><br><span class=\"line\">            # - --publish-service=/ingress-nginx</span><br><span class=\"line\">            - --annotations-prefix=nginx.ingress.kubernetes.io</span><br><span class=\"line\">          securityContext:</span><br><span class=\"line\">            capabilities:</span><br><span class=\"line\">              drop:</span><br><span class=\"line\">                - ALL</span><br><span class=\"line\">              add:</span><br><span class=\"line\">                - NET_BIND_SERVICE</span><br><span class=\"line\">            # www-data -&gt; 33</span><br><span class=\"line\">            runAsUser: 33</span><br><span class=\"line\">          env:</span><br><span class=\"line\">            - name: POD_NAME</span><br><span class=\"line\">              valueFrom:</span><br><span class=\"line\">                fieldRef:</span><br><span class=\"line\">                  fieldPath: metadata.name</span><br><span class=\"line\">            - name: POD_NAMESPACE</span><br><span class=\"line\">              valueFrom:</span><br><span class=\"line\">                fieldRef:</span><br><span class=\"line\">                  fieldPath: metadata.namespace</span><br><span class=\"line\">          ports:</span><br><span class=\"line\">            - name: http</span><br><span class=\"line\">              containerPort: 80</span><br><span class=\"line\">            - name: https</span><br><span class=\"line\">              containerPort: 443</span><br><span class=\"line\">          livenessProbe:</span><br><span class=\"line\">            failureThreshold: 3</span><br><span class=\"line\">            httpGet:</span><br><span class=\"line\">              path: /healthz</span><br><span class=\"line\">              port: 10254</span><br><span class=\"line\">              scheme: HTTP</span><br><span class=\"line\">            initialDelaySeconds: 10</span><br><span class=\"line\">            periodSeconds: 10</span><br><span class=\"line\">            successThreshold: 1</span><br><span class=\"line\">            timeoutSeconds: 1</span><br><span class=\"line\">          readinessProbe:</span><br><span class=\"line\">            failureThreshold: 3</span><br><span class=\"line\">            httpGet:</span><br><span class=\"line\">              path: /healthz</span><br><span class=\"line\">              port: 10254</span><br><span class=\"line\">              scheme: HTTP</span><br><span class=\"line\">            periodSeconds: 10</span><br><span class=\"line\">            successThreshold: 1</span><br><span class=\"line\">            timeoutSeconds: 1</span><br><span class=\"line\">          resources:</span><br><span class=\"line\">            limits:</span><br><span class=\"line\">              cpu: 1</span><br><span class=\"line\">              memory: 1024Mi</span><br><span class=\"line\">            requests:</span><br><span class=\"line\">              cpu: 0.25</span><br><span class=\"line\">              memory: 512Mi</span><br></pre></td></tr></table></figure>\n<p>部署 nginx ingress，执行命令 kubectl apply -f nginx-ingress.yaml</p>\n<h3 id=\"2-9-部署kubernetes-dashboard\"><a href=\"#2-9-部署kubernetes-dashboard\" class=\"headerlink\" title=\"2.9 部署kubernetes-dashboard\"></a>2.9 部署kubernetes-dashboard</h3><h4 id=\"2-9-1-Dashboard-配置\"><a href=\"#2-9-1-Dashboard-配置\" class=\"headerlink\" title=\"2.9.1 Dashboard 配置\"></a>2.9.1 Dashboard 配置</h4><p>新建部署 dashboard 的资源配置文件：kubernetes-dashboard.yaml，内容如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Secret</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    k8s-app: kubernetes-dashboard</span><br><span class=\"line\">  name: kubernetes-dashboard-certs</span><br><span class=\"line\">  namespace: kube-system</span><br><span class=\"line\">type: Opaque</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: ServiceAccount</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    k8s-app: kubernetes-dashboard</span><br><span class=\"line\">  name: kubernetes-dashboard</span><br><span class=\"line\">  namespace: kube-system</span><br><span class=\"line\">---</span><br><span class=\"line\">kind: Role</span><br><span class=\"line\">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: kubernetes-dashboard-minimal</span><br><span class=\"line\">  namespace: kube-system</span><br><span class=\"line\">rules:</span><br><span class=\"line\">  # Allow Dashboard to create &apos;kubernetes-dashboard-key-holder&apos; secret.</span><br><span class=\"line\">- apiGroups: [&quot;&quot;]</span><br><span class=\"line\">  resources: [&quot;secrets&quot;]</span><br><span class=\"line\">  verbs: [&quot;create&quot;]</span><br><span class=\"line\">  # Allow Dashboard to create &apos;kubernetes-dashboard-settings&apos; config map.</span><br><span class=\"line\">- apiGroups: [&quot;&quot;]</span><br><span class=\"line\">  resources: [&quot;configmaps&quot;]</span><br><span class=\"line\">  verbs: [&quot;create&quot;]</span><br><span class=\"line\">  # Allow Dashboard to get, update and delete Dashboard exclusive secrets.</span><br><span class=\"line\">- apiGroups: [&quot;&quot;]</span><br><span class=\"line\">  resources: [&quot;secrets&quot;]</span><br><span class=\"line\">  resourceNames: [&quot;kubernetes-dashboard-key-holder&quot;, &quot;kubernetes-dashboard-certs&quot;]</span><br><span class=\"line\">  verbs: [&quot;get&quot;, &quot;update&quot;, &quot;delete&quot;]</span><br><span class=\"line\">  # Allow Dashboard to get and update &apos;kubernetes-dashboard-settings&apos; config map.</span><br><span class=\"line\">- apiGroups: [&quot;&quot;]</span><br><span class=\"line\">  resources: [&quot;configmaps&quot;]</span><br><span class=\"line\">  resourceNames: [&quot;kubernetes-dashboard-settings&quot;]</span><br><span class=\"line\">  verbs: [&quot;get&quot;, &quot;update&quot;]</span><br><span class=\"line\">  # Allow Dashboard to get metrics from heapster.</span><br><span class=\"line\">- apiGroups: [&quot;&quot;]</span><br><span class=\"line\">  resources: [&quot;services&quot;]</span><br><span class=\"line\">  resourceNames: [&quot;heapster&quot;]</span><br><span class=\"line\">  verbs: [&quot;proxy&quot;]</span><br><span class=\"line\">- apiGroups: [&quot;&quot;]</span><br><span class=\"line\">  resources: [&quot;services/proxy&quot;]</span><br><span class=\"line\">  resourceNames: [&quot;heapster&quot;, &quot;http:heapster:&quot;, &quot;https:heapster:&quot;]</span><br><span class=\"line\">  verbs: [&quot;get&quot;]</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class=\"line\">kind: RoleBinding</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: kubernetes-dashboard-minimal</span><br><span class=\"line\">  namespace: kube-system</span><br><span class=\"line\">roleRef:</span><br><span class=\"line\">  apiGroup: rbac.authorization.k8s.io</span><br><span class=\"line\">  kind: Role</span><br><span class=\"line\">  name: kubernetes-dashboard-minimal</span><br><span class=\"line\">subjects:</span><br><span class=\"line\">- kind: ServiceAccount</span><br><span class=\"line\">  name: kubernetes-dashboard</span><br><span class=\"line\">  namespace: kube-system</span><br><span class=\"line\">---</span><br><span class=\"line\">kind: Deployment</span><br><span class=\"line\">apiVersion: apps/v1</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    k8s-app: kubernetes-dashboard</span><br><span class=\"line\">  name: kubernetes-dashboard</span><br><span class=\"line\">  namespace: kube-system</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  replicas: 1</span><br><span class=\"line\">  revisionHistoryLimit: 10</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    matchLabels:</span><br><span class=\"line\">      k8s-app: kubernetes-dashboard</span><br><span class=\"line\">  template:</span><br><span class=\"line\">    metadata:</span><br><span class=\"line\">      labels:</span><br><span class=\"line\">        k8s-app: kubernetes-dashboard</span><br><span class=\"line\">    spec:</span><br><span class=\"line\">      containers:</span><br><span class=\"line\">      - name: kubernetes-dashboard</span><br><span class=\"line\">        # 使用阿里云的镜像</span><br><span class=\"line\">        image: registry.cn-hangzhou.aliyuncs.com/google_containers/kubernetes-dashboard-amd64:v1.10.0</span><br><span class=\"line\">        ports:</span><br><span class=\"line\">        - containerPort: 8443</span><br><span class=\"line\">          protocol: TCP</span><br><span class=\"line\">        args:</span><br><span class=\"line\">          - --auto-generate-certificates</span><br><span class=\"line\">        volumeMounts:</span><br><span class=\"line\">        - name: kubernetes-dashboard-certs</span><br><span class=\"line\">          mountPath: /certs</span><br><span class=\"line\">          # Create on-disk volume to store exec logs</span><br><span class=\"line\">        - mountPath: /tmp</span><br><span class=\"line\">          name: tmp-volume</span><br><span class=\"line\">        livenessProbe:</span><br><span class=\"line\">          httpGet:</span><br><span class=\"line\">            scheme: HTTPS</span><br><span class=\"line\">            path: /</span><br><span class=\"line\">            port: 8443</span><br><span class=\"line\">          initialDelaySeconds: 30</span><br><span class=\"line\">          timeoutSeconds: 30</span><br><span class=\"line\">      volumes:</span><br><span class=\"line\">      - name: kubernetes-dashboard-certs</span><br><span class=\"line\">        secret:</span><br><span class=\"line\">          secretName: kubernetes-dashboard-certs</span><br><span class=\"line\">      - name: tmp-volume</span><br><span class=\"line\">        emptyDir: &#123;&#125;</span><br><span class=\"line\">      serviceAccountName: kubernetes-dashboard</span><br><span class=\"line\">      tolerations:</span><br><span class=\"line\">      - key: node-role.kubernetes.io/master</span><br><span class=\"line\">        effect: NoSchedule</span><br><span class=\"line\">---</span><br><span class=\"line\">kind: Service</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    k8s-app: kubernetes-dashboard</span><br><span class=\"line\">  name: kubernetes-dashboard</span><br><span class=\"line\">  namespace: kube-system</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  ports:</span><br><span class=\"line\">    - port: 443</span><br><span class=\"line\">      targetPort: 8443</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    k8s-app: kubernetes-dashboard</span><br><span class=\"line\">---</span><br><span class=\"line\"># 配置 ingress 配置，待会部署完 ingress 之后，就可以通过以下配置的域名访问</span><br><span class=\"line\">apiVersion: extensions/v1beta1</span><br><span class=\"line\">kind: Ingress</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: dashboard-ingress</span><br><span class=\"line\">  namespace: kube-system</span><br><span class=\"line\">  annotations:</span><br><span class=\"line\">    # 如果通过 HTTP 访问，跳转到 HTTPS</span><br><span class=\"line\">    nginx.ingress.kubernetes.io/ssl-redirect: &quot;true&quot;</span><br><span class=\"line\">    nginx.ingress.kubernetes.io/rewrite-target: /</span><br><span class=\"line\">    # 指定转发协议为 HTTPS，因为 ingress 默认转发协议是 HTTP，而 kubernetes-dashboard 默认是 HTTPS</span><br><span class=\"line\">    nginx.ingress.kubernetes.io/backend-protocol: &quot;HTTPS&quot;</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  # 指定使用的 secret (刚刚创建的 secret)</span><br><span class=\"line\">  tls:</span><br><span class=\"line\">   - secretName: secret-ca-tf-k8s-xiangwushuo-com</span><br><span class=\"line\">  rules:</span><br><span class=\"line\">  # 指定访问 dashboard 的域名</span><br><span class=\"line\">  - host: dashboard.tf-k8s.xiangwushuo.com</span><br><span class=\"line\">    http:</span><br><span class=\"line\">      paths:</span><br><span class=\"line\">      - path: /</span><br><span class=\"line\">        backend:</span><br><span class=\"line\">          serviceName: kubernetes-dashboard</span><br><span class=\"line\">          servicePort: 443</span><br></pre></td></tr></table></figure>\n<p>执行部署 kubernetes-dashboard，命令 kubectl apply -f kubernetes-dashboard.yaml.</p>\n<p>在本地笔记本电脑上访问dashboard的时候，需要将dashboard.tf-k8s.xiangwushuo.com域名解析到三台master的IP（配置代理），简单地，可以直接在本地/etc/hosts添加</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">## 172.66.23.13 为tf-k8s-m1的外网IP</span><br><span class=\"line\">172.66.23.13 dashboard.tf-k8s.xiangwushuo.com</span><br></pre></td></tr></table></figure>\n<p>从浏览器访问: <a href=\"http://dashboard.tf-k8s.xiangwushuo.com\" target=\"_blank\" rel=\"noopener\">http://dashboard.tf-k8s.xiangwushuo.com</a><br><img src=\"/images/dashboard-login.png\" alt=\"\"></p>\n<h4 id=\"2-9-2-HTTPS-访问-Dashboard\"><a href=\"#2-9-2-HTTPS-访问-Dashboard\" class=\"headerlink\" title=\"2.9.2 HTTPS 访问 Dashboard\"></a>2.9.2 HTTPS 访问 Dashboard</h4><p>由于通过 HTTP 访问 dashboard 会无法登录进去 dashboard 的问题，所以这里我们将 dashboard 的服务配置成 HTTPS 进行访问。<br>总共三步:<br>签证书（或者使用权威的证书机构颁发的证书）</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">openssl req -x509 -nodes -days 3650 -newkey rsa:2048 -keyout ./tf-k8s.xiangwushuo.com.key -out ./tf-k8s.xiangwushuo.com.crt -subj &quot;/CN=*.xiangwushuo.com&quot;</span><br></pre></td></tr></table></figure>\n<p>创建 k8s Secret 资源</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl -n kube-system create secret tls secret-ca-tf-k8s-xiangwushuo-com --key ./tf-k8s.xiangwushuo.com.key --cert tf-k8s.xiangwushuo.com.crt</span><br></pre></td></tr></table></figure>\n<p>配置 dashboard 的 ingress 为 HTTPS 访问服务,修改 kubernetes-dashboard.yaml，将其中的 Ingress 配置改为支持 HTTPS，具体配置如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">...省略...</span><br><span class=\"line\"></span><br><span class=\"line\">apiVersion: extensions/v1beta1</span><br><span class=\"line\">kind: Ingress</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: dashboard-ingress</span><br><span class=\"line\">  namespace: kube-system</span><br><span class=\"line\">  annotations:</span><br><span class=\"line\">    # 如果通过 HTTP 访问，跳转到 HTTPS</span><br><span class=\"line\">    nginx.ingress.kubernetes.io/ssl-redirect: &quot;true&quot;</span><br><span class=\"line\">    nginx.ingress.kubernetes.io/rewrite-target: /</span><br><span class=\"line\">    # 指定转发协议为 HTTPS，因为 ingress 默认转发协议是 HTTP，而 kubernetes-dashboard 默认是 HTTPS</span><br><span class=\"line\">    nginx.ingress.kubernetes.io/backend-protocol: &quot;HTTPS&quot;</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  # 指定使用的 secret (刚刚创建的 secret)</span><br><span class=\"line\">  tls:</span><br><span class=\"line\">   - secretName: secret-ca-k8s-hiko-im</span><br><span class=\"line\">  rules:</span><br><span class=\"line\">  # 指定访问 dashboard 的域名</span><br><span class=\"line\">  - host: dashboard.k8s.hiko.im</span><br><span class=\"line\">    http:</span><br><span class=\"line\">      paths:</span><br><span class=\"line\">      - path: /</span><br><span class=\"line\">        backend:</span><br><span class=\"line\">          serviceName: kubernetes-dashboard</span><br><span class=\"line\">          servicePort: 443</span><br></pre></td></tr></table></figure>\n<p>使用 kubectl apply -f kubernetes-dashboard.yaml 让配置生效。</p>\n<h4 id=\"2-9-3-3-登录-Dashboard\"><a href=\"#2-9-3-3-登录-Dashboard\" class=\"headerlink\" title=\"2.9.3 .3 登录 Dashboard\"></a>2.9.3 .3 登录 Dashboard</h4><p>登录 dashboard 需要做几个事情（不用担心，一个脚本搞定）:</p>\n<p>新建 sa 的账号（也叫 serviceaccount）<br>集群角色绑定（将第 1 步新建的账号，绑定到 cluster-admin 这个角色上）<br>查看 Token 以及 Token 中的 secrect （secrect 中的 token 字段就是来登录的）<br>执行以下脚本，获得登录的 Token:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">## 创建脚本：create.dashboard.token.sh</span><br><span class=\"line\"></span><br><span class=\"line\">#!/bin/sh</span><br><span class=\"line\"></span><br><span class=\"line\">kubectl create sa dashboard-admin -n kube-system</span><br><span class=\"line\">kubectl create clusterrolebinding dashboard-admin --clusterrole=cluster-admin --serviceaccount=kube-system:dashboard-admin</span><br><span class=\"line\">ADMIN_SECRET=$(kubectl get secrets -n kube-system | grep dashboard-admin | awk &apos;&#123;print $1&#125;&apos;)</span><br><span class=\"line\">DASHBOARD_LOGIN_TOKEN=$(kubectl describe secret -n kube-system $&#123;ADMIN_SECRET&#125; | grep -E &apos;^token&apos; | awk &apos;&#123;print $2&#125;&apos;)</span><br><span class=\"line\">echo $&#123;DASHBOARD_LOGIN_TOKEN&#125;</span><br></pre></td></tr></table></figure>\n<p>复制 Token 去登录就行，Token 样例：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJkYXNoYm9hcmQtYWRtaW4tdG9rZW4tNWtnZHoiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoiZGFzaGJvYXJkLWFkbWluIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiYWQxNDAyMjQtMDYxNC0xMWU5LTkxMDgtNTI1NDAwODQ4MWQ1Iiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmUtc3lzdGVtOmRhc2hib2FyZC1hZG1pbiJ9.ry4xYI6TFF6J8xXsilu0qhuBeRjSNqVPq3OUzl62Ad3e2wM-biC5pPlKNmJLfJzurxnQrqp59VjmVeTA8BZiF7S6hqlrk8XE9_LFlItUvq3rp5wFuhJuVol8Yoi4UJFzUYQF6baH0O3R10aK33g2WmWLIg79OFAkeMMHrLthbL2pc_p_kG13_qDXlEuVgnIAFsKzxnrCCUfZ2GwGsHEFEqTGBCb0u6x3AZqfQgbN3DALkjjNTyTLP5Ok-LJ3Ug8SZZQBksvTeXCGXZDfk2LDDIvp_DyM7nTL3CTT5cQ3g4aBTFAae47NAkQkmjZg0mxvJH0xVnxrvXLND8FLLkzMxg</span><br></pre></td></tr></table></figure>\n<h2 id=\"3-参考文献\"><a href=\"#3-参考文献\" class=\"headerlink\" title=\"3. 参考文献\"></a>3. 参考文献</h2><p><a href=\"https://www.ctolib.com/HikoQiu-kubeadm-install-k8s.html\" target=\"_blank\" rel=\"noopener\">1. kubeadm 1.13 安装高可用 kubernetes v1.13.1 集群</a><br><a href=\"https://www.jianshu.com/p/39d7000dfa47\" target=\"_blank\" rel=\"noopener\">2. 如何在CentOS 7上修改主机名</a><br><a href=\"https://blog.csdn.net/mmd0308/article/details/73825953\" target=\"_blank\" rel=\"noopener\">3. Linux之ssh免密登录</a><br><a href=\"http://blog.51cto.com/chenfage/1830424\" target=\"_blank\" rel=\"noopener\">4. sudo与visudo的超细用法说明</a><br><a href=\"https://www.kubernetes.org.cn/4948.html\" target=\"_blank\" rel=\"noopener\">5. kubeadm HA master(v1.13.0)离线包 + 自动化脚本 + 常用插件 For Centos/Fedora</a><br><a href=\"https://github.com/coreos/flannel\" target=\"_blank\" rel=\"noopener\">6. github.coreos.flannel</a><br><a href=\"https://jimmysong.io/kubernetes-handbook/\" target=\"_blank\" rel=\"noopener\">7. Kubernetes Handbook——Kubernetes中文指南/云原生应用架构实践手册</a></p>\n"}],"PostAsset":[],"PostCategory":[{"post_id":"cjsa3xoy900003lxyw07gp0rj","category_id":"cjsa3xoyf00023lxyz6pnos28","_id":"cjsa3xoyj00073lxyf1dx4629"},{"post_id":"cjsa3xoyd00013lxyr9dyd3nn","category_id":"cjsa3xoyi00053lxy4jzbqbmv","_id":"cjsa3xoyk000c3lxy111ilgdk"},{"post_id":"cjsa3xoyg00043lxyvobu2i4w","category_id":"cjsa3xoyj00083lxywsk38d4z","_id":"cjsa3xoyk000f3lxyg1tam6xn"},{"post_id":"cjsa3xp3v000l3lxy94h5a1zd","category_id":"cjsa3xoyj00083lxywsk38d4z","_id":"cjsa3xp3y000n3lxywpp3o768"},{"post_id":"cjsa3xp5q000o3lxy4v4oz4zc","category_id":"cjsa3xp5r000p3lxy4lhqztgr","_id":"cjsa3xp5r000s3lxy37ik2qnt"}],"PostTag":[{"post_id":"cjsa3xoy900003lxyw07gp0rj","tag_id":"cjsa3xoyg00033lxyean6pii3","_id":"cjsa3xoyk000a3lxyjo38tuct"},{"post_id":"cjsa3xoy900003lxyw07gp0rj","tag_id":"cjsa3xoyi00063lxyp60i75iu","_id":"cjsa3xoyk000b3lxy50a6nb5t"},{"post_id":"cjsa3xoyd00013lxyr9dyd3nn","tag_id":"cjsa3xoyj00093lxy8w75mvmk","_id":"cjsa3xoyk000e3lxyprasntpr"},{"post_id":"cjsa3xoyg00043lxyvobu2i4w","tag_id":"cjsa3xoyk000d3lxyo3k6ts3f","_id":"cjsa3xoyl000g3lxyjs9rsbkh"},{"post_id":"cjsa3xp3v000l3lxy94h5a1zd","tag_id":"cjsa3xoyk000d3lxyo3k6ts3f","_id":"cjsa3xp3y000m3lxys1xcp3nj"},{"post_id":"cjsa3xp5q000o3lxy4v4oz4zc","tag_id":"cjsa3xp5r000q3lxya2bpzsr5","_id":"cjsa3xp5r000r3lxys2x239c3"}],"Tag":[{"name":"数据科学","_id":"cjsa3xoyg00033lxyean6pii3"},{"name":"工程","_id":"cjsa3xoyi00063lxyp60i75iu"},{"name":"Hexo","_id":"cjsa3xoyj00093lxy8w75mvmk"},{"name":"机器学习","_id":"cjsa3xoyk000d3lxyo3k6ts3f"},{"name":"kubernetes","_id":"cjsa3xp5r000q3lxya2bpzsr5"}]}}